{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T01:42:04.247577Z",
     "start_time": "2020-10-03T01:41:53.296226Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model,Sequential\n",
    "\n",
    "from keras.layers import Input, Dense,Flatten,Dropout,BatchNormalization,Activation,Bidirectional,LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve,confusion_matrix,plot_roc_curve\n",
    "from sklearn import metrics\n",
    "d = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Fire/CDI_Based/Intensity/CSV/Gray.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T01:42:04.279517Z",
     "start_time": "2020-10-03T01:42:04.248576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Label Demension : (54,)\n"
     ]
    }
   ],
   "source": [
    "data=d\n",
    "\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=20)\n",
    "Y_train,Y_test=X_train['Class'].values,X_test['Class'].values\n",
    "\n",
    "\n",
    "X_train = X_train.drop(['Class'], axis=1)\n",
    "X_test = X_test.drop(['Class'], axis=1)\n",
    "std =StandardScaler()\n",
    "X_train=std.fit_transform(X_train)\n",
    "X_test=std.transform(X_test)\n",
    "print('Test_Label Demension : ' + str(np.shape(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T01:42:05.120957Z",
     "start_time": "2020-10-03T01:42:05.101011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "lr = 0.001\n",
    "generations = 20000\n",
    "num_gens_to_wait = 250\n",
    "batch_size = 64\n",
    "drop_out_rate = 0.5\n",
    "input_shape = (28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T14:56:16.959026Z",
     "start_time": "2020-09-26T14:55:58.124927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 25, 16)            80        \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 22, 16)            1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 7, 32)             2592      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 3, 32)             5152      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,897\n",
      "Trainable params: 8,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.6686 - accuracy: 0.5467 - val_loss: 0.6575 - val_accuracy: 0.6667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6379 - accuracy: 0.7103 - val_loss: 0.6345 - val_accuracy: 0.7407\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6067 - accuracy: 0.7664 - val_loss: 0.6125 - val_accuracy: 0.7593\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5577 - accuracy: 0.7757 - val_loss: 0.5961 - val_accuracy: 0.7593\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5420 - accuracy: 0.8084 - val_loss: 0.5792 - val_accuracy: 0.7407\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5010 - accuracy: 0.8084 - val_loss: 0.5686 - val_accuracy: 0.7407\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4367 - accuracy: 0.8131 - val_loss: 0.5631 - val_accuracy: 0.7222\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.8037 - val_loss: 0.5663 - val_accuracy: 0.7407\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8037 - val_loss: 0.5766 - val_accuracy: 0.7407\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4695 - accuracy: 0.8037 - val_loss: 0.5882 - val_accuracy: 0.7222\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4345 - accuracy: 0.8084 - val_loss: 0.5888 - val_accuracy: 0.7037\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4624 - accuracy: 0.8131 - val_loss: 0.5788 - val_accuracy: 0.7037\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4706 - accuracy: 0.8131 - val_loss: 0.5602 - val_accuracy: 0.7222\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4596 - accuracy: 0.8178 - val_loss: 0.5552 - val_accuracy: 0.7222\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4740 - accuracy: 0.8178 - val_loss: 0.5531 - val_accuracy: 0.7037\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4721 - accuracy: 0.8224 - val_loss: 0.5543 - val_accuracy: 0.7222\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4723 - accuracy: 0.8178 - val_loss: 0.5552 - val_accuracy: 0.7222\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4713 - accuracy: 0.8178 - val_loss: 0.5564 - val_accuracy: 0.7222\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4630 - accuracy: 0.8224 - val_loss: 0.5615 - val_accuracy: 0.7222\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4373 - accuracy: 0.8318 - val_loss: 0.5647 - val_accuracy: 0.7037\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4676 - accuracy: 0.8318 - val_loss: 0.5664 - val_accuracy: 0.7037\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4562 - accuracy: 0.8271 - val_loss: 0.5644 - val_accuracy: 0.7222\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4651 - accuracy: 0.8318 - val_loss: 0.5625 - val_accuracy: 0.7222\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4515 - accuracy: 0.8271 - val_loss: 0.5641 - val_accuracy: 0.7407\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4355 - accuracy: 0.8318 - val_loss: 0.5673 - val_accuracy: 0.7407\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4507 - accuracy: 0.8318 - val_loss: 0.5706 - val_accuracy: 0.7407\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4658 - accuracy: 0.8318 - val_loss: 0.5695 - val_accuracy: 0.7407\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4468 - accuracy: 0.8271 - val_loss: 0.5677 - val_accuracy: 0.7407\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4275 - accuracy: 0.8224 - val_loss: 0.5693 - val_accuracy: 0.7407\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4388 - accuracy: 0.8271 - val_loss: 0.5698 - val_accuracy: 0.7407\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4464 - accuracy: 0.8318 - val_loss: 0.5733 - val_accuracy: 0.7407\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4634 - accuracy: 0.8224 - val_loss: 0.5670 - val_accuracy: 0.7407\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.8271 - val_loss: 0.5653 - val_accuracy: 0.7407\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4665 - accuracy: 0.8271 - val_loss: 0.5634 - val_accuracy: 0.7407\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4417 - accuracy: 0.8364 - val_loss: 0.5595 - val_accuracy: 0.7407\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4398 - accuracy: 0.8224 - val_loss: 0.5602 - val_accuracy: 0.7407\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4471 - accuracy: 0.8178 - val_loss: 0.5575 - val_accuracy: 0.7222\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4430 - accuracy: 0.8178 - val_loss: 0.5541 - val_accuracy: 0.7407\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.8364 - val_loss: 0.5611 - val_accuracy: 0.7407\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4521 - accuracy: 0.8271 - val_loss: 0.5702 - val_accuracy: 0.7407\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4470 - accuracy: 0.8318 - val_loss: 0.5708 - val_accuracy: 0.7222\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8364 - val_loss: 0.5652 - val_accuracy: 0.7222\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.8318 - val_loss: 0.5575 - val_accuracy: 0.7407\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4270 - accuracy: 0.8458 - val_loss: 0.5581 - val_accuracy: 0.7407\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4241 - accuracy: 0.8411 - val_loss: 0.5643 - val_accuracy: 0.7407\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8318 - val_loss: 0.5744 - val_accuracy: 0.7407\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4204 - accuracy: 0.8271 - val_loss: 0.5765 - val_accuracy: 0.7407\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8318 - val_loss: 0.5751 - val_accuracy: 0.7407\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4367 - accuracy: 0.8411 - val_loss: 0.5739 - val_accuracy: 0.7593\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4324 - accuracy: 0.8458 - val_loss: 0.5645 - val_accuracy: 0.7407\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4283 - accuracy: 0.8411 - val_loss: 0.5578 - val_accuracy: 0.7407\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8551 - val_loss: 0.5624 - val_accuracy: 0.7222\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8598 - val_loss: 0.5704 - val_accuracy: 0.7407\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.8505 - val_loss: 0.5688 - val_accuracy: 0.7222\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8551 - val_loss: 0.5658 - val_accuracy: 0.7407\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8551 - val_loss: 0.5691 - val_accuracy: 0.7407\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8598 - val_loss: 0.5671 - val_accuracy: 0.7222\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4256 - accuracy: 0.8598 - val_loss: 0.5678 - val_accuracy: 0.7593\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.8551 - val_loss: 0.5641 - val_accuracy: 0.7593\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4237 - accuracy: 0.8505 - val_loss: 0.5609 - val_accuracy: 0.7407\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4010 - accuracy: 0.8551 - val_loss: 0.5689 - val_accuracy: 0.7407\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8551 - val_loss: 0.5742 - val_accuracy: 0.7407\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.8505 - val_loss: 0.5811 - val_accuracy: 0.7407\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4320 - accuracy: 0.8458 - val_loss: 0.5711 - val_accuracy: 0.7407\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4216 - accuracy: 0.8598 - val_loss: 0.5627 - val_accuracy: 0.7407\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.8598 - val_loss: 0.5596 - val_accuracy: 0.7407\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4038 - accuracy: 0.8738 - val_loss: 0.5592 - val_accuracy: 0.7407\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3905 - accuracy: 0.8551 - val_loss: 0.5667 - val_accuracy: 0.7407\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4122 - accuracy: 0.8692 - val_loss: 0.5653 - val_accuracy: 0.7407\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3932 - accuracy: 0.8692 - val_loss: 0.5711 - val_accuracy: 0.7222\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3761 - accuracy: 0.8738 - val_loss: 0.5677 - val_accuracy: 0.7407\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4010 - accuracy: 0.8692 - val_loss: 0.5621 - val_accuracy: 0.7407\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3933 - accuracy: 0.8692 - val_loss: 0.5482 - val_accuracy: 0.7407\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8645 - val_loss: 0.5513 - val_accuracy: 0.7407\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3938 - accuracy: 0.8598 - val_loss: 0.5685 - val_accuracy: 0.7222\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4143 - accuracy: 0.8692 - val_loss: 0.5781 - val_accuracy: 0.7222\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.8645 - val_loss: 0.5745 - val_accuracy: 0.7407\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3625 - accuracy: 0.8692 - val_loss: 0.5800 - val_accuracy: 0.7407\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3936 - accuracy: 0.8645 - val_loss: 0.5779 - val_accuracy: 0.7407\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4034 - accuracy: 0.8645 - val_loss: 0.5627 - val_accuracy: 0.7407\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3805 - accuracy: 0.8692 - val_loss: 0.5572 - val_accuracy: 0.7407\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.8785 - val_loss: 0.5580 - val_accuracy: 0.7407\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8692 - val_loss: 0.5580 - val_accuracy: 0.7407\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3660 - accuracy: 0.8738 - val_loss: 0.5754 - val_accuracy: 0.7407\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.8645 - val_loss: 0.5863 - val_accuracy: 0.7407\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3741 - accuracy: 0.8692 - val_loss: 0.5819 - val_accuracy: 0.7407\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3784 - accuracy: 0.8738 - val_loss: 0.5712 - val_accuracy: 0.7407\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3801 - accuracy: 0.8692 - val_loss: 0.5669 - val_accuracy: 0.7407\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 0.8738 - val_loss: 0.5727 - val_accuracy: 0.7593\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3718 - accuracy: 0.8738 - val_loss: 0.5820 - val_accuracy: 0.7407\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3581 - accuracy: 0.8738 - val_loss: 0.5727 - val_accuracy: 0.7593\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3789 - accuracy: 0.8692 - val_loss: 0.5795 - val_accuracy: 0.7407\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8738 - val_loss: 0.5886 - val_accuracy: 0.7593\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 0.8738 - val_loss: 0.5647 - val_accuracy: 0.7407\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3580 - accuracy: 0.8832 - val_loss: 0.5579 - val_accuracy: 0.7407\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3762 - accuracy: 0.8551 - val_loss: 0.5642 - val_accuracy: 0.7407\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3511 - accuracy: 0.8738 - val_loss: 0.5783 - val_accuracy: 0.7407\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3509 - accuracy: 0.8832 - val_loss: 0.5796 - val_accuracy: 0.7407\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3579 - accuracy: 0.8738 - val_loss: 0.5783 - val_accuracy: 0.7407\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3501 - accuracy: 0.8832 - val_loss: 0.5666 - val_accuracy: 0.7407\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3390 - accuracy: 0.8879 - val_loss: 0.5624 - val_accuracy: 0.7407\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3504 - accuracy: 0.8738 - val_loss: 0.5727 - val_accuracy: 0.7407\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3252 - accuracy: 0.8879 - val_loss: 0.5817 - val_accuracy: 0.7407\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3356 - accuracy: 0.8738 - val_loss: 0.5920 - val_accuracy: 0.7407\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3434 - accuracy: 0.8879 - val_loss: 0.5894 - val_accuracy: 0.7407\n",
      "Epoch 106/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3352 - accuracy: 0.8692 - val_loss: 0.5720 - val_accuracy: 0.7407\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3246 - accuracy: 0.8785 - val_loss: 0.5725 - val_accuracy: 0.7407\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3234 - accuracy: 0.8925 - val_loss: 0.5839 - val_accuracy: 0.7407\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3407 - accuracy: 0.8832 - val_loss: 0.5783 - val_accuracy: 0.7593\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3341 - accuracy: 0.8879 - val_loss: 0.5735 - val_accuracy: 0.7593\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 0.8879 - val_loss: 0.5878 - val_accuracy: 0.7407\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.8879 - val_loss: 0.5852 - val_accuracy: 0.7778\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3354 - accuracy: 0.8972 - val_loss: 0.5767 - val_accuracy: 0.7407\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3097 - accuracy: 0.8879 - val_loss: 0.5775 - val_accuracy: 0.7593\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3111 - accuracy: 0.8785 - val_loss: 0.5949 - val_accuracy: 0.7593\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3539 - accuracy: 0.8925 - val_loss: 0.5885 - val_accuracy: 0.7778\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3210 - accuracy: 0.8832 - val_loss: 0.5841 - val_accuracy: 0.7407\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3068 - accuracy: 0.8925 - val_loss: 0.5794 - val_accuracy: 0.7407\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3145 - accuracy: 0.8925 - val_loss: 0.5788 - val_accuracy: 0.7407\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3390 - accuracy: 0.8785 - val_loss: 0.5792 - val_accuracy: 0.7593\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3282 - accuracy: 0.8925 - val_loss: 0.5886 - val_accuracy: 0.7593\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3208 - accuracy: 0.8785 - val_loss: 0.5693 - val_accuracy: 0.7778\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3192 - accuracy: 0.8925 - val_loss: 0.5728 - val_accuracy: 0.7593\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3303 - accuracy: 0.8925 - val_loss: 0.6009 - val_accuracy: 0.7593\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2921 - accuracy: 0.8925 - val_loss: 0.6089 - val_accuracy: 0.7593\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3137 - accuracy: 0.8925 - val_loss: 0.5935 - val_accuracy: 0.7593\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8972 - val_loss: 0.5742 - val_accuracy: 0.7593\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3048 - accuracy: 0.9019 - val_loss: 0.5690 - val_accuracy: 0.7593\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3187 - accuracy: 0.8925 - val_loss: 0.5846 - val_accuracy: 0.7593\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2872 - accuracy: 0.9019 - val_loss: 0.5877 - val_accuracy: 0.7778\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.9019 - val_loss: 0.5869 - val_accuracy: 0.7593\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2812 - accuracy: 0.9019 - val_loss: 0.5922 - val_accuracy: 0.7593\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3051 - accuracy: 0.8972 - val_loss: 0.6058 - val_accuracy: 0.7407\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2863 - accuracy: 0.9019 - val_loss: 0.5823 - val_accuracy: 0.7778\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3048 - accuracy: 0.8972 - val_loss: 0.5789 - val_accuracy: 0.7778\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2844 - accuracy: 0.9065 - val_loss: 0.5616 - val_accuracy: 0.7778\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2878 - accuracy: 0.8972 - val_loss: 0.5855 - val_accuracy: 0.7778\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.8972 - val_loss: 0.6276 - val_accuracy: 0.7778\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2826 - accuracy: 0.9065 - val_loss: 0.6211 - val_accuracy: 0.7778\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2846 - accuracy: 0.8972 - val_loss: 0.5909 - val_accuracy: 0.7593\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2801 - accuracy: 0.8972 - val_loss: 0.5765 - val_accuracy: 0.8148\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.9065 - val_loss: 0.5939 - val_accuracy: 0.7593\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2808 - accuracy: 0.9019 - val_loss: 0.6128 - val_accuracy: 0.7593\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2737 - accuracy: 0.9206 - val_loss: 0.6020 - val_accuracy: 0.7593\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2739 - accuracy: 0.9065 - val_loss: 0.6060 - val_accuracy: 0.8148\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2830 - accuracy: 0.9019 - val_loss: 0.6151 - val_accuracy: 0.7778\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2572 - accuracy: 0.9019 - val_loss: 0.6161 - val_accuracy: 0.7593\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.9065 - val_loss: 0.6308 - val_accuracy: 0.7778\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2829 - accuracy: 0.9019 - val_loss: 0.6398 - val_accuracy: 0.7778\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2656 - accuracy: 0.9065 - val_loss: 0.6243 - val_accuracy: 0.7593\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2612 - accuracy: 0.9019 - val_loss: 0.6029 - val_accuracy: 0.7778\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2472 - accuracy: 0.9112 - val_loss: 0.5991 - val_accuracy: 0.7963\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2839 - accuracy: 0.9065 - val_loss: 0.6104 - val_accuracy: 0.7778\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2700 - accuracy: 0.9065 - val_loss: 0.6385 - val_accuracy: 0.7593\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2690 - accuracy: 0.9159 - val_loss: 0.6217 - val_accuracy: 0.7778\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2683 - accuracy: 0.9112 - val_loss: 0.6155 - val_accuracy: 0.7778\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2484 - accuracy: 0.9112 - val_loss: 0.6208 - val_accuracy: 0.7593\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2618 - accuracy: 0.9159 - val_loss: 0.6406 - val_accuracy: 0.7407\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2711 - accuracy: 0.9206 - val_loss: 0.6011 - val_accuracy: 0.7778\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2401 - accuracy: 0.9252 - val_loss: 0.6154 - val_accuracy: 0.7778\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2613 - accuracy: 0.9065 - val_loss: 0.6730 - val_accuracy: 0.7593\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2596 - accuracy: 0.9112 - val_loss: 0.6490 - val_accuracy: 0.7593\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2489 - accuracy: 0.9159 - val_loss: 0.5928 - val_accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2586 - accuracy: 0.9206 - val_loss: 0.5882 - val_accuracy: 0.7963\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2397 - accuracy: 0.9112 - val_loss: 0.6091 - val_accuracy: 0.7778\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2471 - accuracy: 0.9159 - val_loss: 0.6249 - val_accuracy: 0.7963\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2478 - accuracy: 0.9112 - val_loss: 0.6456 - val_accuracy: 0.7963\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2553 - accuracy: 0.9065 - val_loss: 0.6352 - val_accuracy: 0.7963\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2450 - accuracy: 0.9112 - val_loss: 0.6175 - val_accuracy: 0.7593\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2403 - accuracy: 0.9159 - val_loss: 0.6162 - val_accuracy: 0.7593\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2407 - accuracy: 0.9206 - val_loss: 0.6292 - val_accuracy: 0.7778\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2362 - accuracy: 0.9159 - val_loss: 0.6362 - val_accuracy: 0.7963\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2153 - accuracy: 0.9206 - val_loss: 0.6460 - val_accuracy: 0.7778\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2381 - accuracy: 0.9252 - val_loss: 0.6673 - val_accuracy: 0.7593\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2456 - accuracy: 0.9206 - val_loss: 0.6015 - val_accuracy: 0.7778\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2404 - accuracy: 0.9112 - val_loss: 0.6045 - val_accuracy: 0.7593\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2264 - accuracy: 0.9206 - val_loss: 0.6540 - val_accuracy: 0.7593\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2395 - accuracy: 0.9206 - val_loss: 0.6471 - val_accuracy: 0.7778\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.8972 - val_loss: 0.6363 - val_accuracy: 0.7778\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2328 - accuracy: 0.9112 - val_loss: 0.6130 - val_accuracy: 0.7593\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2199 - accuracy: 0.9206 - val_loss: 0.6573 - val_accuracy: 0.7593\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2480 - accuracy: 0.9019 - val_loss: 0.6562 - val_accuracy: 0.7593\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.9112 - val_loss: 0.6708 - val_accuracy: 0.7963\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2346 - accuracy: 0.9159 - val_loss: 0.7090 - val_accuracy: 0.7963\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9159 - val_loss: 0.6914 - val_accuracy: 0.7593\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2358 - accuracy: 0.9252 - val_loss: 0.6556 - val_accuracy: 0.7407\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2287 - accuracy: 0.9206 - val_loss: 0.6254 - val_accuracy: 0.7778\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2174 - accuracy: 0.9346 - val_loss: 0.6680 - val_accuracy: 0.7963\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2317 - accuracy: 0.9206 - val_loss: 0.7040 - val_accuracy: 0.7778\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2190 - accuracy: 0.9299 - val_loss: 0.6815 - val_accuracy: 0.7593\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2115 - accuracy: 0.9346 - val_loss: 0.6557 - val_accuracy: 0.7407\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2124 - accuracy: 0.9299 - val_loss: 0.6451 - val_accuracy: 0.7407\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2073 - accuracy: 0.9299 - val_loss: 0.6602 - val_accuracy: 0.7407\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2213 - accuracy: 0.9252 - val_loss: 0.7074 - val_accuracy: 0.7593\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2181 - accuracy: 0.9299 - val_loss: 0.7332 - val_accuracy: 0.7963\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2063 - accuracy: 0.9112 - val_loss: 0.7260 - val_accuracy: 0.7963\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2224 - accuracy: 0.9159 - val_loss: 0.6837 - val_accuracy: 0.7778\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2006 - accuracy: 0.9252 - val_loss: 0.7248 - val_accuracy: 0.7407\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2307 - accuracy: 0.9252 - val_loss: 0.6885 - val_accuracy: 0.7593\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2070 - accuracy: 0.9252 - val_loss: 0.6750 - val_accuracy: 0.7778\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1989 - accuracy: 0.9252 - val_loss: 0.7017 - val_accuracy: 0.7593\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1970 - accuracy: 0.9299 - val_loss: 0.7120 - val_accuracy: 0.7407\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2063 - accuracy: 0.9252 - val_loss: 0.6835 - val_accuracy: 0.7593\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1977 - accuracy: 0.9299 - val_loss: 0.6860 - val_accuracy: 0.7963\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1921 - accuracy: 0.9252 - val_loss: 0.7440 - val_accuracy: 0.7407\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1841 - accuracy: 0.9393 - val_loss: 0.7509 - val_accuracy: 0.7222\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2015 - accuracy: 0.9346 - val_loss: 0.7112 - val_accuracy: 0.7222\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1950 - accuracy: 0.9346 - val_loss: 0.6896 - val_accuracy: 0.7778\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1791 - accuracy: 0.9439 - val_loss: 0.7550 - val_accuracy: 0.7593\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1978 - accuracy: 0.9252 - val_loss: 0.7393 - val_accuracy: 0.7407\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1831 - accuracy: 0.9346 - val_loss: 0.6763 - val_accuracy: 0.7778\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2039 - accuracy: 0.9393 - val_loss: 0.6952 - val_accuracy: 0.7778\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1810 - accuracy: 0.9346 - val_loss: 0.7682 - val_accuracy: 0.7778\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2014 - accuracy: 0.9299 - val_loss: 0.7534 - val_accuracy: 0.7963\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1957 - accuracy: 0.9299 - val_loss: 0.7267 - val_accuracy: 0.7963\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1889 - accuracy: 0.9299 - val_loss: 0.7554 - val_accuracy: 0.7407\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1811 - accuracy: 0.9439 - val_loss: 0.7696 - val_accuracy: 0.7407\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1757 - accuracy: 0.9393 - val_loss: 0.7070 - val_accuracy: 0.7963\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1894 - accuracy: 0.9299 - val_loss: 0.7012 - val_accuracy: 0.7963\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1801 - accuracy: 0.9346 - val_loss: 0.8283 - val_accuracy: 0.7222\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2243 - accuracy: 0.9159 - val_loss: 0.7657 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1856 - accuracy: 0.9346 - val_loss: 0.7337 - val_accuracy: 0.7963\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1841 - accuracy: 0.9439 - val_loss: 0.7511 - val_accuracy: 0.7222\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1899 - accuracy: 0.9252 - val_loss: 0.7722 - val_accuracy: 0.7222\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1872 - accuracy: 0.9346 - val_loss: 0.7073 - val_accuracy: 0.7778\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1719 - accuracy: 0.9393 - val_loss: 0.7672 - val_accuracy: 0.7222\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1814 - accuracy: 0.9346 - val_loss: 0.7822 - val_accuracy: 0.7778\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9299 - val_loss: 0.7562 - val_accuracy: 0.7778\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1878 - accuracy: 0.9299 - val_loss: 0.7508 - val_accuracy: 0.7593\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1721 - accuracy: 0.9439 - val_loss: 0.8510 - val_accuracy: 0.7593\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1875 - accuracy: 0.9393 - val_loss: 0.8710 - val_accuracy: 0.7593\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1784 - accuracy: 0.9299 - val_loss: 0.7867 - val_accuracy: 0.7407\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1722 - accuracy: 0.9439 - val_loss: 0.7446 - val_accuracy: 0.7407\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1746 - accuracy: 0.9393 - val_loss: 0.7564 - val_accuracy: 0.7222\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1713 - accuracy: 0.9533 - val_loss: 0.7874 - val_accuracy: 0.7407\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1653 - accuracy: 0.9439 - val_loss: 0.7941 - val_accuracy: 0.7593\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1686 - accuracy: 0.9346 - val_loss: 0.8224 - val_accuracy: 0.7407\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.9346 - val_loss: 0.8371 - val_accuracy: 0.7407\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1663 - accuracy: 0.9346 - val_loss: 0.7890 - val_accuracy: 0.7407\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1595 - accuracy: 0.9486 - val_loss: 0.7492 - val_accuracy: 0.7222\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1614 - accuracy: 0.9486 - val_loss: 0.8335 - val_accuracy: 0.7593\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1652 - accuracy: 0.9439 - val_loss: 0.8813 - val_accuracy: 0.7593\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1733 - accuracy: 0.9252 - val_loss: 0.8477 - val_accuracy: 0.7593\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1614 - accuracy: 0.9393 - val_loss: 0.8540 - val_accuracy: 0.7407\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1514 - accuracy: 0.9486 - val_loss: 0.8320 - val_accuracy: 0.7593\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1671 - accuracy: 0.9439 - val_loss: 0.8202 - val_accuracy: 0.7407\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1676 - accuracy: 0.9393 - val_loss: 0.8383 - val_accuracy: 0.7407\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 0.9346 - val_loss: 0.8534 - val_accuracy: 0.7222\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1663 - accuracy: 0.9486 - val_loss: 0.7706 - val_accuracy: 0.7222\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1761 - accuracy: 0.9439 - val_loss: 0.8033 - val_accuracy: 0.7407\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1509 - accuracy: 0.9486 - val_loss: 0.8678 - val_accuracy: 0.7593\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1472 - accuracy: 0.9579 - val_loss: 0.8193 - val_accuracy: 0.7407\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1736 - accuracy: 0.9346 - val_loss: 0.7834 - val_accuracy: 0.7407\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1534 - accuracy: 0.9533 - val_loss: 0.8164 - val_accuracy: 0.7593\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1589 - accuracy: 0.9486 - val_loss: 0.8662 - val_accuracy: 0.7593\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1459 - accuracy: 0.9486 - val_loss: 0.8536 - val_accuracy: 0.7593\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.9579 - val_loss: 0.8168 - val_accuracy: 0.7593\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1562 - accuracy: 0.9393 - val_loss: 0.8630 - val_accuracy: 0.7407\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1537 - accuracy: 0.9439 - val_loss: 0.7562 - val_accuracy: 0.7593\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1564 - accuracy: 0.9486 - val_loss: 0.7944 - val_accuracy: 0.7407\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1541 - accuracy: 0.9486 - val_loss: 0.8833 - val_accuracy: 0.7407\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1534 - accuracy: 0.9486 - val_loss: 0.8598 - val_accuracy: 0.7593\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1493 - accuracy: 0.9486 - val_loss: 0.8358 - val_accuracy: 0.7593\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1490 - accuracy: 0.9579 - val_loss: 0.8354 - val_accuracy: 0.7407\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1620 - accuracy: 0.9393 - val_loss: 0.8642 - val_accuracy: 0.7222\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1411 - accuracy: 0.9486 - val_loss: 0.9301 - val_accuracy: 0.7593\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 0.9393 - val_loss: 0.9007 - val_accuracy: 0.7407\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.9579 - val_loss: 0.8800 - val_accuracy: 0.7407\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1413 - accuracy: 0.9486 - val_loss: 0.9278 - val_accuracy: 0.7593\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1450 - accuracy: 0.9486 - val_loss: 0.9451 - val_accuracy: 0.7407\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1307 - accuracy: 0.9533 - val_loss: 0.9157 - val_accuracy: 0.7407\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1414 - accuracy: 0.9533 - val_loss: 0.8593 - val_accuracy: 0.7407\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1425 - accuracy: 0.9533 - val_loss: 0.9091 - val_accuracy: 0.7593\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1456 - accuracy: 0.9486 - val_loss: 0.9611 - val_accuracy: 0.7593\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1395 - accuracy: 0.9486 - val_loss: 0.8974 - val_accuracy: 0.7407\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.9533 - val_loss: 0.8133 - val_accuracy: 0.7593\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.9486 - val_loss: 0.8438 - val_accuracy: 0.7407\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1308 - accuracy: 0.9579 - val_loss: 0.9246 - val_accuracy: 0.7778\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9393 - val_loss: 0.9584 - val_accuracy: 0.7593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 0.9486 - val_loss: 0.8849 - val_accuracy: 0.7593\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.9579 - val_loss: 0.8720 - val_accuracy: 0.7593\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1374 - accuracy: 0.9439 - val_loss: 0.9504 - val_accuracy: 0.7593\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1290 - accuracy: 0.9533 - val_loss: 0.9909 - val_accuracy: 0.7593\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1280 - accuracy: 0.9533 - val_loss: 0.9582 - val_accuracy: 0.7593\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9533 - val_loss: 0.9137 - val_accuracy: 0.7593\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1234 - accuracy: 0.9579 - val_loss: 0.8994 - val_accuracy: 0.7593\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1209 - accuracy: 0.9533 - val_loss: 0.9408 - val_accuracy: 0.7593\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.9579 - val_loss: 0.9263 - val_accuracy: 0.7593\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1137 - accuracy: 0.9579 - val_loss: 0.9083 - val_accuracy: 0.7407\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1285 - accuracy: 0.9579 - val_loss: 0.9604 - val_accuracy: 0.7407\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1342 - accuracy: 0.9533 - val_loss: 0.9205 - val_accuracy: 0.7593\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1263 - accuracy: 0.9486 - val_loss: 0.9030 - val_accuracy: 0.7593\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1190 - accuracy: 0.9579 - val_loss: 0.9394 - val_accuracy: 0.7593\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.9839 - val_accuracy: 0.7593\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1236 - accuracy: 0.9533 - val_loss: 0.9534 - val_accuracy: 0.7407\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1254 - accuracy: 0.9533 - val_loss: 0.9731 - val_accuracy: 0.7407\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1225 - accuracy: 0.9579 - val_loss: 0.9953 - val_accuracy: 0.7593\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1139 - accuracy: 0.9579 - val_loss: 0.9856 - val_accuracy: 0.7407\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1187 - accuracy: 0.9579 - val_loss: 0.9936 - val_accuracy: 0.7407\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1224 - accuracy: 0.9533 - val_loss: 0.9499 - val_accuracy: 0.7593\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(input_shape))\n",
    "\n",
    "x = layers.Conv1D(16, 4, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "x = layers.Conv1D(16, 4, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.Conv1D(32, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(drop_out_rate)(x)\n",
    "output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(lr = lr),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "checkpointer = ModelCheckpoint(filepath=\"1d+cnn.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "history = model.fit(X_train, Y_train,\n",
    "                          epochs=300,\n",
    "                          batch_size=64,\n",
    "                          validation_data=(X_test, Y_test),\n",
    "                          verbose=1, \n",
    "                          callbacks=[checkpointer]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T14:56:17.270121Z",
     "start_time": "2020-09-26T14:56:16.961023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz4AAAFKCAYAAADc54omAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5xcZd3//9c5Z/rO9t1ssunZhDRKSIRICSI9IUAgaAIainDjbbsVuUHkByjdruj3RhEQBBQBQUKoggnSEjBAQjrpbVO2l5mdds71++NMObOzLWSXZJPP8/HwwZRzzpxBds6853Ndn0tTSimEEEIIIYQQ4hCmH+gTEEIIIYQQQoi+JsFHCCGEEEIIcciT4COEEEIIIYQ45EnwEUIIIYQQQhzyJPgIIYQQQgghDnkSfIQQQgghhBCHPAk+QvSir3/96zz77LNdbvPee+8xc+bMHj8uhBBCtBePxzn55JO5+uqrD/SpCNFvSPARQgghhOhnXnvtNcaNG8fKlSvZuHHjgT4dIfoF14E+ASEOlPfee49f/epXDBo0iM2bN+P3+7nmmmt47LHH2Lx5M2eddRY33XQTAE8++SSPPfYYuq5TVlbGLbfcwsiRI9mzZw833ngje/fupbKykrq6uvTxN27cyF133UVjYyOmaTJv3jwuvvjiHp1bS0sLt912G2vXrkXTNKZNm8b3v/99XC4Xv/3tb3nttddwu90UFxdzzz33MGDAgE4fF0IIceh54oknmDFjBsOGDePPf/4zt99+OwB///vfefjhh9F1neLiYn76058yaNCgDh/ftm0bd9xxBy+88AJgXxdT93/3u9+xbNky9u7dy9ixY7nxxhu59dZbqauro6amhsGDB/Ob3/yG0tJSNm/ezK233kp9fT26rvONb3yDiooKrrvuOhYuXIiu67S1tXHaaafx4osvUlJSciD/1YnDmRLiMLVkyRI1fvx4tWrVKqWUUldddZWaM2eOikajqq6uTk2cOFHt3r1bvfvuu+qMM85QdXV1SimlnnnmGTV9+nRlWZb65je/qX79618rpZTasmWLmjRpknrmmWdUPB5XM2bMUCtXrlRKKdXc3KymT5+uPvroI7VkyRJ17rnndng+qcdvuOEGdccddyjLslQ0GlVf+9rX1P3336+qq6vV5MmTVTQaVUop9dBDD6nXXnut08eFEEIcetavX68mTpyo6uvr1fLly9XRRx+t6uvr1Zo1a9TUqVNVdXW1Ukqphx9+WN1yyy2dPt7+euS8/9vf/ladffbZKh6PK6WUeuSRR9T999+vlFLKsix19dVXq4ceekgppdSsWbPU448/rpRSqrq6Wp1++umqpaVFnX/++eqNN95QSin19NNPq2uvvfYz+LcjROek4iMOa0OGDGHChAkADBs2jPz8fDweDyUlJeTl5dHU1MRbb73FjBkz0r9QXXTRRdx1113s2LGDd999lx/84AcADB8+nKlTpwKwZcsWtm3blq4YAUQiEVavXk1VVVW35/Xmm2/yxBNPoGkaHo+HuXPn8uc//5mrr76acePGceGFF3LKKadwyimncMIJJ2BZVoePCyGEOPQ88cQTfPGLX6S4uJji4mKGDBnCU089hcfj4eSTT2bQoEEAXHHFFQA8/PDDHT7+3nvvdfk6kyZNwuWyvypefvnlLF26lIcffpgtW7awfv16jjnmGBobG1m7di1f+tKXABg0aBCvv/46AF/5yld46qmn+MIXvsCTTz7JDTfc0Nv/KoTYJxJ8xGHN4/Fk3U99wDtZlpXzmFKKRCKBpmkopXL2N02T/Px85s+fn36utraW/Px8li1b1u15WZaFpmlZ9xOJBLqu8/jjj7NixQoWL17M3XffzbRp07jhhhs6fVwIIcShIxwOM3/+fDweD6eddhoAra2tPP7441x99dVZ145IJMLOnTsxDKPDx9tfw+LxeNZrBQKB9O2f//znfPzxx8yePZupU6eSSCRQSqWve87jb9q0icrKSs477zx+9atfsWTJEsLhMMcdd1zv/ssQYh9JcwMhujFt2jReeukl6uvrAXjmmWcoKipi+PDhTJs2jSeffBKA6urq9K9nI0eOxOfzpYPPrl27mDlzJitXruzRa5588sk8/vjjKKWIxWI89dRTnHjiiaxdu5aZM2dSVVXF17/+da644gpWrFjR6eNCCCEOLQsWLKCoqIi33nqLhQsXsnDhQl5//XXC4TAtLS0sXryYvXv3AvC3v/2Nn//850ydOrXDx0tKSqiurqaurg6lFC+++GKnr/v2229z+eWXM2vWLEpLS3n33XcxTZNgMMjEiRN57rnnAPt6d8kll9DS0oLf7+f888/npptuYu7cuX3/L0eIbkjFR4hunHTSSVxxxRVcfvnlWJZFSUkJ999/P7qu86Mf/Ygf/vCHTJ8+nYEDBzJu3DjAriTdd9993HXXXTz44IMkEgm++93vMmXKlG6HFgDcfPPN3HnnnZx33nnE43GmTZvGf//3f+PxeJg+fTqzZ88mEAjg8/m4+eabGTduXIePCyGEOLQ88cQTXHnllRiGkX6soKCAefPmsWjRIq6//vp0i+vy8nLuvvtuKioqOn187ty5zJ49m/Lyck499dROfzT71re+xc9+9jPuvfde3G43kydPZtu2bQD88pe/5LbbbuOxxx5D0zTuuusuysvLAXt4+FNPPcWsWbP68l+LED2iKWeNUwghhBBCiF6glOKBBx5g586d3HbbbQf6dISQio8QQgghhOh9p59+OgMGDOC+++470KciBCAVHyGEEEIIIcRhQJobCCGEEEIIIQ55EnyEEEIIIYQQhzwJPkIIIYQQQohDXr9pblBT07Jf+xcXB2hoCPfS2Rw85H31L/K++hd5X7nKy/N7+WwOHXKd6pi8r/5F3lf/Iu8rV1fXqcOm4uNyGd1v1A/J++pf5H31L/K+xGfpUP3/Rd5X/yLvq3+R97VvDpvgI4QQQgghhDh8SfARQgghhBBCHPIk+AghhBBCCCEOeRJ8hBBCCCGEEIc8CT5CCCGEEEKIQ54EHyGEEEIIIcQhr0+Dz/Lly5k3b17O4wsXLmT27NnMmTOHp556qi9PQQghhBBCCCH6Lvg88MAD3HzzzUSj0azH4/E499xzD3/605947LHHePLJJ6mpqemr0+hT0WiUBQue69G2L720gLff/ncfn5EQQgiRTa5VQghh67PgM2zYMH73u9/lPL5x40aGDRtGYWEhHo+HKVOmsHTp0r46jT5VX1/X44vJjBnncfLJX+jjMxJCCCGyybVKCCFsrr468Nlnn82OHTtyHm9tbSU/Pz99Py8vj9bW1m6PV1wc2O9VXMvL87vfaB/ce+9jbN26mWnTjuPEE08kHA5z11138dxzz7Fy5UpCoRBVVVXcc889/O53v6OsrIxRo0bxwAMP4Ha72bFjBzNmzOAb3/jGfp1Hb7+vg4W8r/5F3tdB6j+vQF4hjJkMaOD2AIfA+xI99uijf2LLFvta9bnPHU9bWxs33ngLr7zyImvXriYcDjNixEhuuulHPPTQ/ZSWljJs2Aj+8pdHcbtd7NpVzWmnncnll191oN+KEKKdLY3wxw+9XD4hRolPAaAUPLTSw7gSk5MHmzn7bGrSmb/RzVVHRinwQMyEP3zs4YtDExxVZnX5envCGn9Z4+HScTEGBBQPr/IwdWCCIx37vbXTYHOTzjHlJs+s92Ap8LsU/3WUfY4PrPBw6tAE40vsfZ7b4GbpHvs7/uCgxTVHxXrrX0+OPgs+nQkGg4RCofT9UCiUFYQ609AQ7vL5777h553q3n07J1UmuPfUtk6f//KX57Fq1RqmTj2BlpYWvve9/yUUasUwvPzsZ7/Fsizmzfsyq1dvJBSK4vNFaGwMs337Dh555Ani8TizZp3DxRd/9VOfY3l5PjU1LZ96/4OVvK/+Rd5X33Jv+xizaBBWQfk+7ac311D64v0AmHnFoGnUf/UXlA8s/tTvSwLTp9ez69S+/fvt7joFcNllX2Pjxg0516r8/Hx+85v70teqmpq9Wfvt2bMr61olwUeIg8/FT0NN2ENLDG79vD295N1dBn9Y4QVg6aW5n/XzXgkQNTWUgu9PibJgk5tH13h5dI23w+2dbnjLz6o6g01NOnPHxvj9x14W7zJ48Ez7c6gtATe/4yeU0Ai4FOGElt5X12BcicVDq7w8tMrLfy5pYXdY4673vSgy200oNbm4Yr//1XToMw8+VVVVbN26lcbGRgKBAEuXLuWqq/r/h+mwYcMB8Hp9NDQ08KMf3UQgEKCtrY1EIpG17ahRo3G5XLhcLrxe34E4XSFEP+Has5GiBb8AoOZbj+7bvnXb07eNUAMAems9UNxr5yf6F7lWCXFoqUnWBba3ZGavrG/oeoRU1LRDxvZWe5+6SCZ0WMoOKJ1ZVWcfe029wep6I+e1/7XNRSgZdsIJjSKvxX8dGePnH/h4ZasbRdxxLJ3Fu1woNI6vSFAZtHhuo4fnN7m5+Nju3vmn85kFnwULFhAOh5kzZw433ngjV111FUopZs+eTUXF/se67n7x6otfbjVNRym7TKcn/ytZsuQd9u7dw+2330NDQwNvvrkIpVS7/Xr1NIQQhzBX7bZ928Gy8G58n3jlOFx1ucON9bbmXjozsa8OxHUK5FolxMHokdUedoc0bvhctMug0ZV4u1Fs31zo56qJMXa2Zg4YjkPAndkmlMkdFHoyQ+NSdrRoPLTKy+o6O8xUFVnceWKEd6sNnvzEk96u1G+xriEVnHSuf8vHliad2rbs9gHnjkwwZ2ycl7a4WVVn8OLmzMl8/00/4bh9rpdPjDG60GLBJjdv73RR2/VAr0+tT4PPkCFD0u2qzzvvvPTjp512GqeddlpfvvRnori4mHg8kdW5bvz4iTzyyENcc80VeDweKisHU1vbP7vWCSEOAs4rUiIGLk/n2wK+tW+Rv+ghzIJy4hVVOc/r4abePkNxkJNrlRAHF0vBHz/2ELM0vjQmTlVR1/NqOrOpORMyPqqxv9K/v9vFhJJMIqqLaATcmeuIsxrUFLVDR62j4vPXdZ6scLK52eCc4Qnu/cibrhABGBqsq88ca9H2zD4lPouJJRZL9xpcNNqer3P+qDir6ox0tQmgPmIfb1ShyXEVJroGM0Ym+OdWF9EEdH21+3Q+86FuhxKv18sjj/w167HS0jIefDB3OMrRR09K3548+XPp288//2rfnaAQot9zVmiM1nrMooFdbu+uXmtv21yDctljvBsu/jG+lf/Cv/YtqfgchuRaJcTBpa5NI2bZAWBdg54VfBLJm64e9F1eW9/xRqsdgaS2TWdI0CSWPO4qxz6pIW7OKs3f19tx45KxMfwuxZ9Webn5XR8RM7sstb1Fz3nspMoE3z02yoCAhc+AiAnBZB46e3icX33oJWpqFHoUf58ZoiEZvCrzrHTV6/87PsL3J8Pggnz6YrUbCT5CCHEQc1Zo9Ja6boOPclSEjMZdKDQSJYNRgUL7GBJ8hBDigNoZygSNdQ0GM0ba8+v+vcPgxrf9WApumRph5qgEkQRc+c8AVYUWd54UAeDej7y8sd3FmOLcjm3t1bZp/M8bfhbvyv3Kv7re4PRn8miK5gaouWNj+Az482pPTsABOnxsUrnJqMJMiAs6Dhv0wOlDE7y0xc3YEpNin6LYp3KO4dIhvy9KPUl9to6PEEKI/aeHGzO3W+v2aV/NMu1OcG4vVqAgeTwZ6iaEEAfSLsccHGfV5u1qF3FLw1Qaf17tQSk7nKxvNHhlq5stTfa2j63xsL1VZ6FjeJmT18gEird2utKhx6MrPLqixJcJJ87Qk3p+VlWMwUFFqV8xd2wcr6EYlGfxv1MiVOZlD8sztMxrje0miF02IcawfIvzR8W73K4vScVHCCEOYs6gYrR0H3z0tuzJ8Ylyu4uX5beDjyYVHyGEyNEcs6dUFno732Z3SKPcrzDalQ3CcbuDWZk/t4IBsDesUeJTuHRoisInjZmhaJ80GChlNxOpdsyh2dxssLJOZ50jGM3f5OabR0ezjj2iELY4fs/66/QQRxRbPLjCwx9WeHl1q/1V/9KxMb4/JbPvaX8P0hzLrtos+lIr3nYN4a6dHOXayZn95o6Nc+lLgfR7OHaAydI99muMLe56rtLoIotnzwt1uU1fk4qPEEIcKEqB6vpCkTXUrQcVn/ZD2eLlIwCw/MmhbmEJPkII4WQpOOvZIOfND2J1nF34uEZn5vwgP12am4wufTmPc/4RpLmDdTfX1uvMeC7IHe/5iCTgSy/m8diazFiulrhGdcgOIKngM63SHvr28hY3ax3NCF7a7GJna/ZX90uPgjxH84LS5PCxVAgzlX3s86uyqyzOqk9K+9DTGWfAmzowU+Up7ST4HUwk+AghxAFS8MpvKf7bzWA5hgeYCVy7N4JlgVLoocxQt44qPp7NH1L07J3J9XlyKzrpik9qqJtUfIQQIsv2Fo2EpRFOaDRGO+4t/c+t9rCyZzd4slpCh+OwIxlGNjXlJod/77CrIS9utts5pzqZQWZI2roGA0vBrrD92ucmh4LtaNHTLaP9LkVdROfp9ZnhbecMj3PJkZDnygSO4nTwyQSbCSUmo9t1jmtLfPp+9amAY2iKS8bG+NKYGHee2HW7/oOFBB8hhDgQlMKz9WNc9Tuywk3eu3+j+JnbCHz4AlqsDc3MXGH1ltqcwxS+9Bvcuz4h790n7W3aB5+yEYCz4iNzfIQQAuA/uw1qwhrrGpxd0DRqwhpLdmWHGNNRzHh9W2amyPrGzFfplpg9ZO6NHa70SgTOgPGnVdmz9k9MVnbW1evUtNnhq8RnMThoh5TqkMbmJh1dU1w23i4nPbvBDj4zR8a586QIBd7sc0t1R3NWXy6oyp1T41y0dF+VJatFowotfC74wXFRzhmR6Gavg4MEn/0QjUZZsOC5fdpn2bIP2bBhfR+dkRCi30jE0qFGi2VWagt8/E8A/B+/mg4pli8IdF2t0cONYCbQo9mrvqlkpUf5gihNQ4+GwOwfFyjRO+RaJUSudQ0631gY4Lzn89JVFbBbTf/gbT/fXhRgcXUm/DiHmL221e04Tnbr6Hve9/G/b/p5bqO9zc5QJmC8tzt7av0XBtufxWsbjPQwt8o8RVmyarOl2cBUGsPyLS4aHcfQFPFkG+zKoLMFdm6IqQgoNBReQ3H28Nzgc1xFdiOCwcGeryVUkWef3/iS7rvKHWwk+OyH+vq6fb6YvPji87JInBACPZJpQqBFc5eotjyBdEc3s3gQSjfQY232IqYd0KxEVjCyvHmEJ013vKCO8uXbt0My3O1wItcqIXKluqklLI35GzNB5r3dLj6utcPMPxyPVzsCzJoGPV3RcYam9Y06C7fb4eYfycrMrtbcr9pHl5n8Ylobx5Sb6WPsbM0EmmKfHVpShuVblPoV0wZnfrRydldLdJBZSnyKO06M8MtT2gh20B761qkRrjkqygsXtPL1o6L87tTc61Bnzhke5+tHRbnqyI6vRwcz6eq2Hx599E9s2bKZP/3pj2zatIGmJvvX2e9973qqqkZz110/ZufOHcRiMS655KsMHjyU995bzCefrGXEiFEMHNj1ehxCiEOIUvhWv0G8ogqzbBh6pDX9lB7LveAobx5a1O5+Y3mDWP4CjFADelszVn5Z7vFNMx18EqVDaZh7V84mscHj8exci+7Lg2j/u2CJT0euVeJQsbFR5/VtLi6fECOh4LHVHmaNjjMob98n1dc4Fu1sdLR0fnxtJiW8udNFQ0SjyKvYlVx7x60rmqI6f1zhYdIAk3WOxUKf+iSz7+p6gw2NOtWO/VLVmkvHxTh1aAJL2fNzatt0nkzuOzjPwqXbc3Xqk8PRBgft93f+qDhv7HBnPQaQ6OTtdzX8rDyguOYo+zrwX0ft2/Ug6Nn3fQ4Wh0zwKXjhl3i3Lu9ym/J9PGZ0+DE0z7yu0+cvu+xrbNy4gUgkwpQpx3PhhRezffs27r77Nn75y9/y4YdLefDBx9A0jfffX8K4ceOZOvUETj/9LLmQCHGY8X6ymPw3Hgag5luPojmCjxZNTgpVmauX8vjR4tH0bWfwQdPRomHMksGZY5gJtGTHNiu5WGl7LWd9EyyTco8X6J8Xrf7sQFynQK5V4tBx/woPC7e7GV5g8UmDzqNrvKxv1PnVFyL7fKzq1q7nuAwOWuxs1Xlpi4uzhyeImhqFHsXYEpP3d7t4YKXd3c25Zk77ff+y1kNzTMNnKI6rMHmr2pV+Huz5OEeVmSzZ7WJNMkBVJZsQlPoU9cm3larunFhpUhGwqI9oDC/IlHkurIrzt088nHcA18fpLw6Z4HMgbdq0gQ8/XMq//mWPzW9paSEQyOPaa2/gZz+7i3A4xFlnTe/mKEKIQ5l75+qs+871dlJzfJxhyH7cDkTK7UvP1dHDLRS+8Cv0tmbq59yZdYxUxSe1Zk8OTQNDPvYPV3KtEv3djha7erKlWefFzXbl451qF7Vtna+h05lUBefyCVGGBBV7whoPOsLMdyZFufFtP/M3ujmq1B6SVhm0GFts8f7uzHGiZm6Aun5KhO/9O8CCTe70fuNKMsHHOUztR5+P8M4uuxlCvkdx6hC7SlPmV6xP9r1Jzedx6fDHM8I0Re11gVK+c2yUqYMSOfN2RK5D5grY3S9e5eX51NS0dLnNvtI0HaUshg8fwVlnTeCss86hoaGeBQueo7a2lnXr1nDPPb8gGo0ye/a5nH32DDRNQ3WzbocQ4tBjODuyxaNZISfVkMBwrNOjxSNocfvnPuX2OhYgbUoHHN8nizPHCDWihxqALoKPOKAOxHUK5FolDg1Kwc5kWHl6vZum5PA0U2mc848gt53Qxqo6g+H5FnPG5lY+VuyBe970M298jL+s9fCf5KKb542KM6JAsXSPwYMr7W1HF1l8YXCCYq/FpiaDm9/1A3ZgqSrMDReGptLr5ZT6LE6qNBlTZLI+uchnZZ5KNwQAKHDMuSkPKGZ10HXNGeQqHfsODqqsYW5gr78zbbCEnp44ZILPgVBcXEw8niAcDrNo0Ws8//yzhMMhvva1aygtLaW+vo4rr7wUvz/A3LlfxeVyMWHCkfzhD/+PQYMGM2LEyAP9FoQQfSUexV29jviQCaDpuPZuTj9lNNdkzfFJVXxSa/HYj7Vlgo/HT+orqKtxT3obz5YPM9tbCVz1OwGwgsW9/nZE/yXXKnEoaI5BKG6Hi1ToOb4iwfvJAPOjxf70th0Fn3vesatDS3YZ6ZACpOcHlTkqKGOLTdwGXDQ6zkOrvOl5OkeVmRw/0MTvUlltqo8ottJD1cYWW2gafPmIOHe9bz92ZJnJyZUJDE3x+UEmWg86STsXGK3ch45romsSfPaD1+vlkUf+2unz119/U85js2bNZtas2X15WkKIg0D+vx/Bt+4dQlPOIzrm83ZHtiQ7+Di7utnPZQWfeAQtlqn4KMMeMmHUbUtv42rYlfWarho7XFl5Jb38bkR/JtcqcShIhQ+nyybEuOn4CJe8nJcVRKKmXQVJ2dmq8c52+7Yz9EBmO+eCn+NK7NvXHBXjjGEJ4pa93ahCO9S8cEEr17/l58O99tfoIcFM8EnN35lVFWdSuYmpoCq53+uzW/HkrnHaIedZ5rk73UzsIwk+QgjRB3zr3gEgsPxVzNKhWc8ZzXuzmxvE7O5tWUPdYm2Z5gZuHyo5N8dVt73T10wFIVMqPkKIPnT7Ei/bWnT+cHobrn1cGOW+5R4WbXfx+9Pbejwv57cfeXh0jTfn8XHFFkU+xdePivKbj3zpx+vaNB5Z7Um3lFZ0X2Jxhovh+XZ4MXQYU5xbbSn0ktVJzvk+KgL2bU2DkYXZ++Z30FZafLZkHR8hhOgDqQutloihtVt4VG831C1VDUp1ZQPQYpHs5gbJeTuGoyrUGStPgo8Qom9sadJ5fpOHZTUutrfs29fIpig8vsbD5mYjvcBnd5Siw9ADUJQcnjZzZIKRBZk5LnvDdvMDezUc+7M46IH/mRShyGvx3WMjDM6z+N8pmW5wmmavT3NEscnRZd3Pl3FWiEr9isvGR6nMs5g1unc6Zn75iDjlfotvT4r2yvGETSo+QgjRB5QviJYczqa32SEnUTIYV/1OjOaadu2sk3N84o6LMAq9zV5vRXl8+9SwQIKPEKIzTVG7urGvlZqU+ZsygaW2TWNkoR1OGqMaxb6OKzjh5JSbV7a4iSXXslmw0c3XJsbY3qKhAUPzFZoGjRGNoEelz29XqONqTcCVea0in+LpmWGu/beft3a6WLrXIGpqVOZZPHe+XVEfUJ5PbW2cyybYJzNvfO48oDtPiqAUPZqDU+p4r2U+iysmJPjOpFiP9u2JAQHFS7NCvXY8YZOKjxBC9AHLl5e+nerCFh8wCrA7vHXU3CA1tC29X8juZarc/py1eaLDj0nfjldUZV7Xny8tq4UQHaqPaJz+TD7XvB74VPsnLHhpc+bzpbbN/lb+2Bo3Zz4b5J3q3AkskQTMfSmPr7ycl67yGJpiZ0jnlnd9zH4hyEUvBHlmg5vtLRpnPBvklnczw9bWNnQ8KWZcSW5VpizZEODdZNvosSUmumavl9PTANHT7ZzD21K3ezukSOjpfRJ8hBCijxkNdrc1s2QIAFpbS4cVHy2evQifkWxPnWpnnWpwABAbdnT6dnzw+PRtKyDVHiFExz7aa4eIj2t7OMO+nXeqDeoima+OdRGNhAVPrLMnr7y9M/dHlzd2uKgO6Wxv1VnfaFDoUZw70q62vLo185m2rl5nfjIYvbYt+3GAwXkWpw+Nc//pYaZVJrjjxNxFS1MBJPX+xnYwP6e3dBR8xMFPgo8QQvQBPZrp4ubeswkAs2ig/VykJWtYW7rjW7vgoyXsseLK4wPDRXzgmPRzVkF5+raZX5bZKSHjwYUQHbMc389bejgV5cO9Bs3JbVPBpDw5v6W2TWfJLoOaNvvr5LoGg8XVBpFEZv/n283lOWdEnKPKcgNJY0zLClUAGxp1Hlplz+/59qQoP50WYUqFya9PbUs3EXAqbRdAxhX33do2pY5206WdDPETBx8JPkII0QdSw9cANNP+ddPML0XpLjTLvhhb/kKUptsBx0ygJ9tXm+3m6Ci3Pd1dYWMAACAASURBVOwjNnRi+jErUEjTudcSOeJEImNPSj9utNQhhBAdqYtkxk511B66vQ/3GlzzeoBrXg9Q26bxTrULQ1NcMtZOQrVtWtacn49rDb7zRoBffWiHlepWjff3uPDoCpduh4Pzq+IdDlNrimrsaMmcX22bxlWvZYbkje9gn/bK2gWQvqz4lPsVuqbwGopCrwSf/kIGggshRG8zE+mw46T8+Vi+PIyw3bTA8gfRrQRaNIQWC6fn+Fh5RelhbpAJPvGhR8KSp+1tAoUkBowkNuJYAFq+cDn5//4zrV+4vE/fmhCi/0rNyQGobtW7DQZv77SHjG1oNHhwpQdTaXxhSJwjkvttaNLZ3KSja4p8NzTF7OO/vMXN946NsiAZik4bmuCLQxM0xzTGFlvETHuej6k0Ai5FOKHRENHYG86Esb+tc6cXLL1ucoQh+d2Hi1JHp7UJJSblHVSFekvADTcdF8XnUugyF6ffkOAjhBC9zFntcbJ8+ShvHqSCjy+IlohDNIQeDafn+FiBoqz9lNv+9TRRPhzLm4dyeXKaHUQmnkZs+CSsoCxeKoTomHMo2c7Wjr+t17fBI6s9XDwmxs7WzPZ/X2/P47lgVDw9p2VDox2MTq5MsLZBJ7XsZltC459b3TyfDD4XVMU5bmCmYuNJLga6vtFg6sAEi3a42dycPe/okdX2596PP9/GzFEJesI51+b8qtwfn3rbrNF9/xqid0nwEUKIXqY55vekWJ4AGC6Uo9ub8gVRyW21WBtacn6OM/golxe05JcPTad+3i/t23q7ycmahpVf2ovvQghxqMmq+HQy1O22f8Nz67x8sMfIWaen3G9xYqVJayw7NF1QFWd8g84DK734DEXE1Pjdcg9NUZ3BeRZTKnKHqU0qN1nfaHDKEDv4dMTvUpw+rGehB7Ln2pw9XEKJyCXBRwghepmerPgkiitxNVQDoFz2r6WWNxN8LF9+utW1nly8VLm8djOD1DaO2wDK++na0AohRF27oW4d+ddm+5+Ld9lfET264vYTI9SENY4baOLSocCr0kPVir0WJ1cmOLESqoosjqtIcN78IE1R+/jnjYp3OBTsm8dEmTrQ5JQhCX6xVBFK5G40vsTEvw/fVD0GPHZOCEODfE/P9xOHDwk+Qgixn7S2FjQrkV44VEt2abP8BZAMPnpyeJvytqv4JOfv6OHUmj0+lMef2cadHXyEEKIzr29z8eFeg+9PjrK1WedPqzxcO9meh/LT//j4pDFTKa5OLgz6/EYXaxsMThyU4NWt7pxub1VFFme0q7romj2sbE9Y49yRCdzJw6a2O3N4nPkbPWgoZo7quPKS74FTh9rbF3ozwafAo2hOVpQ+TXOC8SV919BA9H8SfIQQhxW9tZ7A0ucJT5qOVVTRK8cseuZ29GiIust/Ay5POvgojx/L40ePtaFhD8FoX/FRLnscezoYJdfsSZHgI4Toqd9+5KU6pHPK4AQvbXbz6lY3Q/MtfC674UCKhmJLs92Y4KdLfURNjWc3uElYuVWXz3UwTA3s5gGNUY1Zo3P7Yl88Js4Lm9x8YUiCgXndNxgo8iqqQ/bto8pM3kktQNqH7ajF4UmCjxDisJK/8EE821fi3rGKhq/+fP8PqBRG0140FEbjbsyyYenmBsobIDbsaHwb3kuvtaN8wfSuli+YblygJYe8WR4fsaFHZo5vyMd0X7Esix//+MesW7cOj8fDnXfeyfDhw9PPP/fcczz00EPk5+dz4YUX8qUvfekAnq0QXWuOZebtrGswWNeQvF1vUBbIroJ8cWiChdvd/M8bfqKmHXacoeeEQQm+dUyUuNV5BeWOEyO0xLQOO6eNL7GYf36Ioh62eXZu5ww+46R6I3qZXFGFEIcVV+02+59Ne3rngGY8Xc1xNVRjlg1LL16qPH5Cx1+E5S8gMvGLAFiOOTpZQ91C9lA33D6swgE55yt63+uvv04sFuPJJ59k2bJl/OQnP+H3v/89APX19dx777384x//oKCggCuuuIITTjiBIUOGHOCzFoer1XU6N7/r5/IJUR5Z5aU2uSbPOcPjhBMab+zIfKVbUauzpTkVgnQao9mVnPNHxVm43c2uThocBN2q29Dhc4HP1Xmw6UmlJ8W5Do6zyjOiQIKP6F2ygKkQol/T2popePHXuLev7NH2qSYDvfb6ybV3AIx6ez5PquJjeQIoX5DQKfMwS+0vzMrrqPj4nXN8UkPd7PuJEnv7jtYDEr3jgw8+YNq0aQBMmjSJlSsz/w3t2LGDcePGUVRUhK7rHHXUUSxfvvxAnaoQ/GmVh20tOvf8x8f2Vp22hEZbQuMfGz28utWdrtwAvLHDjans+3vbdFbU2ZNw/C7FVROjnDDIZFwyYAzLt7hodIwyv8XVR0YJeuDyCbnD1/qScmSk4ypMKvMspo+I45JvqaKXScVHCNGvBd98FO+Wj/Bu+Yiabz3a7fbK6Lhtanu+Fa/DxsVo079vNyQwE3g3vk90xGRwdFrLCj4NqeCTqfjkvH5Oc4PkHJ+2zBwfgKZzr6Xgn/cRnnJej85X7LvW1laCwUwQNQyDRCKBy+Vi+PDhbNiwgdraWvLy8li8eDEjRozo8njFxQFcLqPLbbpTXp6/X/sfrOR92V/uo6ZdKdlXNSF42/54SQ9Ju+4E2FAP89f17BhD8uGdr2mAF/DyyjwIx8Hv1tG11A9CXm45HSCv0+P0hbgj4AwdlM87V4Gu6UDPPq97Sv477F/64n1J8BFC9Gvu6h5e9VOc69+YcegkCOW/aYco38qFtE05D//HrxF89wniA0fTeNEt+FYtIlE+Ih1UAFwNO4FMxaej4GP5nM0NHMGnXcXHKiin8eIf7dt7E/skGAwSCoXS9y3LwuWyL4uFhYX88Ic/5Dvf+Q4DBw5k4sSJFBcXd3m8hoaOF67tqfLyfGpqWvbrGAcjeV+2R1e7+b/lXh46M8yRZfs2hOvR1W4SVnajk5G+MGOGwPx12S3uvYZKV3+ct0cXxqmpieQcu/1/tQfi/y+35SMVcvrqteW/w/5lf95XV4FJgo8Qol8zkoGhp7Ro5ouu3tqQNZ+mI3qyeuOuXmP/c/cG3NtWkP/vRwBouPjHmXNp3A2WmQ4xlj/3wzdV8VGahvLkZYa6papEjiAl+tbkyZNZtGgRM2bMYNmyZRxxxBHp5xKJBMuXL+cvf/kLiUSCK6+8kmuvvfYAnq3o7xZtt4efvbXTxZFlPR9KphQ8v8kOBR5dEUtWfMYVWxR4FRdUxchz2WvrbG3WOa4iwZ/XeAi64cqJMf64wkPCsjutHay+NSnK3jbtMx9iJw4/EnyEEP2XmVlbIlHYg9bUSqG3ZX5BMlrrug0+WPY4+NQaPQC+tW+lb2uJzFA3zTIxmvZiNNXYp9fBOVmBApRuYAUKQddzgo5y51aJRN8488wzeeedd5g7dy5KKe6++24WLFhAOBxmzpw5uN1uLrroIrxeL1deeSUlJSUH+pRFP7GzVcPQMhP8TQs+acx0XFMKVtXpjCm2WFevs7dNZ1K5SVvCDjoBNyyrsbfb26axpdmg1GdxYqXJgk1uKgIWRT772LdMjea8/vlVmc/GU4ckcp4/2AzKU/zxjLYDfRriMCDBRwjRb7nqd+zT9lo8gmZlvgQUPXcPrSd8mbbJMwHIe+tx0DRCJ38ls1My+OiR1vRDvg3vZR3TyajfgdG81961oDznHJQ3j6YZ16bbWqfW8Uk/LxWfz4yu69x+++1Zj1VVVaVvf/vb3+bb3/72Z31aop+LmXDB8/bf9/uXtKBrsLVFTw85W9eg88oWF7cs9lNVaLKxyR5+O7HUZGer3SNyWFClGxKknDsyzuCgYsEmN+NKZH0bIT4NCT5CiH7LcLR6djYZ6IzWljteOLj4Kdomz0RvriXw8T8BCB0/O7NPsqKjOYJP1jHbva5n5xo0M24vTtrBHB+A+PCj07fbL1AqC5YK0b/tCmW6q21v0RheoFhXn5m9X9Om88BK+weOVOgBWOUIOiuSHyunDY2ja5DnVswbH8fvUuxs1Th35MFfxRHiYCTBRwjRbzmrMO0rLx1u30HwAcCycO9ck75rhBtyXkPvJvgo3UCzTDxblgFgdjeELik3+EjFR4iDXWNE48XlcFIpvLzZzRnDEvx7p4spA0x2O4LPk594CLgUy2qyqzfOcNSZoFvxs2m5n2v/c6zMgxHi05LgI4Tot7REzHE7ag+O1zr/QqFHmgGIV1SRKBmMf82bABhNe/DsXJ3ZrtURfJJhqaNqEQDJilCiZAju2q0YLbUAmB0Mc+tI7hwfqfgIcbC77NUA1SGozMujOqTz4CqLpqhd1bnxuExYeeqT7HXDRhSYbGk2iFvdB5/KoCzeKURvk6WhhBD9VlbwUcpuT91+m2gYvXGPfbvNrtqYRQNpPe1qosOPAcCo255V8dFDmeCjRVrspgiRjoOPHrWbwSYGjMx63CzoacUnO/hYeYU92k8IcWA0RDSqQ/bXp9Q/U6EHoLo1O9QMy7f41jFRbp3axmXjO67WTB2YO3RtcJ4EHyF6m1R8hBD9VyL7S4QWj6Bc2b+wFv39x7gad1P31V+gt9kVH8tnt5k2S4fA1uV4ty7HaK1P76M7b7e1JpsimCiXF8vjy2qhnaoEWcESzEBh+rlPO9TNzO9ZpUgI0ffu/9hDqV9x8Zg4b2x3sapOp9CrutxnVyj7N+U5R8SYM9b+UeaThtzfm4cGLcYUWby3O/vxymDXryOE2HcSfIQQ/ZazlTTY822Uo5+AFmvD1Wh/m3Dv3Zyep5NaXydRMhTIbk8NYGRVfFrRws3p/SxfMCv4pCpByuUlNmIy/tWLUJpGYuDoHr0HZ8VH6UZW22whxIGzpSnThODiMXF+/oGXPWGdAk/XgWRLcybcuHXFOSMylehRhRZuXWUNdZs6KNHhsLZBUvERotdJ8BFCHFwSMQpe/T+io6YQHX9Kl5tq8fYVn+wg5K5el7ljJdBSi4Qmu60lKrKHp6U45/hoKFxNdniyfEE7mNRsyWybDFPK7aX11CsIH3cBynCh/AVdnnua4c6cYqAIdBmBLMTBYGNT5m+xtk1jT9i+3xzren7O+ka7kcFfp4co8ioKHaNZXTqMLrJYU29wXEWCG4+LUBFQLN1j5BxnsMzxEaLXyRVWCHFQ8a5fgnfLRxQsfLDbbbUOhro5uXesSt/W21rSFaJUlcUsGkSiuDK9jeUN2Ns6Kj4ARsMuez9fEOXLy37N5FA35faCpmEFS3oeeiCrGUOqEiWE6D0JC65/y8f/W+bpfmMH57C09sGk0GsRcLffI8OjK0YXWQwI5FaHxhbba/BUBi2GFyh8LhicHNamawpds29X5slQNyF6mwQfIcRBRTN7vj5F7lC3dsFn59rMc5GW9PPOeTWxkZPTt+ODxwMdBZ9qwJ4bpPTsQnlmqNu+fanqyD4FJiFEj6xv1Fm03c3jaz3E92Hdz3UNmbDzn3bBZ2yxxZAu/lyH5FvonRSGzhyewKUrplVmTmZI0GJI0OJzFSbHV5gMzrMYmi8VHyF6mwx1E0IcVJTRxc+o7aQqPpYngB4LZw91UxauZGCBZMUnnl3xAYiOPp7Ahy9geQKY+WVA9hwfIH0cy5+PZmV/c9KdFZ/9JBUfIToWNcHryB5mMhMYPfj5dm29vWPC0ljfqDO+xELT7O73prKHnzVGNGKWfbvEp2hLwOJdmRdcujv769LYYovqCHxS1/Frji3uPLRMHWiyZG72umBuA/4+M5QOS1byvIQQvUuCjxDi4GI4Ppa6WZcn1dXN8ufnBB891IjmaG+tR5zBJ1PxSZSPoHHWTVh5RXjXvZ19fN0Ay8So227v5wsSLxuGf+W/0pukXkO5eiH4+IL7fQwhDjVbmzUufTmPS8fF+NYxMUzLXkcnZsJfp4dx506PybLOMWTtslfzGJZv8eSMEPd97OXpT9ycNyrO0+szFdsLq2I8v8mNqTKfPTuTndo8uiJmaYwtNjFC9nN5LkUokf05lRrOti+cQaezapEQYv/I7wlCiIOLcoxrb9esoL1UxUcF7DEnzqFuRvPerG3tik9yqFu7kBIfPA6zaGDu4qHldtc3PdkUwQyWEhtxLI0z/5d4RVX2tvtR8TGDJQDERhz7qY8hxKHq4VVeoqbGw6vsv7H3dhusazDY3Gzw5s7uf79dV5+djLa16Hxca/D0J24ippYOPcVeu0rzj42erNDj9D/HRjm+IsHJlQnOOwLGFZvc8vkIE0pMPleRGaY7rkSGqQlxMOqz4GNZFrfeeitz5sxh3rx5bN26Nev5559/ngsvvJDZs2fz17/+ta9OQwjRz2RVaWLhrrdNVXx8yeDjmPOjN9nBJ142zH6uk4qPU87jA4Zl3bXyS0HTiA8/Oj0sLrPvpw8+DV+6jcZZPyQ+ZMKnPoYQh6qoo3iypUnnrvczf6c/+Y+X9cmKTty0qztKweo6nYRlD4n7pDH3q87/LfcSMTPhpsxv8fKFIUYUZF7swTPDzKrKNFDJcynmjo1z3+ltBD3wuUp4fHqYM4YlePScMBePyXx2fZqKjxCi7/VZ8Hn99deJxWI8+eSTXHfddfzkJz/Jev5nP/sZDz/8ME888QQPP/wwTU1NnRxJCHFYcQQfLdpd8LGDTGpujHOom5EMPokKez2dzub4OOU8Xj4k666VrMwA0K6Zwf4MdVOBwnRjBSFENmfwueTlAHvCOrqmcOmKhqjOV14JsLFR58+rPXzl5Tz+63U/l72ax/8t97K+USdqajlr73xca1eBvIb9+MyRcVw6nD/K/vwZXmByTJlJvuPPvNTfdZe1oDvzfP7+9zoRQvSBPpvj88EHHzBt2jQAJk2axMqVK7OeHzt2LC0tLbhcLpRSaF2N4xdCHDacFR+tu4pPPDXHp/OhbokBI2EVaJFQZv5Qp8GnXcWnYkTWXdMRfNp3ceuN5gZCiFyN0cxvtKmFP6+bHMXrgjvf82Epjec2unlinf03uazG/jufv9FNOPlxctbwOCMKLD7YY7Boh91AJc+luPfUNl7c4mLeePuz5OIxcXaFdM4cnkDTssNMmb/r4WvHVZhcMjbGlAFS7RHiYNVnwae1tZVgMDNR1zAMEokELpf9kmPGjGH27Nn4/X7OPPNMCgq6buNaXBzA5epmBmM3yssPzY5J8r76F3lf3fBmvuQU+xR0dlyl0s0N8srtYWcBwyKQ2j5UC0D+yCpYHESLtKarSWWDSu3GBe01FTvuaDDkiMzdvELKB5Vm7udnNyIoG1SW3ZjhIHeo/ncoDj3VoewfRqePiDNnrP23PLbYZN4reby0xYVbV+lgBPZCo89ssMPQBVVxxpdYnDM8kQ4+Z42IM2mAySRHUAm44QfHZSrHzkpRqa/rio+hw3VTup6XKIQ4sPrsKh0MBgmFQun7lmWlQ8/atWt54403+Ne//kUgEOD666/n5ZdfZvr06Z0er6Gh619+u1Nenk9NTct+HeNgJO+rf5H31b1Ac4jUEqHNe+uIFndy3ESMchRKd9ESMygAIi0ttNS0oMXaKKnZgQ7UWkGKfEFcEbt9rHJ5qK3r+PPEFbZIRR8zUIgRKMBy+9DjEeJ5JTQ63mMgrtLnqXQXtfVt+/vWPzP78/+XBCbxWYqaUNuWPSq/Mi9TeRlXbDGmyGR9Y/YPGeV+i5rkfmOKTMYl20sX+RSDgxY7W3UuGBWnO/keZ8VHFhQVor/rs+AzefJkFi1axIwZM1i2bBlHHJH55TQ/Px+fz4fX68UwDEpKSmhubu6rUxFC9CM9HeqW7ujm9qSHmaXm8ASWPm+HlYFjUIFClC8f2J3cvvMhac55OlZ+KYamYeUVozfuwgqWZm9sZIa6WQFZeFSIvrArlDsMflAwE0A0za7m/OIDO/hMKk9w5rAE54yI88JmN60xLT1sLeWnJ7exO6RzZFn3ndecQ926m+MjhDj49VnwOfPMM3nnnXeYO3cuSinuvvtuFixYQDgcZs6cOcyZM4dLL70Ut9vNsGHDuPDCC/vqVIQQ/Ymzq1sXzQ3SwcflTc/N0eIRMOP4P/4nAK0nfwU0LT0HCDrv6Nb+OTNYihuwgsXQuCtrfo+9rTP4FPXgjQlx+GqMwoMrvFw8Js6IQgul4IGVHtY36EypMJk7Nrf6UhPW+Ma/AjmPD87LDiznjIhz70de4pbG5AFmehjcV8Z1XNEZV2L1uN20c6hbmU9aVAvR3/VZ8NF1ndtvvz3rsaqqzLoXl1xyCZdccklfvbwQop/SEl1XfLzrl+Bf9gqhE+cC9tA15bMHnWmRVoyWOjQzjplfRqJiFABWXmF6/66DT3bFBzKd3FL309s6Kz55xQghOnfLu34W73KxrMbg8elhltcY/HGF/fe2aIebkysTDMnPrqg8v8mdHq7mVBnMDiBFXjhreIIXN7uZUtG7jQWc3dlkqJsQ/Z8sYCqEOKhoZmbdjI7aWRf88z7cezcR+M8/7AdcHqyAHWz0cBN6i93UwCwoT+/jrMi078bm5AxFqaFtbUeeTqTqeKKjp2Zv63IGH6n4CNGZmAmLdyXn+DbYQ9Lmb3JnbbOg3X2AHa32V5RpgxNcOznTsbEikBtAfnhchEfPDjF1YG8HH5njI8ShpP+0IBJCHB7MzOrn6YqPssAys9pV645mBamhbHpbc3r9HsuxwGgqGEHXFR8cw9fMoF3FSVRU0XLOt3M2zQ4+UvERojMLN2ffn/tSgA3JZgQ3Hx/hzvd9vLDZTb5H8fR6D4UexS9OaaO61Z6YM+eIGFuaM7/Tujr4ydbnggmlvT8ULX8furoJIQ5+UvERQhx4ysK9bQUkYlnNDVJzfArn/5SSx6/Hsy2zHpjRmGxW4PLYVR9vAM0ycdVsBcB0Bh9HRabL4KNlPhLthghdcAQfUyo+QnRq6a7s+6nQc3Jlgguq4gwJWuwJ69z7kZedrTqr6w2eXu+mOmT/PQ7KszhjWAKvoZg+ovtObL3Ja8CwfIsBfotCrwQfIfo7qfgIIT5z/g8W4Fv/Ho0X/ADlzyfvrb8QWPEa4WPPze7qFg1DPIpn5xoAfGvezDyX3C5VebH8hejRMK69G4F2wcc51K2HC40mSiq7fF6GugnRM9ub7H8619m54XMRZo+Oo2lwflWc+5Z7UWRary3Y5KYhoqGhGJSn8Bjw+uxWfPu3nN+n8uQMe2kOXdZZF6Lfk4qPEOIzF1zyNK66bQSWzgcgsOI1AHyrF4GzuUE0hKtuR/q+e/eGnGOlWlCnhrO5a7fZ9ws6q/h0HXzqLvsV9XPuRPm7blGtXJk5CdLVTYjObU+uVnFMeWb+zUWj4xjJbyAzR8bRNbuacvPxEYblW9S26ZhKo9xvhx4Av4usttSfFbdh/08I0f9J8BFCHDDu3RsgnlnpPFE+MqviY4QacNVtS9/XEh2sip6cl9N+LZ2sio+znbWRO4naycovwywb1u25S1c3IXomFXy+d2yUMUUmP/58W9Y8nQEBxVfGxZkyIMFZw+Oc71hYtH0HNyGE2B8y1E0I0ef0llq77XS7Kop77yY81WsdG+pZ6/hoiRjuHatyjpcoGoSr0Z444BzqlqI0Pd2G2j5u5ufa1Po/+83x07PyBXvnmEL0QzVhDZ9LZbV+Boib8EmjTnMUfIZibLHFEzM6Xpvru8dmftQ4d2Sc+z72YCmNyjyZVyOE6D1S8RFC9Akt1gZKocXaKH30+5T96dug7C8xSs/85uJbuTCzTzScmbuTDCveLctyjh2vHJu+nargKEfnNrOgPCvsZJ2XozPc/nBWkQ7I+BshDgLNMbj4hTy+8nJe6s877Zcfern8VXuNrcqg1eM/k/KA4sRB9rC4wVLxEUL0Iqn4CCF6nXv7Sgpf+BXhKecRHZNZ/0ZvqcXKK0azMi2rPds+Tt92Bh+zaCCu+p05FRql6YSPvxD/6jfsfZLbO1tWx0ZM6vTctFjbp39jzvPIK6Lh4h9lByAhDjMbGw1CCY1QQmN5jcGkAXZgaY1nr82zr5Wb7x0bJd+juKDqs+3iJoQ4tEnFRwjRuyyToud/hmYlCPznObRYpsLi3rkWLZ4dPDQrM+FZi4XTQ93MokEdHl55A1h5xTSe/wPiA0YRGX+K/bKOOT7RUZ/L2S82ZIL9zw6e+7QSFVVYjoVShTjcVIcyZRznoqT/3Oomamaec+n7FnxGFFrccWKEgTLUTQjRi6TiI4ToVZ5NH6Rvm4UDMouQAp7qtcQHj+t0Xz0aTs/ZMYsGdriN8gQAiA+dSOPQienHnZWXxKAxOfs1Tf8e7tqtxDt4Tgjx6VS3Zn4/XbjNxc3Hg6HD69uyv16MK5Yha0KIA0+CjxCiVxlNe9K39Uhr1tAyd/XaDoeaWW4fmhm3h60lh8ElHBWfRPEgXA12MwPLG+jwdRMDRtF60qUkykdkLUSa5vFlzQ0SQuy/1CKjAKGExvZWjeH5ijV19hy7v0wPsbo1j+mDeqmpiBBC7AcZ6iaE6BEtGgIz0e12ejTsuB1Cb2tO3zeaa9LPmwUD0o+bhQPSlRwtOUPaWfGJDTs6fVt58zo5QY22Sed0WVESQvTce7sN/rYuM3ytulXj1x96qW3TiJnw++Ue/rnV/v3Ua9h/t+vqDXaFNFriGkVeiyOKLK6ZDD75mVUIcRCQjyIhRLf01npK/nID8cpxNM28rssuZlo0lHXfSFZq0scK1QPJYXCRFvRYG1bBALR4FD3SAtgd3czCTDCKDx4Py1+1n+uk4iOE6F3fWmj/rR1ZanJkmcWPl/j4cK+LNfU6Zw5L8NCqzGLAXxyS4JWtbtY2GOkFR8cV97yTmxBCfBYk+AghuuXetR4tEcOz7WM8W5d32TVNbxd8UuvtpJ9vtYOP8vgxCyvQa7ZgFpSjt9alt1GGGxUopGXaV1HeYNb8Hauzio8QotfURzKJZW+bDlisrLUTzYd7XbQlshPNqUPt4LOuQU9Xf8aWmAghX6F/cwAAIABJREFUxMFEgo8QolvOeTuBD57HvWs9JKKEpn01Z9tUxUcZbjQznlPxMVrsgGO5faiiQbhrttitq2u3Ojayh9dEjj7Lvlu/M/2UVHyE6J5ScPf7XpbXGkwstZhYavL+boPThiZ4dLWHhAKvAddPiXB0uUXUhDuW+Di63OTLR8RZV58ZCb8r2bmtzK/SXdzW1Gevk3VkqR1y1tUbeJK7jpWGBkKIg4wEHyFEt4ym3ZnbdTtw7d6IhiJ83CyUL5i1rZacw5MorsRduxWjpTbreWfFp23CqVh5RURHT8WzfWV6G2VkfzQ55/VIxUeI7u0Kafxjo90hcVOTwYubXVhK440d9j9THljp5XdfbOP1bS5e2epm8W6DL42Js64hE2x2JTu3pSo5KScOSrC81uDUIQkqAooBfou9bTrv7rL3PapMKj5CiIOLNDcQQnTLaMwEHz0eQcP+AqSHGnK2TQ11M0sGd3is1JA25fFhlg4hdNIl9to8Hkclx3Bn7WN5/OnbUvERonvO4AKkw46lNEp9Fo+cFcKtK5bsMtgd0nh+o/031xTV2RPWWFGX+XqwM9m5rS6S/ZXhm8dEeXFWK7dOjaBpMGNkPP0akwckGCRr8AghDjISfIQQ3UoFH0X2uH69NRl8TBO9uQbIDHUziyuztjXziu1jpSo+bn/W885Ao1zZwQeXB6Ubye2k4iNEd9Y12Jf304bGc547d2ScI8ssTh2SQKHxh4+9fLA3U2WdOT/Iv3dkd3OLmdAcy/z9H1FsMq7EIui21+0BOG9U5rXOH5X7ukIIcaBJ8BHiMOWq2YLeuKfb7bRIC3qkFcvtI1E2LOs5I1XxeeH3lD52Ha5dn6BF7XV6EsWDsra1giWAvbYP2EPdnJz3VbuKD5qWfj6rMiSE6NC65BycM4YluHB0jKPLTK45KsqIAnsOD8AFVfY/X9hs/73pWnaFZlShPVStOqRT52h2MCjP4r+Piua85vACxawq+7XOGNZ963shhPisyRwfIQ5DWqSV4qduBaDmm3/usj11qtpjFg1EObqrQXKoWywCH/0LAP+qRWgorGTHNiczvwz3no3p+8rjy3o+a2HS9sEH7HV+Iq1S8RGiE7tDGmV+hUvPVHzGFZucNTwTQq45KrOQ6HEVJgMDFrvD9razquI8u8GeF/SNo6NcdWSMU58O0hrX2NBobzOhxOTRczJrdbV389TcQCSEEAcLqfgIcRjSWzKto1ND1AD8y1+l5JHvZj1mtNhD06z8MqxAYfZxWhvwbvpP5n5ysVLlzcMsrkwPT7P3L83at/1QN+fQOM2x6GlKrHIslj8fs3hgznNCHO4WVxvMnB/k3o+87Alr7G3TCbgUQ/I7n2dj6JnhaUODFpeMzQxPm5l8vDJod2Zbusf+nbTUL/N2hBD9l1R8hDgMGeHG9G33ng1Ek4uFBt/+CwB57z1Dy5n/DdhD3QAsf35OYwE9VI93w/vp+669m+1tvQEwXJhFg3DV7wDsio9T+6Fu8SETMfOK7eFzeu5vMq2nXU2rZYIhH1tCtPe3T+xKzfyNbgIuO5xMHZhA72YB0TljY2xp1pk5Ks6IAot542OU+iwqAvYxpgww+aTB4K9r7SpsmU9aVAsh+i+p+AhxGNJDmeDj2r2xy+dTVRzLn4/lz674GK0NuBqqM9um5u8kh6OZRZnhbu2rRe2HuqFpNHz5DiJHnEjrybnrA6FpEnqEaKctAQ+t9PBOtf23EU5oPLTKC2Tm8HSlyAv3nBzhpEoTTYPvHhvlq+Mz+6WOkWpsUiYVHyFEPybfIoQ4DDnbUKfn3ajMF5pUZzZwhBlfAZY/e80evaUGLR7JOX46+DiqPKpdU4KO1uNRgYJ0pUkI0b0/rvDy2Bq72lPgUenOa2V+i88P2v91dEYXWUwoMVmdbJaQqgQJIUR/JMFHiMNQVsWnditYFlosM2HZaKm1g5CmpefbWP783Dk+MbuDG0UVmPFYustbKtRYzuDjGCZnuX05c36EEPsmbsKCTfZlfOrABD/4XISXt7hpiGqcNTyBq5fGdNw8NcJzG93/P3vvHSZHeeVt3xU69+QZ5ZwlhBBCIgjLJMkYYwyYZFjAXrzG7LvGnzFe8LU2Nsti8BqH3dcJb/hwwoADtsEYE4XIQQIhCZRzntgz07m6qt4/KnRVh5mekYZRa+q+Ll2a7kpPdVd31+855/wOEZ/O8smeTXW1IaTjhN/+C+m5Z6Gabpuhd59CjTaSnb7kiPcvte8huOVVEosvgcJIvofHMYYnfDw8RiCio8ZH0FTEVDdCqje/PJNATHajReoRU/kaH83h6qYFInazUprGoiWTtvCxRE56zjJC7z5FdspClw11btRUELxMWw+PSvjLDpmGoM6Z4/IRnM1dIne8GiSWEZlRr/Kjc1IIAnx+QbaPPQ2OWQ0aty323NqqlcCO1YTf+SuCkiF+1qcRezvses62f/rlEe8//M5fCW55lVzTJDKzlx7x/jw8hhJP+Hh4jECcER8AMd5pp7RZSJ37CoRPLVqkHgBd9pOZtpjQxlXGyo1jyfni+A5uASA76URjvUCYzuu+Z0aO8sIq1zJlKE7Lw+O4Y1OnyJ2vG0Ygb3yq124W+q03guzoNtLPLpmu9OVI7zHCEbJGOrKVlizkjq44tvYrJjqP6n49PIYCT/h4eIxArBqfXNNE5I69iIkuW+BYyJ37USbOt5/XQzXowSjx069AD0bRgtG88GkaS3rqFIRclvSJ56GMm5PfkXlH5nRxy42aOnQn5+FxHPH4jnxPq729IlPqNLbFRLvm5hunpfjYVK9ZqEd5LKGTFzyOOi01d8SmMdZ+CyfUPDyORTzh4+FxDCLGOxGUjJ2PfVTRNMRkNwDKqKmG8HFEfHTZj5DLGo1LdS1vZx2sASB1ykUACBlHE8OaJnItU+g9/5/KH9fx45prnHA0z8jD47gjo8LXXwmycl9e+GzqMoTPn7cbz10+M8snpnuix6MfVMX9fy5fpyUoGfQjdcs092v9rnh4HMuMmCR71Ws94FFFNP3iSzT+5nZbdBxNhFQPgq6hBWvQao3+PVKiy44CZSfMM56LHULIJI11/aGiWUE9ECY983TDyGDK/IqOHV96NcmTL0RtHH8Uz8jD4/hjQ7vkEj0Am7skFBX+usv4LH5immc04NE/gilMBFPwWI8BBCV15PvPWcLHi/h4HPuMCOHz8GYf8++HHd0j4nQ9qh2HrbTcvndAmwY2vUzktd+69lGI1XdHrWlCjTQAIMa7kOKG8FHG54WPneZmRnsK6V3+eTr+/ocQqS25vJDUyReQWHoVXkGCh0ffxM1706agxt1LjZvTzZ0iL+6X6TYNDeY2ejN6HhVQIHicNT6CcuSmFdZ+vVQ3j2pgRKS6bY+JJBVYc1hiWp33Q+FxjOP4IZJ62qh4TlfXqX3uvwBIz12GWl86Tc637z3jMOPmoEUt4dOJaKauKWNmoosSUrwDMd4BGI5uJRGlSkfn4XHMoWkad955J5s3b8bv93P33XczefJke/ljjz3GAw88gCiKXHbZZVxzzTUf2NgSijE5cOoYlYUthpvbm4dl3jxs/GxfPM0zNPCoDEE1hY5V6+OM+GSL+7ANGKvGx0t186gCRkQIZGzUmP0+kBgRp+tR5YiO5qGSGZ2paLvejvwDpbxrj3+vKXwmnoBmRXwSXQgp40dLizag1rYA4Du0zXguVFlEx8Ojmnj22WfJZrM88sgj3HrrrXz72992Lf/Od77DAw88wEMPPcQDDzxAd/cHd2MXN4VPxKczOqyzeHS+lmdcROOCqV6am0dlFKW4uVLdjlz42BEfJQ1HQ0h5eAwhIyLi86GuF7im+1F+3Pl1oH64h+Ph0SfCIIWP3LHH/lvMpijs2S4kYjQ8ejdSTyu6KJEdOxvBdPeR4p2gGTdWWqgWtX4McuwQ/l1rjefMyJCHx/HEmjVrWLZsGQALFy5kw4YNruWzZ8+mt7cXWZbRdR3hAwyxJBzCRxDgp+em0MwMVlHwskU9Kqeoxic3NMIHQErGUP1jjnifHh5DxYgQPpPiW5motTK17W3g3OEejodHn4gOtzR5QMInXw8kZJMENr9C+K0/0XP+F1BbJuPfuwGppxUw0tzwB9EBzR9CzBo1BFogApJspsmtxde6w1h/7OwjPzEPj2OMeDxONBq1H0uSRC6XQ5aNn8aZM2dy2WWXEQqFWLFiBbW1fUc+GxrCyPKRpX+2tBhppbrpazCqLkBLS+CI9nksYJ3X8UZVnJdkTnDpqjHevfnsl7ogUOIcBnReDuHT6FdK7u9YoSrer0HgnVfljAjhIzePh+3QkhxYobiHx3DgjPiIPe1G/rTs73c7uT0f8RGyKSKvPoyU7Kbxt3fQ9n9+gZjqASBXN5qe5Z+319VqmhFN0aSF6wDITllIeO2T9jrK+LlHdlIeHscg0WiURCL/edM0zRY9mzZt4oUXXuC5554jHA7zz//8zzz55JNccMEFZffX1ZUsu6wSWlpqaGszDEXaugOAH7Jp2tqqO63NeV7HE9VyXnXJJH5Ay6bpaOslGOvFup3s7ewmXXAOLWGd3tefJTP7TPRAuN/9N+cUrABkz+5diJs3GL9jgkhm1umoDeMA8O3fhJBJkJ12SkXj9u98G/nwDnJjZ5KdfBIAYk8b/j3rSM89q2T/If+2N5Hb96CMn4My0e02ar9fuSzBjS+SnboILdrY5xjERIzgxlXookR63jnogRDB91YiJrrITD8VtXkSvv0bEbJpslNPrui8jjbVch0OlCM5r74E04gQPoExxoduSnYvqRyERsRZe1QrTuEjoCP1tNn2z0ImSeidJ0jPP6/oC1tyRnwySfRQLZjFpv6db9uFp+m5H0aP5FM+1ZpmO1pkCR9lnDvCo0W8FFGP449FixaxcuVKPvaxj7F27VpmzZplL6upqSEYDBIIBJAkicbGRnp6ej6wsTlrfDw8jgQ71U0tYWedLWFn/eYT1Lz0WwQ1R+rk8kIfAE1F0PKJ1eF3/+bKPpBbd9Bz0VcAqH3qhwjpBB2f/TF6INL3fpUMtX/7IYKmoks+2j/3M5BkIm/8geCWV9HCdWSnLXafZ6qX2qd+jICOtu5pOj53PwjFtd2Rt/5I+O0nyL37FF3X3tfnMEJrHie8/hnzACLKmBnUrPoFAP79G4ld+nXq/3QvAG03/jf4qj86e7wzIiSA1mQ0S5yl7uG9uMC0eu+HxOPYQ0j1oMsBxHTC9byYjtv1OuE3HyW87mmCW16j8/rv2+tIsUPIsUP5bbIpoyO3SXDji/bMnSVuLCwjA3CYGAgiqbkfJrTxRdIzTjsap+fhccyxYsUKXnnlFT71qU+h6zr33HMPjz/+OMlkkquuuoqrrrqKa665Bp/Px6RJk7j00ks/sLElzHvTqK/v9Tw8+iXnMDXQ9YIanxJ21jEjJVrqbat83yaW6Mk1jkfu3G9nGqBk7PYIYrwLtR/hI2YStqASVAVBSaNLUXtMUk978TbpXrtuVVTSCOkEeglHUt++jcZYuw/3e3pSb/44YjphN/oGENJJl3AUVAXdEz7HPCNC+OihWrrlOupy3XS1dUB936FND4+jSc2zP0Pq3E/s0q+BmWAgpHoJv/0XUgsvQIvUI8Y7afrFl8iOm4MydpZre2cEyHd4O2B8GQvpOHrQqE8IbnzRvU026fqC9u9ZR67ZsOnVCxzatNrm/N8OURT/8PXkWqaQmXn6YE/dw+OYRhRF7rrrLtdz06dPt/+++uqrufrqqz/oYQFucwMPjyPBNjXQddBUUJ19fEqYG/QaPd0qsad2Ro+cZCfOR+7cbwsrZ3NTMRlDNSeky+63YFyCkkYPRhET3UX7K7eNmIyhlmrFoBVa/5THdRw16+qBhJYrWJ6fbPQ4dhkx/s5tkUkAqK37h3kkHiMJqW03wc2v4Gvbhf/AJvv5mlU/J7z2Seoe+w5gpKIB+A9sctlZAwiOCJDgEDOBra8bf+SyBDa9BEB61lJjvUwCIWOsm50wD0FTbaOCQmtqtcYR8XFGg2Q/6ROX2+LKw8Pjg8MTPh5HC1dqm6r07+pmNrOupCFpOeFj9ZGz9u/cV0WCqsAWW8imQddtoVFqbIXblBu/MBDh49iHkFPcVuBqznUugid8qoIRI3ziDYbwkbo84ePxwRGycoMBn0P4yGbkRu7cB5h20iZWaoBmCg5LCAnZlCs0b1lNh9Y9g5TsJtc0yS4AlXraEXQdLRAhM9VdSKqFC4SPI9WtMBrk4eExPHjCx+Oo4RQnOcUthPqM+FQgfHKle8apdaNd+3cKhIoEVVHEJ4OQTdnHKx3xcaftlR2/XqHw0bV8qh4lRKOacwsjzRM+1cCIET56syF8anv2DfNIPKodqW03wXVP9x/WVhWCVlQGw9HGwlnYKWRTSA5HNqt3j1o7ylhuRm4s8wLN3NbXugMhmyK85nEA4kuvRPcbdTyWbbUWjBalFBRGfDRnjU/YEz4e1UdbWwW1CFVGwvx6iXg1Ph5HiFOcCGrWVZdTJHzUHFi1OIkY6P0Ib1NEaUF3Spla7xA+uo6UcKe69TvmIuGTcqfLJYqjRoLiNmooK7A0rd/jg5Fh4YoOqW7R6KW6VScjRvgExxnCZ5Rnae1xhNQ+91/UvPRrIq8+3Od6vkPbEHJZ1JpmdEFEbt0JGeOL2fmFLB/ahq9tt/3YFj51hvCx+vpYdtXZqYvQQnWI6TjB9c8iZpMoo6ejTFqAFggZ++gxbgT1UA050xEOQPMFi6yxdX8o/7dwZD1IPDyGg2uvvZYbb7yRJ598kmy29Ax0tWFFfKJexMfjCHFFeIoiPuWjJIKqIGT7tmi3IiBqtBHd7KqrI6CF69Eln1FXlMsWiJbBRXzEfsRT8bmUTqmrNNWtcJxCLmu0l7AeexGfqmTECJ/GyRMBmJDZX7Ha9/AoheVaE173NGKiq+x6vn3vAZCZdgq5lskIugYHtiFkkojpvDd9cOvriClHnrA5w2ZHfMy6Ht+hbQAoLVNQxhgF2JE3H7WPAdgRHwstWONKXyv3hZ864VxydaOLbKw9PKqBp556ihtvvJGXX36ZCy64gLvuuov169cP97AGjaJCRhWQBJ2ANxfhcSToutt5rSBqUWhnXRhJ6U+k2PvyBdBCRo2oHoqCJKP7g8Y6SrrI3KA/imp8CveRSbhEiLUO5LMayo5dr+wesHCcQsmIj+P1UiuvHfIYPkaM8GlpjHBAbCZIllxX63APx6OK0XxB+2/f3g2lV8plCW56GQBlwjzbUY3Du+00NIugaUxQdBwzBc2K+PgObDb2N242ymhD+FhCJjt5IeCO3gC2MYE1E1euEDV+9mfo+rvveD0IPKqWxYsXc8cdd3DzzTfz3HPPcfPNN/PJT36StWvXDvfQBowzzU0Q+l7Xw6NPNNW2eAYzQuOMWvRTF9OvEYG5L13y2f3etLDxv+5zCh9HjU8l5gYF4yrch7Efd18tSyyp9WP6Pk7FER9jezXSYDxRGC3TVNfkp6BVd6PhkcKIET6iALv9RtQnfsAzOPAYJEoG0RGCt1LK0HX8O1YbOcGZBA0Pfw0p3okuiCjj5pBrMq49Du9G7DaET2bqIjJTFxmbS74iEwIr1U1IxxF72pDiHWiBCGrTBJQJ8/Lr1TTbDU4Lu2xbBgl6sHwXYxvvDsujSnnttde4/fbbWbFiBatXr+YHP/gBL7zwAvfeey9f/OIXh3t4A8ZLc/M4WhROdvXn6lYsLiqL+Oiy33YFtQSQLXyyaXea2mBS3Qr2UWps1jY501ih3NiFCrN+rO2tSUhBVYr6Fkm9HfkHXo1PVTAi+vhYtIYnQvod1Na9wCn9ru9xfCMke5B628mNnlbxNoU/ClZzs8CW16h99n6UUVPJzDwdufswarSJ5OJPoPtDqM2W8NmFFDBmj9TaUaQWfhTUHJk5H0JIxwnsXGMvs2bNhEwiH+0ZOwsEkdzo6XRd/k38u94lO2m+LVp0XwAdwZ7h08weBulZZxB+9ymyY71UNo/jjx/96Edcfvnl3HnnnYRC+ajn7NmzueGGG4ZxZIPDc3Q7/hBSPcjte1AmnGB8X2sq/j0bUMbNKorUS7GDCJkkudHTS+9M1/Ht3UCueTK6aUgjde6306FdFEb5c9kiVzexpw3/vvdRa5qKxUWiG/+udxFS3SgT56NFG+1j5RrH2SJKl3zoZo1p6YiPQ/goacSedqTYAZSJJ4KWw7/zHQRVITtlIXogYosYXQ4g5DJlIj6lhY8V8bEMFYRUD3LbLmg22j2UivjIrTvQfSHUhrGIve34976Hf7/R6FStbcF3cAtCLusSjQCio8GpoKr593nMTAJmm4rM1EXHVzZFLot/3/tkJ8wrqhmuBoZM+Giaxp133snmzZvx+/3cfffdTJ482V6+bt06vv3tb6PrOi0tLdx3330EAkN7YXTUT4NOCLeV+HLwGFnoGg1/uAupp5XOq+5GNV3/CvHvehe1psl2RnPW4gCIZsTHEiy+1p1IpuV0/MPXk516MgC5RlP4tO7BLxs/DmrjeLRoIz0XfcU41o7V9n6zE+fb7m1iJoHv4FYAVw1ObvT04h9GQUT3h+yCVCvSkzj9CtT6sXaEycPjeOJnP/sZf/7znwmFQhw+fJiHH36YG2+8kVAoxGc+85nhHt6A8YTP8Uf0pQcJbn2NrsvuIDdmJqG1fyP62iNkJy2g2/wNsKh7/HuIiS46/v6HRVF8APnwNuofv4/09FPp/egXjG0e+w5SHzWnFkbUwt3AtPapH+Fr3Qlgp1GrNc1Ive0EdrxlC6rshHl0X/xV6v78baRkN7ogklh6lTkoH1q0ydg2ajSJ182bfTGTREz1GqYH0QakeCe1T/8Y3+HtxC75F6TYQWpeeACA5IKPkFh2bV7EROqRuw+7hI8abUKKdxSbD5jpcVqkwTBWyGUgmyb60q8Nh9Xmb0F4YnGtq5Kh/o/3oIVq6bz++9Q+cz++g1vsxZY1t1EfVVBX5KwX0nJEX/4NwS2vkpmykIDZciJ+xpWkFn28v7emaoi8+gjh9c+Qmvth4uf+w3APZ8AMWarbs88+Szab5ZFHHuHWW2/l29/+tr1M13XuuOMO7r33Xh566CGWLVvG/v1Dn34Wb5kFwOjYVs/gYITj37XWrrXx73635Dry4e3UPfE9Gh/+F/s564s312CkllmpbqIj3C1mkqi1o+yeOgB6MGL8GOSy+PesRxdEMqYosrBmyQCyk+bbP3hCJoHcvss47qip/Z6bczbPSnVD9pOefy56pL7MVh4e1ctXvvIVWluNz3MkEkHTNG677bZhHtXg6TXvrcIjKifj+EY0e7WJZnNQq7bTv2ede0U1h9jThqAqiPEOSiHFDgEgm/+jabboSc39sP1PGVWczVBYoC/ouhENMZHNRte5FmOi2uo5Zx9XzSGZv4OCriF1HQSMiE9q3tkkTvkE6fnnGs/5LZdRYzJQD9WimfUy1nGk2EH7fJznZNXr2JkPZh8fALVxHFA+4qP7g7bRj6ik8vvvOGC+Xg7ho+uIZn8gqbcdVMV+r9IzTiW56ONkZpxq7L+ggWkhgqrYNT+yKSTt1+04IrTxRdf/1caQCZ81a9awbNkyABYuXMiGDfki8J07d1JfX88vfvELrr32WmKxGNOmVZ5uNFh8dQ3sFUcRUFN2TxSPkUlo7ZP2386ZHSf+PQ5XKLtpmlFMmRs9FR3B+JLLpm2raYue5TeC6P54KaNn5P8eP7eoWahT+Cjj54Iko/mCCLpuz8blmkpHppzYs1OAMn5Ov+t7eFQ7Bw4c4JZbbgEgGo1yyy23sGfPnn62OnbZ3Wt8d4yLehN0xwtWjxnRvHkv2TgUo4G1lapcrhbGet668RdyZqTDFyR+7j/Y/9InnFO8sSPVTTfTlARHrx7r71zLlKJlYrK7aNx26wTZjx6pJ3n65ba4sSI+1o2/Gqmz63+s/YrJ7pL1P7ZDm1k3JCjpfBTIquEpcKCzxJLuC6L5Sxgr9HaBmnPbTqtuMSMmum2BFf/w9STOuNLOvhDU4lQ3F5qab7CayduAV1LTVE3oDoOnamTI5pPi8TjRaNR+LEkSuVwOWZbp6urinXfe4Y477mDy5MncdNNNzJ8/nzPOOKPs/hoawsjykfl6TmoJ8pY8l4nZVhrje2De/CPa37FCS0sFhetVyKDOK52AnRtg1mKQylwvug6OGa7Aoa20NIaL1z+cbzjaQg+0TAWML8Rgyxg40AQ97bR0bgItB03j4OTlMHU+DeNnFh/34hvhgT3QdQj/4vOKz685CksugJoGmicYOcqEa6Db/KGpbaZ54pj+X4Pl18D2tXDO1TRHP7gIj3cdVhfH03kJgsDmzZuZPdtIBd2+fTuyXL3hkk2dxnfRnAZP+BwvWGlY+f/LCJ8KbJ+tG3kh1WvcbCv5G34nzsk0exyOVDe1pgW5q3S2Ta55SvG2mmrXtVrYBj9ScaddazxS7LA9nsIxiYlYyXO2hY8llBzCJ2e7tpWJ+PiCtugSMqm88Il3FrvF5RRXg1cxGbPXsV9P69wKXN0KEdScLaKc61Vi311N6L6AdStUlQzZL0M0GiWRSNiPNU2zf4jq6+uZPHkyM2YYM+DLli1jw4YNfQqfrq6+m2j1R0tLDWImyWp5Dp/MriK9dT29U5cd0T6PBVpaamhr6+1/xSrDOi8hnSD07t/ITl1UUZpX5OUHCb/7FKl55xA/5+9LriMmYjQpGbRABC0YRe4+TNfGDS6TAyGTpGnvZiyfs54dW8jIzUTb2wgBvYQIRJvw97STefsFAkC6ZTq9s5cbG5R8T/y0fO47dG94m+y4haXXOfVq1/YNcsj+kGYaJ9JTyXvdMt/4l8LuwD3UHO/X4fHGkZzXsSiYbr/9dm644QZGjzZmgru6uvjOd74zzKMaPJu7jIjP7EavL8jxgmhGI6yb88I+NfZ6jih/kCQ+AAAgAElEQVRGfxEfAd2Mwlg36u46aS1SV7Sts4GpWttcXvi0lM4usESMPRYr4tOX8DHrXrVIvS1k7O2TbuGTF3NmFMuK+GSdEZ/SdtVu4WOk2Ym97fk6nN4uO/Jmb1OQ+if1diBoOXRBtAWPLvvsdQtd3VxouZLCSEr0b99dTWj+INXcXmzIhM+iRYtYuXIlH/vYx1i7di2zZs2yl02cOJFEIsHu3buZPHkyq1ev5vLLLx+qodjUB3RWy3MB7GJxJ/5dawlsfxMtWEPijKuKUpU8jgJKhsjqP5OecRpqy+R+Vw+/+Sjh9c8QWf1nui/4Itlpi13Lpa6DiMluo+hfEAitexqA0PsrSS1YYZsSoOuE1j2DWttsh63VutGojeORuw8jt+4whI+aw793PeHVj7kKIKVOIzfY+qLVwnWGxeWBzbZzi1KJO1y4huwADAZyzRORO4yUHdsS28PDw8XSpUtZuXIlW7ZsQZZlpk2bht9ffW5DAEkFdveISILO9Dov4nO8YAse63/zZlwX3beQ7uhH6RtmqShCYrl6uiM+aomIDw47a6tJNoAuiHmBEKpBC9eji5L9O2j9bYkY+7zMtDxLHDixhY8ZJSob8TGFgXUMQ8wZAsUd8THEkFo/2t7WNZYSER/ZWV8T7yqK+FAgZqzz0/3BfIsHUTbcUjXVTisshaDmSqbCCakeo65IrGa54MApsHUNhOq6Vx4y4bNixQpeeeUVPvWpT6HrOvfccw+PP/44yWSSq666im9961vceuut6LrOySefzNlnnz1UQ7GpD+hsESfSK4SpiXcg9nag1RguJGQNZxMr5KlMmOcqTveoAF2n7i/fQ0jH6f74reih4pnhmhd/SXDTSwS2vUnndd/te39qjuDW1+yHofXPkZ22GKl9D3qoBi1cR91j/44U7yQz7RR6z3G7i9Q++Z/ELv8mejCKb997RF/+NQA9537O2H3dKJSWKQQ3vYTcuhMhHafuie/bDja6KJNaeD7ht5+wZ8UsVzc9XIcyaprdpBQobz16BMTPvJrA1tcRNHVI9u/hcTywa9cufv3rX5NMJtF1HU3T2LdvHw8++OBwD23AbI2J6AhMr1PxHyf3SSMeXbNvmAUlbaRbW4sKojSuRp/9RHys9S2BofvdwqewjhSMeiArKqHVNtvP51qm4DMNB6hpAEFAC9chmYX+uebJ+Fp3IHWXKdTvQ/hYaJFi4SP1tiFmk+iijNowFrljryvdzFpfTMcRNBVdlGz3ODHVbRhVmZPUeXODgCPa5Bhvb1dRpM2wqM6nulnru8YuCMb55bJ27Y4u+13bAUb9UCnhg46Y6rFrn6oehzmYkIrblurVQsXCJ5lMsmfPHmbPnk0qlSIcLrZYdCKKInfddZfruenT8zduZ5xxBr///e8HONwjoz6gowsia+TZnK28g+/QVjKm8AnsXuu6iIMbXzwuhY/UsQ//vvdInbhicBEtXUeKHTJmXApUvnx4h+1QU/fkfxK75F9AFJEPbSW8+jESZ15jO9lYjmo2qmJ8mBw/Av7daxHTcbRgDWK6F/nwdqTYQRp+9020YA29yz9vfykHdqxB94cRdJ1cw1gQfcgde6j92w/pvuifCb73Qn6/ew3TArV2FLlRUwDwte0i9O7T+A5tQ400oNW2kDrhHHJNEw3h07oTsmnbvU2NNNgheDBEUq5xwsBfz37QTXtN34HNZKccf9ejh8fR4Mtf/jJnn302a9as4dJLL+WZZ55h5swSdXZVwK4e43t1er0X7TlecEYZBCWNkMmXAThFEBSLmlIUiqPChqH5hcW/8ULGiKToouy6Ec+1TM4Ln6jxvBauzwsfc7llVKAFIoiO89Cl4ghrUepduK4o/U4007GNZQ3QsddlomCdm/W66L6gYfxj3hcIqR7DrVTXHSl/IVsEuhzV4rH+U91iJYQPmPbYWfu90/whpALhI2i5sq5vYrL7uBE+TvEoJmOox6Pwee211/jGN76Bqqo88sgjfPzjH+d73/seH/rQh4Z6fEcVWTQ6Ya+W5hrC58BmMjNPByCw7U0AkidfSGjtX/HvfBsh1VsyajFcCMluhFzW7iI8YHJZGh75OoKuofuCpOedVfGmvn3vE9jyKoKSIbjtDZTmSfRc8P+5xhJwRGd8B7fg2/8+ysT5RF96EF/rDrdLmjkeZD+Rl35N6P0XQFNJz/4Q8bM/A0Bow/MAJE/5OKF1zyD1thN+41Ej3J6MUf/YvwOgCwKCrtuiSplwAsmTL6T+93fi37+R5v+60eXiEtj6BmCkuuWaJqELIlLnfvyS8XGIn/XpfDqamkONNiLFO2l49G6kRBe65EOrac6HwcH4WxqaAKoWabCvUw8Pj2IUReGLX/wiuVyOefPmceWVV3LZZZcN97AGRSpnfK/U+L0ePscLbuGTcYkbOwJk/p70Z24gZFOudCtXxKcCty3R6vEm+1zRl1zzpHzza1v41JnrBuy6GisVTK0fg+iwui5V46MVNGYtleqWX1ZnH09MxIrtrM3fcOsctXAdYroXKRkjF6k36mvMiBCSXFRfZAxase3E8yfudnWzU91KCB8w6n8Bwy67UJiqxTU+WqgOMWU61w3y1u1Yw2nMISZjqPTvNnssUdGU//e//31+85vfUFtbS0tLCw8++GDVFo7WB3Re8hkz5/4dq0HTELIpu5dLasEKlHFzETQV34FNfe2qcnQd+eAW2yJxMNuHX/89Tb/4Ek2/upWGh79GcMPzRTNF/RFa94ydwxvcNAD/dV0n+sIDhDa+SHCbIRp87XsIv/Wn/DqaRtAUFJkpC41jbH4FuXWHPYvkavSFWZ/T3Up43dNGtE3TCG1chX/vBmjbi3/vBnTZT3rOMrupmnV8J73nfg7VMZOijJ2FVtNEz4W3oNaOMgoVyYsUKydZqxsFvgBq43gEXcPXuhMdAWVsvkkokkz3xV9F84ftWhu1fowxkyYI5BqNfj7KmLxVtYeHxwdLKBQim80yZcoU3nvvPYLB6rVbzZqlhQEvze24wRllELIpdzG/rrsaijpFkVQi1a1QDImJWFlXt5JjsWyWJZ8r+qJFG/MTvTWm8DGjLWqkPi9KzAiNs20CUDLVjSKzhXq0UC26c9LQucwUOVKPYUigizK6WZNrYUVy8pEg0+Eu634NrP/FAoOfwlQ9I9XN4cBmrl8YrcKy/rZqmgpEHRRHj8AwkIDjy9nNJXyq0LihoilqTdNoaclLVcuNrRqpD+islWaSjI4mHD+Mb997SPFOBFUhO24OWrQRZcx0/Pvfx9e6k+z0JQPav3xoK4Htq1HGziI76UTktt2E3n+B4KaXUFqmELv8zrIpZkKyh9B6I7KRXPRxVPOmWm7dQWTNY0bXY18QuWMvNat+bnzxjDodIdVDaMPzZCfMIzdmphFSDUZdEQipcz+Rt/5oP/Yd3GqmrDnskXNZoq8+jFo3htSCFfYMlG//RmTHrEl65ukEt76Of/9Gx/73Iaa6UaNNxM/8OwK71hLYvrpodkWXA2QnzCOw6x3krgO2GMxMPoncqGlE3voj/u1vQashOtOzzkQPRsmNmQGm6NH8YeJnXU/tM/cDkJ28AC3SQGDb6+RappAx37PcqGl0XvddhGwKXfLh37ueuid+YI9FrTMKO5XRM5DNvk5q0wT0oPuLVq0fgzJuNoFd7xj7Nd8XgO4Lv0zkrT+ROPWTJd9TDw+PoecTn/gEN910E9/97ne56qqreOmll2yHt2ojk4MTcjuY2dsN6uSSNsFVQS6LFO9ArR/b52pCshu5Yx9qw1i0aOMHNLgCNA2p6wBq4zikroOodaMR4x3GjXjhDfAAEFK9yO17ELJ5V1ohmyKwY7V7PSWD7gsgxjvz6WYY9Tj+XWtd0RS5c59r28DW19DMWp6im/USWEYDuux3RV+saIyY6nGlutnLCtzYtFAtmj+cjyD14eqWP0YdiCJaqNZuguo8vmoKMfnwtvz5iKKrnsYZ8YFi++u88Cn9WsgFzUQNsZItWq9cxMd+7C8WmaUmt9XaFnyHtyMf2oavdpQxiesYm5BNIaTj7kwes6mskEmCKKKMno6Y6kH3h4qEIGoO2vaCbr527bsR0mYKoiAYbrjWaxeuAyWD7/B2tFCtYf6k68a1Xz8WRBGx+7DruhfSCeS2Xag1zWg1TUg9rS7h4zu0td/PrRaus48lt+7Mv06CYL8eQrIHdM1IW8xlzQjZ0GRcVSR8xowZw8qVKxEEgZ6eHh588EHGjRs3JAMaauoDRkh55/gzOWHzo4Tee95W+Ok5hr11zux2LB/eUXY/aCq+ve+h+wLkxs4CQSCw8SVqXvj/DReUtU+6HFHAqCMJv/koySUXl/wxi77yG4JbXjWO3baLriv+FWQ/wfeN6EzqpPNJnHEFkdd+S/jdpwi99zwsOp3oql8S3P4mkTcfRRkzE/nQNrRoA2rdaJQxM0kuuYSaZ3+GkMuSnvMhdARCm14iuO4ZEh++DjSV4PurCG143o5qSF0H7JSz4PurAEguuoj0rDNQG8fh37MeqbcdsacNzfxgAyhjZ6LVjyY7fi7+/Rvx738fXQ7Qc/4/EVr/LInTL8e//S0Cu95B6tqPbLqlZacuQhk7i8hbfzQiR6Y4TM83GrBlpp1iNB3VVFKLLiQzayndonH56qFalIknoEw8oeRbZc3MKC15O+z09FPtfNvk4k8Qen+lsU4Zy+zc6OlYwkdtyF/7Wm0Lved9ruQ2Hh4eHwyLFy/mkksuIRqN8qtf/Yr169dz5plnDvewBsXk9rX8S++/w3pI6ecSP+szwz2kQVGz6ucEN71M56fugZa5pVfSNRoeuQMpGUMLhOn4zP+1Z9Y/SELrnib6ym9Iz1pKcMurpGeeTmDrG2SnL6bnozcPer/1j/5b0Y227/B2+/fSQlBS6EqAhof+xX5OjTQgJbqoe+L7JfdtLRezKSKrjeyLUjfjuYZxyF0H7MfWJJ8u+9H9ITRfEFFJo0UaUCP1xj1AjXEja4kdzRHxsdB9QbRIfV74lBAazlQ3LRCx31st0oCU7LbPwT6G+ZtsTarqgbC97yLhY0V8rJ5GhcKnICKjhuuRkjF3zQ8Uubo5z8/1WC4UPsV17qWFjzHBGtr4IqGNL5Kefiq9H/2Cvbz2yf/Ed2AzHZ/+D0OYAP7tb1H31I/sdTLTTsG/Zz25ponELv+ma/+R138Ha5/Ed/FXEZQMdX/9gWt5dvxcpK6DIAh0fvo/qHnuvwluN0o7ui7/JnLrTmpe/CXJk84nteB8Gh+8jeyUk+n52JcAqHv8PnytO9ARyMw4tSjrJvT+C0apQj90XXEnUtchap+93/V8Ztop9Hz0izT87psIao6Oz/wnNS88QHDzK3Dzj4GjL34qEj533XUX3/rWtzh48CArVqzgtNNOKzIuqBbqA0aYct2Ys5m3/S8EdqwBjC+B7HTDKtnq5yK37Sxp1Se1G0XzVhREGTsLtW6U7fCljJ6OkE0hdx1ArW0xlte0EFn9JyJrHiO46SWSSy5xdVUWkt0EHBeU3Lmf8JrHSZ38Mbt2Jj3vLJB8pBZeQGjdM/h3vg071hHY/pa9ne+QYdMtxTuR4p34928ksOsd5I69qOF64suuQ+xtJ7TpJUIbV5FccgnBjS8Sfe0R1zmG3nseZfwcMjNOw7/vPeP4cz9kz94p4+cQ2LEG/773Sc87y3ZCy402ooG9532O+j/8G1Kii/jSq8hOWUjWTIGTOg2HNLl1l71dduJ8tNoWcg3jbQe1XNNEu3u0VtNM56f/wzXG7IxTy7zLpdEj9UZkRsuRXHKp/bxW00Ts4q8SXv1nUgsvKLmtM5Ut11Cdot/D43jllltu4cknnwSMiboxYypo9HuM0hTfbf9t3aRWI1K7MYlmnENp4SMoGduaWcwkkeKd7iyEDwhrws/6DQ5sfwsB3T6HQZHLFomeQqzJUUHJIMU7bBERP/0KtJomghtfhFIZ7ZJM8pSPE1z/nOtGtFSqW/eFtxB584+kFqwg9O5TiMkeECA916jxTZxxJVK8Cy1ST+rkj6GHagjOOBl6VTLTFuM7sJnUiecVRXx0f5DkkksJvr8SLdKAMnZW0bHVpgmkTjgXKXaIzMzT7OeTiy/Gv3st6TnLCK9+DCQf6dlnogVrSM88wxYz6TlGHbkWrHWkoFkRH0v4mNeP1WrCTNcrFGK5lslIu2NIDhEI7r5GhefnwjFZrQtGFMp+bL2PJYRPZvaZyLGDiIkufIe2FX2m5fa9CJqKHDuIYgof67qxDBz8u9Ya63TsddWDQf47Qu7Ym+9zVNuCGmnEf3AzvoNb7Al4IZOwr3Vrm/Ba43sz/O5TKBPmI+h6foy6jmx+BgT0okhlZtrifOpkGaTYQaREF3L7XqTYQQBydaPRQ7X4Dm01zj+bRIobxlFiqsc+JtkMyMMkfJqamvj+941Zh97eXg4dOsSoUaP62erYxBI++8VRxM+8hppVP0cXJXrP+rQ9Q2DMfBgzEVLXQTvlDIwv8/pH70ZU0kb9SCZhFPIf3IIuiMQ/fD3p+eeCriHGu9CiDbZwyjVNIPLWn5A791HzwgOGPfPEE0iechGhDc8jaCqZqYtILryAhj9+i9C7TyF1H0ZU0oZ4MsehRRvJTFtsqPZffhMBSM07m9RJ5xNe8ziZ6UvQfUHkjj2EVz9mX8SpRR9D94dQmyaSmbSAwJ511P/hLlcaW/zMq9F9QWpeeIDoi78i1zzZsGEM1tjFjQDZ8fMI7FhD8L2VZGacin+34eamjDFqcbSaZrqu+Ffkzn0oE9yRGGXsLHRBJGA6wOUaJ9hh3vhZ11P/p3uBfATuaJJccknJ55UJ8+ieMK/sdsqofI+e4fhh9vDwKM+MGTP40Y9+xEknneSq71myZGCpyscCkayjuL0K8+ctrKaNfdU2OFNmrHWH4/vVbghq3SCa/5dzVaton/1sG/v4V4is/jO+Q1uNdCfzmMrYWaROuQiAzKylfe5DGWukYBdGQ5xodaPpXXETAL0f+T9Fy9MnLs/vb8I8lAnzCAbD0GuYO1nbouuGs5kpEnRfkMzM01yCpghBtDNHnGSnnUJ22ikA9Fz0Fdey3o/8Y/E5ROrAnBC1BI0tfBIFwqeMw12uZQqB3e8W9SUS1Gxp4dNXxEfyuVLfdH8IIR1HLBnxaabnozcjpHtp/t9/cn8e1Bxiutd1HpD/XGSmLyb03sr8dZnLIihpVzTLOm8xmTeESC04n9SJ59H80xtcWUdGz6SY67HzPG0RmYgZLnmZhMsYyrkvNdpIzwVfLDrfQiKvPkL4nScQk932sZOnfILs9MU0//fnjQa2LidDx+NoPZTu83tEVCR8fve737FmzRpuu+02LrnkEiKRCBdffDE33XTT0R/REGMJn1hGIL3wHLRgFK1ulB1ZsFDGzUba+jqRVx+m58JbEDIp/HvXE3n994hKmsz0JfQs/zyCphJ87wXEdJz07KV5kSSI+R5BJtkZp5KdvoTg+y8QfeHnyB17kDv2EFr/rP3BS510Prlxs8lOOhH/nvUEt76OLgjEP/R3rn0lTr/CDldq/jDJJZegRRvzX1KAMvEEspMXUvvkf4IgkpqXjzAlll2L/Ph3XVGr2KVfM2YSdJ3Q2ieRY4cIvfuUsXzMDNcsQ2b2UsJv/wVf6w6a//vzgJEDm2vONyXVI/UoBbNEYKSHpU84h9CG5wBDbNljHj+X2Cduo/7gOlKOiNiw4w+SXHgBUk8b6hDYVnt4eAyeWCzGG2+8wRtv5Ge/BUHgl7/85TCOanBEMgWuXgUzvFWBphpNGynfiwYo6qnS17pDSVnbaCUN2TSUSCHrd5/9nIsWqbdv4gUlg5iJA2WajpZDEAzLabM9RCXmBoNGENAi9Ug9bUN/rAKctUhF5gbOm3UcTnSO8elyoEhQq7UtRmQlp7jMJext+qjx0WU/SHn3Ed0fgnS8tIGVlZIfiKKLsiGOlAz4Am5b8mSx8CkykDDPU3UKn0T+/O3tIvUgSuihWoRU/hjWRLrzmKWEj6AqCNlkn9ew7is2dyiFZaAhJmP2/rVIndFk1qzdcqYfir0diOlew603UgvpviNKg6Ei4fPQQw9x//3385e//IXzzjuPr33ta1x55ZVVKXwm1BjOYlu6DFeuculSidOvxL9nPYHd79L4yy8bF5XpSpZrmkTP8s+D7EcHUieXTo8qiSCQPuEc1GgTcuwAga1v2Pm+mUkLUMbPNY9/Bb4Dm9FFieSplxoFag60+tHEz7iK6PvP0738H8sWl6kNY+m6+l4jZc/RNVitH0PXFf9KcNNLiMluUiecnf9xFQSykxYYwuc9w1K60LVMD0ToPe9G6v5iNCHV/SEjQlOhpXPi1EuRD20jN3YmyqQTXcuUifNh0RnQ1ltm6+Eh4RBoHh4exw6/+tWvhnsIR40aJW8II+SyhjlLoO++eccaYqrHdr/qK/JRKuIzHPR1gyclY6j+gUeh+jsXLVxv33QKStqO7hWmlPWHIUYs4TN4I4aKjhV2Cp+hPZbruI7XpMjcwI74WMKnOOKjlqhR0mpbIHbIuMmvoMbHWXumyz50UXasa4iAQuGjSz7XfZXRELYDMRlDqxtdYF2e/5zYPYyCUbRgFDEdd6wXQ20wDUOcEaNkt31861zVSJ3ddB0M4wMnYqLb9T4WRoP6uoYrff+dkTn7Gg/Xu0S73OZI7zXHqIXqkMShsbasuPHIqFGjWLVqFddffz2yLJPJZPrf6BhkYYsRqlvXLpHTjN4+pdBqm+m54IvUPPszpHgnuiiRHTeX7OSTjNzYIyzAVCYvQJm8gNT884i+8HP8Bza5bqxzLVNo/9zPjDS5MrN9qUUXEj3/U+T6EwiCAELxBaQHI6QWfrT0+CbOh3VP58czprgZoDLxBDr+/kfoPv+AnYf0UC2xq/5tQNt4eHh4lOK6665DKPE9WY0Rn1qlwK442Y1abcKn4AaqHM7+Nsa6w5Da57h5LMVg0+/6i/jooagdvRCUtOPGva6vzYpQw/VYv76lLJaPJq6m3cMV8TGPq9o1Pt2g68Wpbo4onR6uK+ofpNYY6fVOC2rL6ME4jvvG3hXxkXyuSV4tYAkfd3Si0BBBi9SbwqfbED5lPif5RqxBw2nPJXy6S//tiPjYphThesBR09NWIHySMdsREEA0Hf+sffc1aVHp++80ochHfPKmGVJPq0uQWWPUIvUMlaN/RcJnxowZ3HTTTezbt4+lS5fypS99iQULFgzRkIaW5pDO5FqV3T0SGztFTmwu3x1bGT+Xzr/7DnL7btSG8UMz6yb5iJdzBRsitVsJ2fFz7RxYZezMsn1qCq2fPTw8PD5obr4577yVy+V47rnnqK2trm7iAOg6dabw6a6bRF33HvcMb5VQLoWnEGd/m/7WHSpEMyWv7PJBijHrNcg1TXIVlNsIojvikxx8xMdiyCM+zmMNIv1v0MctJbj8QVuoONOySqW6qeF6V88iXZTy55LL2qluWm0LouV65++jxkf2ozuEj+XwVhzxcU+QF0epSosYaz+G8KkDh4W5ux7GKXy6bMGUtyF3i2hLYFjXZGGNj+ww83DW2pS6hit9/+1z7m1HzCTQRQk9GHUtcwkfK+IzwAmAgVBRA9Pbb7+d+fPns2zZMn72s5+xZ8+equ2RALBolBH1ebu1At0n+8mNmVl1qQZHjC9A79k3kFh8MbFP3F5xCpuHh4fHB82pp55q/1u6dCl33HEHL7/88nAPa+BkUgT1DEkCJGsMsTNcdS9HgjuFp/+Ij2Y1mzwCM4HB0t/rO1gxZm2ntEwuWqbLhkCxm2xm044b9wEKH5coGOqIT3Hk5YOgnLhzCglbONqpbgHX9nog39tQC9fZ74HT1U2taXYcpw9XN8ln1+5APtImFDaVL4z4FDnR9RfxCRQJ4XKfLdE0ItB8QbsHT+G2UrwTMBzujO27XemmlrW4MZ7uvq/hCrN87Ka0lm15qNY2/LKidta4nH8P9HMwECoSPjfeeCP79++nvt4YyLnnnossV++NsJXu9n5HRac/YsnMXUbytMuGpa+Ch4eHR6UcOHDA/rd//35WrVpFLFZ9ggGz4XOr2EAu5G7QWE24ZqUzSaOYuwTWzLaVSjYcIq+/13fQwseaLS8wTgLQ/FaTTSvikylKA6oUtxgZ6hqfYyDVzdkbqI80Kuf4tHCdkfLvaMxqRXCcqW6qo4lon+YGkq8g4lNacBaKA2tstuNhokzEx9GTqFAA9JdG6rx+yokHtW4Umj+EoOUQHaLDdZxkXkyWuoaFEoYQpdD9IVtkFo2vj2vdGaE72lSsXu69994hG8QHzdiIocrb01XmlOPh4eHhUcS1115r/y0IAo2NjXz9618fxhENkt688GkpsOutJorEQrwbKL45tGa21fox+Np2DU+qW38Rn0G+/ta55ErNlltNNm1Xt1RRcX6luFK4hliMlDIZ+CAoH/ExhUT3YcRsyhAkATP9XvKhCyKCruW3jzZAd5vx2BIluazdwFTrS/g4J4Dl0hGfQnS5TKpbqYhPuhfUHEhyXvj4g0UCoL9oqvP6KScstLBh9iBmU64oj+s4DutrtWGcy8ocio1J+kKN1NsOwq7x9XGtD2XEpyLhs3z5cn73u99x+umnIzks/MaNq85Gjk1Bo66nI+VFfDw8PDyqneeffx5FUfD5fCiKgqIohMNVmJ5sRnzahHqazR9+3+FthiunpiHGO42bmcFG4XUdsbfD2N9ANgvVoPtDxuywmgPZb99UCdkUQsptDmA5f9m07obGObY1tJBJGj1CLBeqmhZ0QURMx5FiB9FLmPE40WqazV55+dlqPRi1U9KFZHeRcUI5rKaK5RB72hG7W8tsnEDsTpRZ1JUfawF54WOmuvV2IGaSZv3DwOpmS1k9DxXqBxhdclJOZFnXoO/gFuOxFdkBEAR081qzX6OaAUR8+mpgWhDx0cqZSlHkFwsAACAASURBVJSJ+MiHtoKmFgkXuXUnav2YPiM+vkPbDLEm+0vWn1US8TGETz300WBX6m0zmt2a+9TCdUgO84NKP1/2OEoJnz6iOgONfA6EioRPMpnknnvuoaGhwX5OEASee+65IRvYUNIUMiI+HV7Ex8PDw6PqefLJJ/nJT37C448/zsGDB7nuuuu44447WL58ef8bH0vYqW6NzLFv6rZS+7cfIsUOI3fuQ4000HntfYMSP5FXHiL87t8GvJ0u+0nNP8/u8g7Qe84NZCYvpPHB21y9QZzYVrwP3UNk0ccJvfMEqZM+6updB4YrlhauQ0p00fjg7f2OJzPlZMR4Bz5HMbYu+ei85tv4Du+g9ukfD/gcrbEW/u8/uJmmX3+l7HZNZZeAjuByzbKPZbafsG7oA7veMZ4P19n1D5WiO/cvDm0Jgp1GVuBqNuQ4HRsddTTWTXRw8yvmY/eNtO4LQiaZf95Odauz09CEnGKnbWnBGtswoa8GprrsPv9yNeBFqW7meOXYIer+9O18XZd5rTU8+m9G/xrzHHVfMO+AZq4j5LI0PvQvdP7dd/LCKVQD5uSD8zWw3y/ZbzQktdzrInXlo0HmcXyHtjnGbazvFD4DEb5OgeMan1NIixK65LO/S4bS3KCiK3flypW89tprro7Y1UxEhoCkk8oJJBUID8yJ2cPDw8PjGOInP/kJDzzwAACTJk3i0Ucf5YYbbqg+4WM29OwVwihjZ5JrGIvcdRD/nvX2zZmU6ELq7RiU05s1M65GGiq+cRWT3Qi5rN1wWpcDCLkMvoNbUaONxk2i7C+6UVFrR5Gedxa1T/8EgNC6pxF0ndCG51yiB4wbvNSJywm9vwooKBB3ragj9bbj3/ceQi5rCIvaZsRkD0Iug9y605hNx7iBq9TeWQtGSS6+mPDbfyF58oWE1v6N9AlnE9j6OnLXgbLbSaKIqpWPnmWmnAySTO+Hryew821SJ5xD+N2/Ef/wdYDhnqqMmWHWUgiDatqthetIz1mGFggPeaNbPVRLevaZJcXcUBP/0DX492wgOynvKJydughl6+uI2SS6IJI64VzXNqn55+E7tC3fWP7EZSj7tpGZvhjRFApCOg7W9Sj7SJ30EaSuQ2iRBte+spNPQtnyGoKSITPrTIRMPtJXzlSi0M461zSR7IR5+Pe9j+/QVvv9Siy5lPC7TyFk4kZNHKALAsh+lFHTyE6cT2bKQnxtuwhuehmpp9XVEJSlF5N7eyUIApkZp9vH02qaSM84FbVuDIKuEdj2BrmGceQaJxR9XpVRUxEySZKLLyaw/S1k00kuO24OeiBC6oRz0EWZ1EnnE177V+JnfabkOZciM3sZcsdeEH1kpi+2n1cbx5OZshC5cz+Z6UvQJR/BLa+i1o0uWVd0tKjom2/8+PF0d3cfN8JHEKA5qLM/IdCRFgj7+vii9fDw8PA4plEUhebmfEpRU1MTeqHDUjWg5gBQkPEHA3R96h6af3pDUSHxYC2urRul2Ce/7qpn6Ivo8/9DaOOL9hhSC5YTfvsJ0+7WSLXJTFtM74rSDc1703FqXvylvX2pomjdFyB94nJSp1zU92B0jeb7P5ufoa9tpvO67xFd9XNCG553WfDGl11HZtYZFZ2jRXbqIuP/aacY5zX7zD7Xb2mpobOCRtvpE5eTPtEQ4dnpS/KnE64ldtk3BjTGIgSB3nItMY42gkDv8s9/MMcqIHXSR0md5O47qDaM7bMfYOqUi3AZTE+el3+9TUErJmMgGlE2XfKRPO3ykvtSG8YRu/Iu+3Fg6+v232UFdmFUVpLpvvirNP3PPyJmEqCDFoiQXrCC9IIVhNY+SfSVh4x9+oLGzarsp/sTtwGQBuS2PYYVtcN8gPnL6JrzkeLjCyK953/Bfpg440r7b1fKWSBM7Ip/tR9n5nyoaFeZOcvIzFkG5D8flZKdchLZKScVLxAlei78suup5GmXDWjfg6Ei4aMoChdeeCEzZ87E58sr2GpsDmfRFNLZnzDqfCbWqMM9HA8PDw+PQXLKKafw5S9/mYsuughBEHjiiSdYuHDhcA9r4JjCJyvIBCRAlNBDtQgpdy7/oArudc1h+Vt5GklhnUCuebI9hkqablZyrIoL5QXRSIkrsLzNW+Z2Iw3SHc1jZJG/ZmJooRqg2IygL3RHn0U9UJmrm33sSL0hfCgQIBXYhWuRejB78NjCJ1oPscprbuz99HOs45WKhM9NN5WeyalmDIMDyXN28/Dw8KhyvvnNb/KrX/2KRx55BFmWWbJkCVdfffVwD2vA6DkFAcjiw2eWeqiROsRC4TMI9zMhnUDQVCMlagA3eIXCxdkDpLB3SsntKxAgA7nxcgufOtf/giPiM5Q1Ah7Vj2Gz7EfIZRBTZk1Nhb1pAJdxgeavrMbHXj9cD537jb/L1L+Uq6FRraafHfvMz3ME0ecHBih8hsma/FigIuFz6qmnDvU4PnBsg4OUJ3w8PDw8qhlFUQgGg9x///0cPnyYhx9+GFWtvki+msshY8wmW+Uahqhwd00fTKPPwdslO2aG5QBq7Sh0BIRUL1K8w1ynr4hPBcJnAG5kpex67f4ozn4uQ2iH63EcIAiGiO5py6dfypULn0r6+JTbXznntUqiMLYzXPtuc/u6yhpyFu5nmJrRHguMWD/npqDb2e3xHTJ/21W9TVk9PDw8Riq33norra2G5XAkEkHTNG677bZhHtXA0RQj1U13uHM5b4ZyZl3PYFLd8pGQwTfIVCP1+fQ7dOT2vf3us1zkJdeQb4cxsIhP8U2jnbYUO2SYHsj+io0NPEYuhdftgCI+rj4+pa/f8hGfClzOygkfyxmubXfRNgNhJKe6jVzh47C0Tufg7jeC3PV6EHVg7Q08PDw8PIaZAwcOcMsttwAQjUa55ZZb2LNnTz9bHXuoOUP4aE7h47ixyTVPAQaX6lbY2b5SSs1Oq2aER+pp7X+fsh9K9KZxujYNSPiUSA2yIz7WeML1Q+5w5lH9FF23AxA+uqOnpS4H0EvYkBe6utnHLRflqUCsF13rg6xl0wMRW5h9kD2ZjgVGrvAxm5i2p0Ta0wKqLpDVBDq9mh8PDw+PqkIQBDZv3mw/3r59O7JcfRF8zRQ+glQm4mOKhVKNC/tjsLUv7r4gVk1NfcE6/dx8Rd3WwDoCueZJ+cdHGvEJ1aKT/+3uK/XOw8PCVeci+QYmlh3mBpTraySVrqUr22TUcXyhXG+sos/eIK91M9UPRl7Ep/p+GY4SdabA7c0KdDrqfA4nBVrCVWiD6uHh4TFCuf3227nhhhsYPXo0giDQ2dnJfffdN9zDGjB6zmww6BQ+jhubvLHAYCI+phHBQGeIZT9aIIyYSeaFhqvup4K0spoGaN+X3yYUtZt4wgBrfJw3jZbAKXC/8+p7PCrBlVo2gPqeIgQBXZKLrNr7NDew/i7zeRSU0mYFhesfiXuhFq5D6m0f0OfveGDERnxqzN49vVnoTOdfhrbUiH1JPDw8PKqSpUuXsnLlSu68807OOeccRo0axec+9wH1NjmKWBEfpDKpbo0T0EXJsMK1brJ0Pd/N3vrb+ZzJYGt8nNvYZgKFUZf+ZsoLIj5auB4tGHUMrvI5WFfNkav+qK7k8x4e5VCdAr5MdKYsWsEEuTM91ZwIKJvqFild1+OkfMSnruDxEQgf8/y9iM8IIeo3Ltq4ItgGB2BEfDw8PDw8qoe9e/fy29/+lj/84Q/09PRw00038dOf/nS4hzVwzD4+QglzA12U0EM1aKFapEQXYrIb36Gt1Dz3PyBKxJdeReSNP9j9QQBScz9M/Nx/IPr8/xLc/qaxv0GkxmjhOug6UGQfXfH+TOGj+YKIShotXOeOEg0gxchOzxEE9FCt/bzucL/TPStrjwpwXScDjvi4hY/L5S0QgWyqbM2Qe+JggNeq7EfzhxGzycFt7xrHyEx1G7HhjagvL3ycdT1tnr21h4eHR1XwzDPP8NnPfpYrrriCWCzGfffdx6hRo/jCF75AY2Nj/zs4xtBVI9UNOV8/oEWbUEZPJzP9VCMv3xRCYrIb/661CFoOIZch8tpvXaIHILB9tfn/W8a+glGXqUClZKYtRo02ooybA4AyYR5asAZdlMhMW9z/DmYuQg3XkzjjStRIA5lpp5BrmYIyahppsxt8pWjRBpSxs8hMWwJi/hYmM+0UdFFGC4TJTpw/oH16jEyU0dNRa5rREchMHljD41zLFJSWKaTmnQNAdsrJAKi1o0gu/KjxeRkzo+S2ui9IZtICshPnF6WJxj7+FdRwPb0ryvfPzMw41T7WYD7PFtnJJ6OG61EmzB30PqqRERvxCcsgCjqpnECrQ+y0JkesFvTw8PCoKm6++WYuuOACHnnkESZPNupfhGp28zJT3URnobQoErv8m/ZDa7ZYdDTrBBDN1JjEkktILrmU5vtvQMwmEdJxxGwSXZTouOHHg3I7Sy9YQXrBCvux2jiejs/+uPIdTFtA59//X2NfJy63n45dceeAx4IgEvvk14vHeMI5pE84Z+D78xix6MEondd/f3AbSzKxK++yH8bP+jTxsz5tP04v+Ej5bQWBnou+UnKRMjn/WSlH/JwbiJ9zw8DGW4LslJP6PdbxyIgVPoIAUR/0ZGFvb17stHqpbh4eHh5VwWOPPcajjz7KNddcw/jx47nwwgursnGpjVpc41OIlZ4iJmIlG5laNTdauA4p3oncvie/XTWLQg8PD4+jwIgOb1jpbrt7ypsbdGfgwU0+dnaLJJSielEPDw8Pj2Fi1qxZfPWrX2XVqlXceOONvPHGG7S3t3PjjTeyatWq4R7egBE0I9VN7FP4OCI+Jdzd8nU4R6fRoYeHh8fxxIiN+IBpcJBwi53DSQFdh60xkVcOyBxICPxxm58fmMvHRzVuX5xm6bgqnlX08PDwOI6QZZnly5ezfPlyOjs7+dOf/sT3vvc9zjrrrOEe2sCwzA0cNT6F2A0Mu1sRs6myy63/5bZdxmOv4N/Dw8PDi/g4kQSdjCrQnRG45skIP343wB+35S0O/aLO/rjIv74eJKPC/27w8/utxa4dqgb7esunFGzsFNkWG9EvvYeHh8eQ0NjYyA033MBjjz023EMZMKJmCB+pj+arloCR241IjhptRHc0U7Stp62IT/su4/ER9Pvw8PDwOF4Y2REfh/CRRZ3xUY3dPRKPbHGLmRqfzrOXxQG47m9htsQkfvG+n/9ab3RB/etOH6kcPPCRJEEZHnjfz/3rAvzHWUk+NN6IDOk6/Hm7j7FRjX96PgzAm1f3Inop1x4eHh4egKhWIHysSE7XQfNxA+g6UqLLeGyluhWu56W6eXh4eIzsiE+No19VU1BndNgQQv+9IeBab2qdhiSCJMJ1c42mcZboAVjXLrE1JrGm1Zh1e36P8aP1yoH8j9fqwxJ3vxm0RQ/AoYSnejw8PDw8DESzxkeooMbH+dgWO8Ea2xihqNGhF/Hx8PDwGNnCxxnxmRDVGBVyp77VBzQAzpuk2M8tGVO+tue1AzKxDGyJGQJoY2c+/WBDR3HO9q6eEf3ye3h4eHg4sFLddLH/VDf7caSuqK6n8G9jO0/4eHh4eIzoO2+n8JlYo9ES1uzHPlHn4Y8l+fppaT41Ky98moI6Ebm0tdurB2Xebs3/YG2NieTMXW7oKH6pC4VPUoEX9soonm+Ch4eHx4jDFj59RHyQZLRg1H5oRHysup46x/MFAskzN/Dw8PAY2cKnxu8UPvlUNzDc25pDOpdMV5Acr5IgwKTavEC6eHqW/1meJOrT2dMr8tj2fH1QRhXY0S2i67CurTjis7tA+Ny/LsBXXgrxjdeCnm22h4eHxxCjaRrf+MY3uOqqq7juuuvYvXu3vaytrY3rrrvO/rd48WIeeuihoRuMriPrVsSnvKsbuKM3WqSc8CmI+Py/9u48Pqr63v/468yZJZNMSIAEZEsgLAoiIsUFFXBD6m6tFryt2GoX7KJepdVasQqoWNRatbX1tvW23v4qFEWLilTrgopYQRZBdsK+hRDINvs5vz9OkkkggCzHZIb38/HwQTJzZnK+npk55z3f7/fz1VA3EZHjO/iEGtUwKMq1KAymAk3X0IGTR1FuarsRRQkGdkgyuKNzwvqgbl7PCXW9R8t3e9hUZVAR9RAwbTpmWxg4z72+0sNvFgb4+qvZrKzwNBRVeHOjj39vOq7rToiIuO6tt94iFosxdepU7rzzTiZPntxwX2FhIc8//zzPP/88d9xxB/369eMb3/iGeztjOV39cUw8noOfmuOdTwScgBTv2JN4p97YhkG8U5/U02Xnk8jrCEAir6N6fEREON6ruvmbDnWLp/IMXUNWM49wFDfq8emc4/x8Wock7252gkvAtPlarzjPLAmwfLfJur3Ot3fDuyaYMCTC9lqDq/8ZYsFOLwt2Os/zzVk5Tf7Ga6U+LipKHFX7RETkwBYsWMDQoUMBGDhwIEuXLt1vG9u2mThxIo8++iimefCemKNSV9Ethg/zEHVvqoeNofYrV2D7srAD2STbd2PX954FX6PCPB4PFdc/hKdmL1ZOHhyiF0lE5HhwXAefoLdpcYOaeOps0zX3wMGnS6NQdEKO8xyDOqQm5pxamGRAgfP7+1u87Ik6zzumbwyvBzrn2GR7bWoT+5/dhneN895mH/N3mMSS4G/mXGXbkLDAp/OYiMgRq66uJhRKzZcxTZNEIoG3UTnpt99+m969e1NSUnLI52vbNhvvQRYfPaha55+44SU3N0BhYeDg29Nmn99zD7BduyPbn2OssPBA+5fe1K70onalFzfadVwHn0SjbJPlBb+ZCkKFwQMPdWs8F6g+mPTOtxrCzOCOSU5q5wSfHbXOkIXhXeOc1M75gx4DHjwnzNOLAiRs+MOFYZ5Z4ufNDT6+2z/G1moPq/eYnD01l/FnhrmqZ9Oen3vnZjFvu8lT54UZXnhU/wtERI5boVCImpqaht8ty2oSegD++c9/MmbMmC/0fBUVtUe8L0bNHgqAGF7CNRHKyuKHfEy6KCzMpaysqqV345hTu9KL2pVejqZdBwtMx/UcnzNPcHpmxg6IAjRZTLToID0+gzokGd0nxgNDwg23eT0wrEsC07AZ1iVBrh+6NeoZurKk6UlsaJckUy+r5cXLaykI2ow/M8q711XTt53FkE6poPOr+VlEGuUe23bmEe2Nerj13SDrKg6/3YvLPNw3N4s9Ea0jJCLHr0GDBjFnzhwAFi1aRJ8+ffbbZtmyZQwaNMj1fTHqhrrF8WphaxERlxzXPT5ZXvjzxU2/oXvu4ho2V3no3fbAwcdjwLjB0f1uv/fMCD8eaDQMf8tuVC57SKdD16iuP9ld3TPOojIvS3aZRJMGb270ckWJc1KsiBoNQ/L2RD3cMAP+cjHkHWpURCN3zAmyN+qhOg6PD4988QeKiGSQESNG8OGHHzJ69Ghs2+ahhx5i5syZ1NbWMmrUKHbv3k1OTg6G4X4SMepKWccNBR8REbcc18GnOacUWJxScODQczBZXjih0byh87smWFlhclphotm5OgdS1MbmzxfXMnOdlwfmBXlsQRaFwTBndUqyscrppCvJS+L1wKoKkzlbUsGoXjQJ33szm9JKDz3zLL7bP8q5XZzwtTfqPMecLT4sO6KTrIgclzweDxMmTGhyW8+ePRt+bteuHa+88sqXszOHUdxARESOzHE91M1tN/aLce8ZER4fHj70xs24pHuC87vFqY4bTPw4i0+2m8xY41SO651vcWE350S5dk8qVZWHDb45K5u73w/y+W6TcMJgabnJnXOC1MSdQNTY/B2qkCAi0tLU4yMi4j71+LjIZ8LVvY58gqrXA4+cG+GrM0x21Hq45e3shvuKci165js9U2v3ethabfDUogBxC1ZWmKysm/vztZ4xFpaZrK80Kd3rIbBPzvlom5czTjj0MDwREXFR0vkcjuFVj4+IiEvU49PKeQw4veP+waRbrkWvPOf2tXs8jHs/yJsbfQ1rCdW7oFuCE9umAlJppXPIvR5nSN5nu1IvgYqIQewAGeiDLSY/ez+LythRN0lERPZhWM6XZHHDi2EcuKqoiIgcOQWfNHDmCfsvZFqUa9E5ZJPlhZ1hD6sqmh+yNrBDkpI8J/is2+v0+gBcUVdl7vNyk3gSNlUZXPZyDg9/ktXs89z+XjZvb/LxzOLDqKIgIiJfjOb4iIi4zrWhbpZlcf/997Ny5Ur8fj+TJk2iuLh4v+3Gjx9PXl4e48aNc2tX0t5Z+1SE83psurex8BjQKQSle/Z/TMC0OatTgqCXhiFxc7ea+Oqi7qkFST7dmWRDpcnKCg9r9pjELIP3NnuxbagvYvSnpX4+25UKVUt2aU6QiMixZtQNdVM5axER97gWfN566y1isRhTp05l0aJFTJ48mWeeeabJNi+88AKrVq3i9NNPd2s3MkKHbJvfX1hLyGfTPssmkoSQ37nvrK5O8GmfZXFlSZznPg8wpFOCX54VIVRXTrtn3ZC40kontOQHLM7qlGTBTosNlSbf/lcOXerWHKqMGWyqMihqYxNJwJ+X+YkmU2fh0r0eIgkIJwx+szDAtb1j9D/CKngiIlKnrrhBTMUNRERc41rwWbBgAUOHDgVg4MCBLF26tMn9CxcuZPHixYwaNYp169a5tRsZY3Az83wAbjsDOvsjXF4SJ8cHfdpaDO6YpG1Waox455zUz33aJnnyvDAFQZtLuseZuc6ZE7SlOjXqcWm5yf3z/M327sQsgwU7Taau9DN3m5dPdpi8dnXNftuJiMgXZyTr5viouIGIiGtcCz7V1dWEQqGG303TJJFI4PV62blzJ08//TRPP/00s2bN+kLP17ZtNl7v0Q2zKizMParHt1a3Ds0CnLk5/9Wh+W3GfgUW7YBnLjVpF3SOy2WFsLAXnPZs023n7gyyZNeB/96WWDZztzk/76j1UFiYy9YqyPFBXvNThPazeDt0zz/49pl6vNSu9KJ2yZfCqhvqph4fERHXuBZ8QqEQNTWpngDLsvB6nT/3xhtvUFFRwfe//33KysqIRCKUlJRwzTXXHPD5Kipqj2p/CgtzKSurOqrnaI2+aLu+eyJwIiSroay66X1dQjlNenzeKrWB/c+8XUIWW6o9/N9ii/q6GAY2n66r4WszQ/TKT/LCpYc+TqsrPFw/K4cLu8V5ZGjkqNqVbtSu9KJ2Nf9YOfaMRsUNFHxERNzhWvAZNGgQ77zzDpdeeimLFi2iT58+DfeNGTOGMWPGAPDSSy+xbt26g4YecdeAgmST4JOwUmfdolyLy0vifLDFy8jiOFMWZLG1JrWtjcELK50JR2v2mJSHnce2Dx64HOvauspy9f+KiBz36uf44CWoctYiIq5wLfiMGDGCDz/8kNGjR2PbNg899BAzZ86ktraWUaNGufVn5QjcflqUiojBtb3jPL3Yz/q6Igg/GRhlTN8YhgE3nRzjP9ubH2r4xvrU2kGXvpyD1wP//no1WQd4de2sdcJRWa2Cj4gIpHp84oaXkHp8RERc4Vrw8Xg8TJgwocltPXv23G879fS0vPZBm6cvCAPw7mZvQ/ApyUs2lLUGKNinF2dQhwSf7vSyN5baKGkbJJMwf4fJ4I5JahMG7bKaPq4s7ASemoRBTdyZGyQiclyrDz4qZy0i4hp95S5N9C9IVY/r3qZpmerCYNPfh3XZf2HVere/l83IGSEufTmHDZXOWXxzlcF3Zmfz+vpU3t5W4yGpatgicpwzrFSPj4KPiIg7FHykif7tneDj9dh0ymnaUxPygafR2PNre8cZWHjg8FMTN0hYBsvKnR6k10p9fFZusjeaetmNfj2H294NHssmiIikn7oen6iKG4iIuMa1oW6SnnrnW1xcHKdLyMK7Tyw2DLDs1Bk5ywvPXhRmzhYvqys8/OGzQJPtA6ZNNGnwWqmP6av9VMaa/5vztnuJJcF/dNXKRUTSlnp8RETcp+AjTZgeeOic5ktMN8djwHldE+QHTP7wmXPbL88K0zZgs6Xaw5QFWXy8/dAvs01VHnrma8ybiByfLH82AGVGWy1gKiLiEgUfOSLmPuVWu4ZSoWVkcQK/Ce9t/uLPt0HBR0SOY+EBF/Po1n68UnkylxgH6B4XEZGjouAjh6VHmySllWaTIgjgVHz78cAobfx2w5C1fecIHcyGSk03E5HjmC/AwuyBxKvAVPAREXGFgo8clinDwvzl8wDfPyW6333f7tf0ZH1CzhfvwVlf6eG+uVmsqPDwPxfVUnjUeyoikl6Sdd8VGRrqJiLiCn3NLoelexubX54V+UK9Obn7rM9T3CbJg2eH6ZmX5J4zIpzSPsmpdVXhXiv18fp6H+v2mvx9pf+o9nFZuYfvzM5mWble3iKSPqy6j1XN8RERcYd6fMQ1jb+1HFCQ5M8X1wIwsrsTdq7pFac8bDByRqjJ4/6+0s8pXeCP87N5+NwwJxzGkDmAn70fZEethzveCzL7mpqja4SIyJekPvioqpuIiDv0lbh8KTpkNz/srV2WzcjiOHl+m4GFCU4tTFATN7htNnxWbvLcssPv/dkVdq4ayiN6eYtI+kgq+IiIuEo9PuKqiUPCPPe5n58M3H9OEDi9Qg82Kp/9z7VeFpelXpbhhMGaPR7u+iCLm0+OcWkPp7eoNu5cHGQ18wr2eSCZ3P92EZHWLFn3/ZCGuomIuENfiYurLumRYNpltXQJfbHhaud3S+DzpLbdWmPw5MIAGypNfrMwQDQJkQRc+2oO33ojm0hi/+fYdyFUy4anF/l5d5Nyvoi0XlZDcYPDG94rIiJfjIKPtCq5frioKJVmFpV5mbvNCSzlEQ8z1/lYvttkZ9jD+kqTPy/zY9swf4fJE58GSFjgaXTREEvCpztN/vfzAOPeDxJXT5CItFJJFTcQEXGVvgKXVucXZ0S441wfV/zdJpJ0rgB65ydZvcfkxdU+vto9FYz+vCzAqgqTD7Y6L+VuuRZVsdRVaxbYsQAAIABJREFUw86wwebqVL7/cJuX87omqI45w+gKs/XNqoi0DipuICLiLvX4SKuT5YU+7aFDo1Ay6ewIeX6b1XtMXlrj1Mnu2y5JttduCD0Aa/Z4SNqpq4btNZ4mi6POKvVi23D9rBy+NjOHSq0TKCKthKU5PiIirlLwkVZrbzR19u+Zb3FRURyALXU9OA+eHWZEcbzJY1ZWNJ3gs73GoHRv6mX+7mYvb2/ysq3GQyTZ9D4RkZakqm4iIu7SVZ+0WrcPcqq9PXJuGICreqZCTn7AoluuzakFTSftLNm1T/Cp9bC+rsenX7skSdvgrg+CDffvVslrEWklNNRNRMRduuqTVuvyHgneu66KC+uKHfRrb/HHi2oZ3SfGvWdGMQwYWHjwagXLd3vYWmPgMWwmnB1uUjEOUmv+gFME4eKXcvhgi7nv04iIuE49PiIi7lLwkVbLMCDH1/S2gR2SjBsc5byuThjqlmvTNrD/4qhnd3Luf2+zD8s26JJj072Nze8vrOW8rqmeo7lbvfzvMj8JC77/Vja7Ix4mfJzlXqNERA4g1eOjoisiIm5QVTdJa4YBtw+KsqTMZMFOk/WVTm/NwA5J1u31sL22bphbe6dn6NRCi1MLI8xYk+TB/2Tx/lYv72/1Em+UnbLU4SMiLUDFDURE3KUeH0l7l/VI8PMzopzYNpVe+rVLcnL71DC4G/o2Ld9WGGzaS/SHzwINP3sbvSuqYs6CqQnL+U9ExC0a6iYi4i71+EjG+MnAKKcWJjm9Y5IeeRYJC/69ycfQLglOatc0tRQEDzyUZGOVhwfmZXFO5wQT52XRt32SqphB0ob/d0mtLkpExBVawFRExF0KPpIxTsix+Uaf1Pydc7sk+fOIGvq03b+rpvAgwQdg5jofM9c5E4zm70i9TTZXGRS10fh7ETn26uf4GAo+IiKu0FA3yWgDCi2ymon3bbNS4aVnXpLLesT5x2U1nNj24FXi9l0nSETkWElqjo+IiKsUfOS41Hi42rAuCR4YEqFHnkXnnINP5FlVobeMiLhD6/iIiLhLV3Fy3AqYzlXGGSekenm8h3hHfLjNy2qFHxE5xmwb6vuhFXxERNyhKzg5bk29tIZHh4Y5vVHwyfYdfP7OqgqTb72RzeflHjZXG7y6zkskcXh/N2HBhkpd2YhISqqwgeYQioi4RcUN5LjVNdema27T1PLDATF2hT1ke23e3OgjYNoUt7HoGLRZvMukMmaQtA3GzM7BNGyStsE7m+P86twIH283GVCYxABu+Xc2J7ZL8oszokyZH2D5bpPfXVALwNRVPn79aRZ3nx7h2t7xZvZMRI43KmwgIuI+BR+RRtoHbX5zXpiluzy8udHHye2TPHtRGIAPt5osKjN5bpmz5k/Sdq5Q3tvs4yfvGPxnh5fTChMM75rg890mn+82uXtwlKmr/AB8vN2kWyf49adZAEz+JEvBR0SAVPBRYQMREfco+Ig0o3+Bxa+GhumdnxoGd07nJOd0TpJlwuvrvfz0K1HKIwa//CjIf+pKXi8s87KwLPW2WlaeGk26Zo9TEa5ryGJztXN7PAk+FYoTOe6psIGIiPsUfEQO4IJuzU/eubl/jJv7xwCojoPXY5Owmr9aeX9r6i322S4n4TTe8t3NXi7olsD0OJOb/77SR4dsm4uKDnPikIikNQUfERH3KfiIHIWQD87omGTuNi9dQxZf7R6nOmbwnx0m6/aafLClUfAp92DbsDOcurL5+YdBQj6bcV+JcEKOzeN1w+A+ub5KY/1FjiNJDXUTEXGdqrqJHKXLejjzdK7sGWfsgBjjBke5vO621XtS49j2Rj3MWgPRpHNlc0n3OB2zLarjBi+t8TNjjS+1bexLbICItDirbs6goapuIiKuUY+PyFEa2T1B33bVdAmlLliK2zRdCLVbyGJTtYdbXq+/P8nEsyPsicJFL+ayZJfJ0kbzgcbNCRK3DL55UoyLihLUJpzeJRHJTOrxERFxn3p8RI6BojY2ZqN3U3Fu029tHz43zOCOqXk7HYLO/fkBOCHbCUn13/gCLCrzsqzc5J4Pg9z2bpALp4dY1Wjh1I2VBvFU3QURSXOa4yMi4j4FHxEXdAlZ5AecQJPtddYCqh/+BlAYTAWjk9odPMF8tM1L0jaYuc7p8nlro5drXg3xm4UBF/ZcRFqCylmLiLhPwUfEBT4TXri0lilDw/xxRC1BL5zVKRVw8gOp4NM7PzUs7uu9UpN7uoaaDpfbXmMQS8LdHwQBeGGVn/AXKP62J2Lw28V+yuuKKlTGUG+RSCujHh8REfcp+Ii4pCBoc363BH3aWg2/1ws3Ch6N5wOd2SgcXdUzTvc2qd/f2exj6LRQk7/xzqb9p+kt3+3hlbXehgupce9n8dyyAI/MD7C52uCC6bk8MC/rqNomIsdWQ/Bp2d0QEclo+owV+RI9ciG0z7L41kmpnp0RRQm+3S/K7y6opXNOKgT1zk/y0DkR7hocwedxroqStkGe3+aS7s6wuWc/C7Bur1MmGyCcgNvfDTLx4yB//dxPbdyZLwTOkLlZpc5wuTc2qFKCSGuSVI+PiIjrVNVN5Es0uj9c2LGmyW2mB3480AlCe6Kp23u3teiYbdOnrcXjn6bm88y+ppqEBasqPKzda/KN13I4qW2SZy6s5aU1fsojzvcZv1vipyo1rYhYEmoTqauqiohB2yyVzhVpDeqLm3g8ek+KiLhFwUekFcnzw/CucSzbaKj8BnDbaVF+/WmAx4aF8XrA64HHh4e59d0gGypNVlSYjJ8bZO1eJ/S0DVhURD389XN/w3MkbYN/bUi95aeu8nFiW4sFO5y1hu74SlTfNstxxbIs7r//flauXInf72fSpEkUFxc33L9kyRImT56MbdsUFhYyZcoUAgF3ioqouIGIiPsUfERaEcOAx4ZF9rt99IlxvtYrTiC1HipdQjYvXl7LthqDa2bm8MFW5+0cMG1+OjjKPR8GsXGuokYUxXlzo48dtanRrX9c2vQCrl/7JCV5Fu9s8nJz/xh+k4PaUWtQGzfokWcdfEORVuqtt94iFosxdepUFi1axOTJk3nmmWcAsG2b8ePH8+STT1JcXMw//vEPtmzZQklJiSv7ouIGIiLuU/ARSROBAwSRTjk2JXkWKyucDbq3sTjzhAQew8ayDfq2S3JxcYI3Nx58Xs8zSwK0y7JZVm7SMcfmml7xg25/5Ss5JG2DN75WTeERtUikZS1YsIChQ4cCMHDgQJYuXdpwX2lpKfn5+fzlL39h1apVDB8+3LXQA5rjIyLyZVDwEckAfdqmgk9JnkVeAPq2s1hWbnJu5wRnnNB83evZX6smP2Az+vVsSitNttVNP3p/s/egwSeedIbOAayu8NC36Ni2B+Cfa70UtbEZWKja2+KO6upqQqFUpUTTNEkkEni9XioqKli4cCHjx4+nuLiYsWPH0r9/f4YMGXLA52vbNhuv9xBdpQewra7j1O8zKSzMPaLnaM0ysU2gdqUbtSu9uNEuBR+RDNA7Pwk4PTo964ae3XxylL+t8HN1rzg5PigIWuwKO0Pdxp4SpVdbi/Z184gu65Hg6cWpC7b/7DCJJCDLC7Vx+NX8LIZ0SnBhUYIf/DtIbTz1tfTGqmNfHHJrtcGEj4MUt0ny4uW1x/z5RQBCoRA1NaliI5Zl4fU6p8X8/HyKi4vp1asXAEOHDmXp0qUHDT4VFUf+Wi3f7QFysBJJysoy6zVfWJhLWVlVS+/GMad2pRe1K70cTbsOFphUzlokA9SvFQRQkuf0kAzrmuQPF4XpmO2Emwu6Ob0+OT6b754S47yuqV6gi4qb9u5Ek0bDnKF/bfDxaqmPX8wN8suPslhc5mX1nlRIWl957D9G6ucibatOleoWOdYGDRrEnDlzAFi0aBF9+vRpuK9bt27U1NSwYcMGAObPn0/v3r1d25ekihuIiLhOPT4iGcDp8XGU5DdfbODWgVECJlxcvP8Qtq4hm+I2STZUmowsjjN7g49nP/PTo43F3G2pkDO7mfV/1u099sFnd8S5+otZBlVxaOM/xANEjsCIESP48MMPGT16NLZt89BDDzFz5kxqa2sZNWoUDz74IHfeeSe2bXPaaadx3nnnubYvtspZi4i4TsFHJAPkBeDS7nGq49A5p/kLpyyvUxb7QP5wYZjN1R5OaptkwU6TdXtNRr2e03C/z2MTt/b/OrrUhR6fimjq75TVemjjV+U4OfY8Hg8TJkxoclvPnj0bfh4yZAjTp0//UvZFPT4iIu5zbaibZVncd999jBo1ihtuuKFhuEC9V199leuuu47Ro0dz3333YVm6sBE5GhPOjvD48MgRV4UqCDqFBLK8Tu/Qvr7VN9bs43ZHPFSEnQVRp670ET0GtQjKw6lG7IroSlAyX305a73aRUTc41rwabw+wp133snkyZMb7otEIjzxxBP89a9/5YUXXqC6upp33nnHrV0RkcN0aY8En1xfxT1nOGsKfbtftGGOUHPeWAuPzA8wZUEW//NZalxadQyS+3ynMW2VjwnzAiQsqD5A4bimPT66FJTMpx4fERH3uTbU7WDrI/j9fl544QWCwSAAiUTCtdWwReTIGAZc0yvO2Z0SFARtvB749fBavAb85N1sAG4dGOHJRVk88B6EE878nxdX+7np5Bi7wgajXs9heNcEk8+NkLCcb7V/tzhAddxgc7WHpbtMfn1emDNPaNpNtDvSuMdHNVgk82kBUxER97kWfA62PoLH46GgoACA559/ntraWs4555yDPt/RrI9QT3XO04va1ToUNlqd9JpCsG342xoIx+HWc7N4pRQ27E1tUxU3eG1LLn4T4ha8tdHHwkofj8yFnTWpXp5PdzofPz96O5vPxkKbRt99VDXKQTUEKCxsuS9G0u14fVGZ2q50peAjIuI+14LPwdZHqP99ypQplJaW8tRTT2EYB/+0P5r1EUB1ztON2tW6PT3M+XfPbnjobA+PLMhhxS6bm06O8fvPAjw+z6a4jQU4X1b89E2LPdED99w88m6M2wel5hXtqMqhfiTupt1xysoibjXloDLleO3LrfUR5MhZGuomIuI618aQHGx9BID77ruPaDTK7373u4YhbyKSfk5sazHzepjzjWq+e0qMr/WMEbcM1jRa6+dgocfA5oVVPjZVGVTH4O4PsposiloWNpj8SYCx/w6ysiJ1eywJC3eaJCzYWGmQUH0USWNWXTlrw1A5axERt7jW43Ow9RH69+/P9OnTGTx4MDfeeCMAY8aMYcSIEW7tjoi4zFuXSX40MMqMtakCBwMKkizZ1fww1Uu7xzE9MHOdj2c/C9C9jcVbG5uuFbS4zMviMufn775pMuOKGuIWjJsTZGWFydAuCd7f4uVrvWL84owDl+sWac1U3EBExH2uBZ9DrY+wYsUKt/60iLSg/ACc3y3OO5t8tM+y+ErHxAGDz4ntklzQLcGs9V5mb/DSZZ81iIJem3AidSUYThj8bYWfWeu97Ao7Sev9Lc7H2Iw1fm4ZEKNdlr4xl/SjOT4iIu7TAqYicsyNPzNCfsDm8h5xauMGz9XdPrRzgmgSKmMGKypM+raz6JRjc0WPODPW+tlU3fSq7/mRtcxY6yM/YBMwbR7/NIvnlzu9SSV5SdbtbRqoZqzxcXP/5tcbEmnNkgo+IiKuU/ARkWOujZ+GYWfhBHTOsejexuLX54UBWLHbw+e7TU4rdMq3/WBArMnwuAu7xRnaJUH3PIv/rit6sKrR/J5sr82fL67lxtnZbKhMhZ/fL/FTFjbo3z7J5SUHXncIYP1eD11CFr5mOqMmfRzg051eZn0LIgnnb59SYHGIGiwiR8zWUDcREddpgQwRcVXQCzOuqOE3daEH4KR2Ftf0ijcEiYKgzRPDa8kybcZ9JcIjQyP7BZde+anqBYM7Jgj5YFAHJzgN6pDg3M4JbAymr/Zz/7wgv1l44BLYr5d6ufa1HJ5Z4t/vvi3VBi+v9bOxysOn2+CxBQFuejOHF9f4mnkmkWOjvsdH4VpExD0KPiLiOtNz6Au6c7skee+6akafGG/2fo8B1/WOke21+fFAZzjbZT0SBEybK0vi3HV6hC45Fv3aJfF5bJ5f7mfotBA3zs5m7R4Pa/Y4H3dJC+77yKkk+dflASwbXlnrZcK8ALNKvfxzbSrgrN9DQ0/U/y7bPySJHCsqZy0i4j4NdRORVsM8xFcxPx0c5bbTomTVfXINLEzy4ajqhvtfvrIGw4D/W+7jiYVZhBMGy8pNRr2eA8CUoWG21zS9snxxtY9H5mcBMHuDTX4gVRxh3Z7Udo2LLByKrW/v5TDVl7P2qJy1iIhr1OMjImnDY9AQeppTHzRGnxhneNc4p7RP0i2UGiL30/eDPPapE3IKgs7t9aEHIJo02FGb+lhcXpZ67poEbKg0SH6B9YL+tsLH2VNDTdYdEjkYlbMWEXGfenxEJON4PfDYsAgAVTHYXO3h/o+yWFtXBe6OQRFOLUxy4+ycZh/fMdtiR62HeVtStyUsg6+/GuKHp0b5Tr8Y/97kpVOOxaYqD14PXNAtgcdwenueWOiEqYf/k0WHbIsfDojRPU8rrMqB1ffzqKqbiIh7FHxEJKPl+qFvO4tfDQ3zeqmPi4sT9My3sO2mJbGvLInxz3XOPJ4RRQn+vtJH0t7/KvQvy/wETbuh56heUa7FeV3jXNI9VZRhabkJ5SZt/Db3nqnFVeXA6nsSFXxERNyjcRgiclwobmNzy6kxetZVhzMMGN41FVIuLEr9fEpBkq65zffQ1CQMnmhUMS7Pb9M+y2JjlYe/Lg9w/az9e5GWlTe/gKtIPS1gKiLiPvX4iMhx68a+MdZUmAzrmuCktqmgc3L7JMO6JHm+bo2gOwdFGFCY5H8/9/POJqcnaFSfGDf0jZHjs/GbMH+HyT0fBqmJ73/lunavh9o4rNnjoSjXJj/Lucqdv8OkNg7DuiYbtrVsWL3HQ598rRt0PNECpiIi7lPwEZHjVshPw6KqANf0ipGwoGO2zY9OjZI0/by6ymZI5wTd29hc2C3BO5t8nNQ2yW2nRfE36sg5p3OSv1xcy1ubvGR7bR5vNBTOsg1+9HY2n5WbDOmU4EenRpmxxseLa5yhdU+fX8ueqMH01T5OKbB4frmfn58e4eu9my/tLZlH5axFRNyn4CMiUueeM1LzcLwGPHwh3H5KdcO38COLEwTMMIM6JJqEnnrd8yy+m+esMfT/VvjZ3qhC3Gd1w90+2ublo21NP3of/iSLSALKIx4W1VWSm7Xey9d7xykPG+QFbLz7DEyuiBjsChv0bquiCZlA5axFRNynOT4iIgfReOiRYcD53RLkBQ68fb0nzgszoijO3ac71eXaZzUNKIVBiz+NqKEkL8mWag/lkaYfx0t2mczbZnLpyzlMmNe0kALADW9kc/2sHNbv9ZCwYFGZ2bB+kKSf+leHenxERNyj4CMi4oJe+RYPnxvh2t5xpl1WwytX1nDTyakepTu/EuXUQotbBzZf7c2yDW59N0jSNnh9vY8Nlakr4nCCht6kRbtMHpiXxXffzOZvK3zuNkpcY9UlH83rEhFxj4KPiIjLSvIssrwwuGOqiMHQLk4VuXM6JzmjYwLTsCnJc+7v3sb512pUTvveuUF++O8gj84PNKkSN22lj1nrncDz28UBajUtKC1pAVMREfdpjo+IyJdkcMck3z8lSp98i0BddjEMeHx4mN0Rg4QFL6/1cWO/GF+dESJuOVfBIZ/N8t3OA/6zA97bkvroXrUnFYLilsG0VX6+fXKM+TtM/rTUT698ix8PjDb8PQ2Ha51UzlpExH0KPiIiXxKPAd8/Jbbf7Vle6BxyrnxvPc25/5kLwtwxJ8j3T4lyUVGCT7abfLDVy+wNPrbV7N9Z/+DZYX4xN8jzy/0sLjN5f6vz8f7JDli7x8Njw8PcOzeLjZUeZt/gYiPliCj4iIi4T8FHRKQVGtghyb+/Xt0w5+OSHgku6ZGgc47Fc583ra7QKz/JxcUJ/rE6waIyL+9vdUpqj+oT46U1fv6zw8t5/wiRtA06ZqsKXGuk4gYiIu5T8BERaaWam+j+o4ExLihKsDdq8ON3sgHoEnIWO71jUJTxHxkM7pDk+6fEaB90ymD/z9IASdugIGjxuwtqCXhDX3JL5FDq53OpuIGIiHsUfERE0kzfdk7/QEleknV7TS7p7hRK6Nfe4sXLa5tse23vOH9d7sey4dGhYYrbaJJPa5TjdY5LXkDHR0TELQo+IiJp6unzw6yq8HBul+QBt2kftHnuYicM9dFip63W6BNjnNwlwGltVJZPRMQtCj4iImmqQ7ZNh+wDh556CjytX8gPV54IZWUtvSciIplL6/iIiIiIiEjGU/AREREREZGMp+AjIiIiIiIZT8FHREREREQynoKPiIiIiIhkPAUfERERERHJeAo+IiIiIiKS8RR8REREREQk4yn4iIiIiIhIxlPwERERERGRjGfYtm239E6IiIiIiIi4ST0+IiIiIiKS8RR8REREREQk4yn4iIiIiIhIxlPwERERERGRjKfgIyIiIiIiGU/BR0REREREMp63pXfAbZZlcf/997Ny5Ur8fj+TJk2iuLi4pXfriF199dXk5uYC0LVrV8aOHcvdd9+NYRj07t2bX/7yl3g86ZNnFy9ezKOPPsrzzz/Phg0bmm3LtGnTeOGFF/B6vdxyyy2cf/75Lb3bh9S4XcuWLWPs2LF0794dgOuvv55LL700rdoVj8e555572LJlC7FYjFtuuYVevXql/fFqrl0nnHBC2h+vZDLJvffeS2lpKaZp8vDDD2Pbdtofr0yl81TrpvNUerRL56n0Ol4tdp6yM9zs2bPtu+66y7Zt2164cKE9duzYFt6jIxeJROyrrrqqyW0/+MEP7Hnz5tm2bdvjx4+3//Wvf7XErh2RZ5991r788svt6667zrbt5tuyc+dO+/LLL7ej0ahdWVnZ8HNrtm+7pk2bZv/pT39qsk26tWv69On2pEmTbNu27d27d9vDhw/PiOPVXLsy4Xi9+eab9t13323btm3PmzfPHjt2bEYcr0yl81TrpfNU+rRL56n0aldLnafS5yuXI7RgwQKGDh0KwMCBA1m6dGkL79GRW7FiBeFwmJtuuokxY8awaNEili1bxhlnnAHAsGHDmDt3bgvv5RdXVFTEU0891fB7c21ZsmQJp512Gn6/n9zcXIqKilixYkVL7fIXsm+7li5dyrvvvss3v/lN7rnnHqqrq9OuXV/96le57bbbGn43TTMjjldz7cqE43XRRRcxceJEALZu3UpBQUFGHK9MpfNU66XzVPq0S+ep9GpXS52nMj74VFdXEwqFGn43TZNEItGCe3TksrKyuPnmm/nTn/7EAw88wLhx47BtG8MwAMjJyaGqqqqF9/KLGzlyJF5varRlc22prq5uGDJRf3t1dfWXvq+HY992DRgwgJ/97Gf87W9/o1u3bvz2t79Nu3bl5OQQCoWorq7m1ltv5fbbb8+I49VcuzLheAF4vV7uuusuJk6cyMiRIzPieGUqnadaL52n0qddOk+lV7ugZc5TGR98QqEQNTU1Db9bltXkzZ5OevTowZVXXolhGPTo0YP8/HzKy8sb7q+pqaFNmzYtuIdHp/GY7/q27Hv8ampqmrwB0sGIESPo379/w8+ff/55WrZr27ZtjBkzhquuuoorrrgiY47Xvu3KlOMF8MgjjzB79mzGjx9PNBptuD2dj1cm0nkqfWTK596+MuVzT+ep9GoXfPnnqYwPPoMGDWLOnDkALFq0iD59+rTwHh256dOnM3nyZAB27NhBdXU155xzDh9//DEAc+bMYfDgwS25i0elX79++7VlwIABLFiwgGg0SlVVFWvXrk27Y3jzzTezZMkSAD766CNOPvnktGvXrl27uOmmm/jpT3/KtddeC2TG8WquXZlwvF5++WX+8Ic/ABAMBjEMg/79+6f98cpUOk+lj0z43GtOJnzu6TyVXu1qqfOUYdu2fUxa0ErVV8tZtWoVtm3z0EMP0bNnz5berSMSi8X4+c9/ztatWzEMg3HjxtG2bVvGjx9PPB6npKSESZMmYZpmS+/qF7Z582buuOMOpk2bRmlpabNtmTZtGlOnTsW2bX7wgx8wcuTIlt7tQ2rcrmXLljFx4kR8Ph8FBQVMnDiRUCiUVu2aNGkSs2bNoqSkpOG2X/ziF0yaNCmtj1dz7br99tuZMmVKWh+v2tpafv7zn7Nr1y4SiQTf+9736NmzZ8a8vzKNzlOtm85T6dEunafS63i11Hkq44OPiIiIiIhIxg91ExERERERUfAREREREZGMp+AjIiIiIiIZT8FHREREREQynoKPiIiIiIhkPAUfkVbkpZde4u67727p3RAREWmWzlOSzhR8REREREQk43lbegdE0tGzzz7LrFmzSCaTnHvuuVx//fX88Ic/pKSkhDVr1tC5c2emTJlCfn4+77zzDk888QSWZdGtWzcmTJhAQUEBc+fOZfLkydi2TefOnXnssccA2LBhAzfccANbt25lyJAhTJo0qYVbKyIi6UbnKZH9qcdH5DDNmTOHpUuXMn36dF5++WV27NjBzJkzWbVqFf/1X//Fa6+9Rs+ePXn66acpLy/nvvvu47e//S0zZ85k0KBBTJgwgVgsxrhx43jkkUeYOXMmffr0YcaMGQBs27aNp556ilmzZjFnzhxWr17dwi0WEZF0ovOUSPPU4yNymD766COWLFnCNddcA0AkEsG2bbp3786ZZ54JwNVXX824ceM455xzGDBgAF27dgVg1KhRPPvss6xcuZKOHTvSt29fAO68807AGTs9ePBg8vPzASgqKqKiouLLbqKIiKQxnadEmqfgI3KYkskkN954I9/5zncAqKysZPv27fz3f/93wza2bWOaJpZlNXmsbdskEgl8Ph+GYTTcXlVVRU1NDQBeb+ptaRgGtm272RwREckwOk/bt2n6AAABNklEQVSJNE9D3UQO01lnncUrr7xCTU0NiUSCH/3oRyxdupTS0lKWL18OwIsvvsiwYcM49dRTWbx4MZs3bwZg6tSpnHnmmfTo0YPy8nLWrFkDwB//+Ef+/ve/t1ibREQkc+g8JdI89fiIHKYLLriAFStW8I1vfINkMsnQoUM5/fTTycvL48knn2Tjxo2ceOKJTJo0iezsbCZMmMCPf/xj4vE4nTt35sEHHyQQCDBlyhR+9rOfEY/HKSoq4le/+hWzZ89u6eaJiEia03lKpHmGrf5JkaO2efNmxowZw9tvv93SuyIiIrIfnadENNRNRERERESOA+rxERERERGRjKceHxERERERyXgKPiIiIiIikvEUfEREREREJOMp+IiIiIiISMZT8BERERERkYyn4CMiIiIiIhnv/wPz+22TnAmsXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(history.keys())\n",
    "\n",
    "# \n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history['loss'], c='dodgerblue', lw=2)\n",
    "plt.plot(history['val_loss'], c='coral', lw=2)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('mse'); plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history['accuracy'], c='dodgerblue', lw=2)\n",
    "plt.plot(history['val_accuracy'], c='coral', lw=2)\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy'); plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T14:56:17.780081Z",
     "start_time": "2020-09-26T14:56:17.272115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('1d+cnn.h5')\n",
    "y_prob = model.predict(X_test, verbose=0)\n",
    "fpr_test,tpr_test,_ = roc_curve(Y_test,y_prob)     \n",
    "auc_test = auc(fpr_test,tpr_test) \n",
    "plt.title('Receiver Operating Characteristic \\nAUC = %0.2f'% auc_test)   \n",
    "plt.plot(fpr_test, tpr_test, c='coral', lw=3)\n",
    "plt.plot([0,1],[0,1], c='dodgerblue', ls='--')\n",
    "plt.ylabel('TPR'); plt.xlabel('FPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T15:56:45.208706Z",
     "start_time": "2020-09-26T15:55:51.131633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.6407 - accuracy: 0.7056 - val_loss: 0.4944 - val_accuracy: 0.7778\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5083 - accuracy: 0.8037 - val_loss: 0.4781 - val_accuracy: 0.8148\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5108 - accuracy: 0.8037 - val_loss: 0.4489 - val_accuracy: 0.7778\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.7897 - val_loss: 0.4632 - val_accuracy: 0.7963\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4892 - accuracy: 0.8037 - val_loss: 0.4524 - val_accuracy: 0.7778\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8084 - val_loss: 0.4548 - val_accuracy: 0.7778\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.7991 - val_loss: 0.4542 - val_accuracy: 0.7963\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.7991 - val_loss: 0.4504 - val_accuracy: 0.8148\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.7944 - val_loss: 0.4509 - val_accuracy: 0.7963\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.8037 - val_loss: 0.4548 - val_accuracy: 0.7963\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4606 - accuracy: 0.8084 - val_loss: 0.4510 - val_accuracy: 0.8148\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4626 - accuracy: 0.8037 - val_loss: 0.4513 - val_accuracy: 0.7963\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4564 - accuracy: 0.7991 - val_loss: 0.4525 - val_accuracy: 0.8148\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4598 - accuracy: 0.7944 - val_loss: 0.4543 - val_accuracy: 0.8148\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4661 - accuracy: 0.7944 - val_loss: 0.4537 - val_accuracy: 0.7963\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4368 - accuracy: 0.7991 - val_loss: 0.4554 - val_accuracy: 0.8148\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4485 - accuracy: 0.8037 - val_loss: 0.4614 - val_accuracy: 0.7778\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4523 - accuracy: 0.8131 - val_loss: 0.4599 - val_accuracy: 0.7778\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4567 - accuracy: 0.8178 - val_loss: 0.4695 - val_accuracy: 0.7778\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.8271 - val_loss: 0.4540 - val_accuracy: 0.7963\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4641 - accuracy: 0.8084 - val_loss: 0.4671 - val_accuracy: 0.7963\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4336 - accuracy: 0.8224 - val_loss: 0.4565 - val_accuracy: 0.8148\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4253 - accuracy: 0.8271 - val_loss: 0.4595 - val_accuracy: 0.8148\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4364 - accuracy: 0.8271 - val_loss: 0.4681 - val_accuracy: 0.7963\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4255 - accuracy: 0.8271 - val_loss: 0.4584 - val_accuracy: 0.8148\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4311 - accuracy: 0.8318 - val_loss: 0.4619 - val_accuracy: 0.8148\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4164 - accuracy: 0.8224 - val_loss: 0.4792 - val_accuracy: 0.7963\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4156 - accuracy: 0.8318 - val_loss: 0.4737 - val_accuracy: 0.8148\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.8411 - val_loss: 0.4751 - val_accuracy: 0.8148\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4058 - accuracy: 0.8411 - val_loss: 0.4902 - val_accuracy: 0.8148\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4538 - accuracy: 0.8458 - val_loss: 0.4723 - val_accuracy: 0.7963\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4081 - accuracy: 0.8411 - val_loss: 0.4714 - val_accuracy: 0.7963\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3767 - accuracy: 0.8598 - val_loss: 0.4902 - val_accuracy: 0.7963\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3679 - accuracy: 0.8505 - val_loss: 0.4710 - val_accuracy: 0.8148\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3640 - accuracy: 0.8551 - val_loss: 0.4691 - val_accuracy: 0.8148\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3556 - accuracy: 0.8598 - val_loss: 0.4591 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3777 - accuracy: 0.8645 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3436 - accuracy: 0.8738 - val_loss: 0.4822 - val_accuracy: 0.7963\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3609 - accuracy: 0.8505 - val_loss: 0.5128 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3405 - accuracy: 0.8551 - val_loss: 0.5329 - val_accuracy: 0.8148\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3366 - accuracy: 0.8692 - val_loss: 0.4749 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3337 - accuracy: 0.8692 - val_loss: 0.4826 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3118 - accuracy: 0.8832 - val_loss: 0.5487 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3118 - accuracy: 0.8832 - val_loss: 0.5147 - val_accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2947 - accuracy: 0.8879 - val_loss: 0.6007 - val_accuracy: 0.8148\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3033 - accuracy: 0.8832 - val_loss: 0.5765 - val_accuracy: 0.7963\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2871 - accuracy: 0.8972 - val_loss: 0.5899 - val_accuracy: 0.7963\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2671 - accuracy: 0.8972 - val_loss: 0.5974 - val_accuracy: 0.8148\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2977 - accuracy: 0.8925 - val_loss: 0.7014 - val_accuracy: 0.7778\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2900 - accuracy: 0.8879 - val_loss: 0.6400 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2631 - accuracy: 0.9112 - val_loss: 0.6523 - val_accuracy: 0.8148\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2422 - accuracy: 0.8972 - val_loss: 0.7210 - val_accuracy: 0.7593\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2535 - accuracy: 0.9019 - val_loss: 0.5933 - val_accuracy: 0.8333\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2407 - accuracy: 0.9112 - val_loss: 0.6670 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2170 - accuracy: 0.9299 - val_loss: 0.7132 - val_accuracy: 0.7778\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2252 - accuracy: 0.9206 - val_loss: 0.7314 - val_accuracy: 0.8148\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2067 - accuracy: 0.9206 - val_loss: 0.8335 - val_accuracy: 0.8148\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2334 - accuracy: 0.9112 - val_loss: 0.9162 - val_accuracy: 0.7593\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2188 - accuracy: 0.9159 - val_loss: 0.8724 - val_accuracy: 0.8148\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2227 - accuracy: 0.9112 - val_loss: 0.8201 - val_accuracy: 0.7963\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2153 - accuracy: 0.9206 - val_loss: 0.9352 - val_accuracy: 0.7593\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9206 - val_loss: 0.8163 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2344 - accuracy: 0.9112 - val_loss: 1.3078 - val_accuracy: 0.7593\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2916 - accuracy: 0.8832 - val_loss: 0.8463 - val_accuracy: 0.8148\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.8972 - val_loss: 0.8421 - val_accuracy: 0.7778\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.9019 - val_loss: 0.8850 - val_accuracy: 0.7407\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2167 - accuracy: 0.9206 - val_loss: 0.6692 - val_accuracy: 0.8148\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2387 - accuracy: 0.9159 - val_loss: 0.7980 - val_accuracy: 0.8148\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.9112 - val_loss: 0.8293 - val_accuracy: 0.7963\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2078 - accuracy: 0.9252 - val_loss: 0.7965 - val_accuracy: 0.7778\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1995 - accuracy: 0.9299 - val_loss: 0.8118 - val_accuracy: 0.7963\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1817 - accuracy: 0.9346 - val_loss: 0.8670 - val_accuracy: 0.7963\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1683 - accuracy: 0.9393 - val_loss: 0.9362 - val_accuracy: 0.7963\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1859 - accuracy: 0.9252 - val_loss: 0.9606 - val_accuracy: 0.7963\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1822 - accuracy: 0.9299 - val_loss: 1.0158 - val_accuracy: 0.7778\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1781 - accuracy: 0.9252 - val_loss: 1.1357 - val_accuracy: 0.7778\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1899 - accuracy: 0.9159 - val_loss: 0.9774 - val_accuracy: 0.7963\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1743 - accuracy: 0.9299 - val_loss: 0.9737 - val_accuracy: 0.7963\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1547 - accuracy: 0.9346 - val_loss: 1.0743 - val_accuracy: 0.7778\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.9439 - val_loss: 1.1520 - val_accuracy: 0.7778\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.9439 - val_loss: 1.1967 - val_accuracy: 0.7778\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1589 - accuracy: 0.9252 - val_loss: 1.3804 - val_accuracy: 0.7593\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2412 - accuracy: 0.9252 - val_loss: 1.3000 - val_accuracy: 0.7778\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9393 - val_loss: 1.0539 - val_accuracy: 0.7778\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2406 - accuracy: 0.8645 - val_loss: 1.0299 - val_accuracy: 0.7963\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1723 - accuracy: 0.9346 - val_loss: 1.0956 - val_accuracy: 0.7963\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.9206 - val_loss: 1.0625 - val_accuracy: 0.7778\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9346 - val_loss: 1.0540 - val_accuracy: 0.8148\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1574 - accuracy: 0.9346 - val_loss: 1.0582 - val_accuracy: 0.7963\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1460 - accuracy: 0.9486 - val_loss: 1.1032 - val_accuracy: 0.7778\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9393 - val_loss: 1.1684 - val_accuracy: 0.8148\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1430 - accuracy: 0.9486 - val_loss: 1.2504 - val_accuracy: 0.7593\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1160 - accuracy: 0.9533 - val_loss: 1.2800 - val_accuracy: 0.7778\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1362 - accuracy: 0.9439 - val_loss: 1.2459 - val_accuracy: 0.7963\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1125 - accuracy: 0.9766 - val_loss: 1.3991 - val_accuracy: 0.7593\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0854 - accuracy: 0.9766 - val_loss: 1.4275 - val_accuracy: 0.7963\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9486 - val_loss: 1.3464 - val_accuracy: 0.7778\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.9720 - val_loss: 1.3373 - val_accuracy: 0.7778\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0929 - accuracy: 0.9579 - val_loss: 1.3920 - val_accuracy: 0.7778\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0806 - accuracy: 0.9673 - val_loss: 1.4440 - val_accuracy: 0.7963\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0889 - accuracy: 0.9720 - val_loss: 1.5469 - val_accuracy: 0.7963\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0886 - accuracy: 0.9673 - val_loss: 1.5587 - val_accuracy: 0.7963\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9766 - val_loss: 1.5867 - val_accuracy: 0.7963\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.9673 - val_loss: 1.6152 - val_accuracy: 0.7778\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9626 - val_loss: 1.6444 - val_accuracy: 0.7593\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9579 - val_loss: 1.7411 - val_accuracy: 0.7593\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9720 - val_loss: 1.7309 - val_accuracy: 0.7407\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0920 - accuracy: 0.9533 - val_loss: 1.6759 - val_accuracy: 0.7593\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9673 - val_loss: 1.6539 - val_accuracy: 0.7778\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9673 - val_loss: 1.6454 - val_accuracy: 0.7963\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0652 - accuracy: 0.9860 - val_loss: 1.8444 - val_accuracy: 0.7407\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9533 - val_loss: 1.7558 - val_accuracy: 0.7963\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0682 - accuracy: 0.9673 - val_loss: 1.6806 - val_accuracy: 0.7778\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9813 - val_loss: 1.6499 - val_accuracy: 0.7778\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9907 - val_loss: 1.7490 - val_accuracy: 0.7593\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0623 - accuracy: 0.9720 - val_loss: 1.8413 - val_accuracy: 0.7593\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 0.9720 - val_loss: 1.8817 - val_accuracy: 0.7593\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9813 - val_loss: 1.8188 - val_accuracy: 0.7963\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0635 - accuracy: 0.9953 - val_loss: 1.9798 - val_accuracy: 0.7222\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 2.0591 - val_accuracy: 0.7407\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 0.9907 - val_loss: 1.9633 - val_accuracy: 0.7593\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.9834 - val_accuracy: 0.7593\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9907 - val_loss: 2.1443 - val_accuracy: 0.7593\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.9953 - val_loss: 2.2146 - val_accuracy: 0.7593\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9860 - val_loss: 2.1509 - val_accuracy: 0.7593\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0424 - accuracy: 0.9860 - val_loss: 2.1344 - val_accuracy: 0.7593\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.9907 - val_loss: 2.2419 - val_accuracy: 0.7593\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 2.3405 - val_accuracy: 0.7593\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9953 - val_loss: 2.2707 - val_accuracy: 0.7963\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9907 - val_loss: 2.1575 - val_accuracy: 0.7778\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9813 - val_loss: 2.2709 - val_accuracy: 0.7778\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0327 - accuracy: 0.9860 - val_loss: 2.0614 - val_accuracy: 0.7778\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 1.9677 - val_accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9907 - val_loss: 1.9204 - val_accuracy: 0.7963\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9907 - val_loss: 2.0410 - val_accuracy: 0.7407\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0676 - accuracy: 0.9766 - val_loss: 1.9132 - val_accuracy: 0.8148\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0570 - accuracy: 0.9673 - val_loss: 2.0327 - val_accuracy: 0.7778\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1197 - accuracy: 0.9860 - val_loss: 2.2957 - val_accuracy: 0.7593\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0860 - accuracy: 0.9813 - val_loss: 2.1015 - val_accuracy: 0.8148\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9860 - val_loss: 1.6691 - val_accuracy: 0.8148\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9673 - val_loss: 2.0769 - val_accuracy: 0.7778\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1254 - accuracy: 0.9579 - val_loss: 2.1482 - val_accuracy: 0.8148\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: 1.9334 - val_accuracy: 0.7963\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0653 - accuracy: 0.9813 - val_loss: 1.8603 - val_accuracy: 0.7963\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9813 - val_loss: 1.9581 - val_accuracy: 0.7778\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9860 - val_loss: 2.1487 - val_accuracy: 0.7778\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0370 - accuracy: 0.9953 - val_loss: 2.2171 - val_accuracy: 0.7778\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 2.3075 - val_accuracy: 0.7593\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9766 - val_loss: 2.3494 - val_accuracy: 0.7778\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 2.3604 - val_accuracy: 0.7593\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 2.3988 - val_accuracy: 0.7778\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 2.4045 - val_accuracy: 0.7778\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 2.3856 - val_accuracy: 0.7778\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 2.3921 - val_accuracy: 0.7778\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 2.4551 - val_accuracy: 0.7778\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.5335 - val_accuracy: 0.7778\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 2.5831 - val_accuracy: 0.7778\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 2.5363 - val_accuracy: 0.7593\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 2.5559 - val_accuracy: 0.7593\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9907 - val_loss: 2.6372 - val_accuracy: 0.7593\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.6994 - val_accuracy: 0.7593\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 2.6944 - val_accuracy: 0.7593\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 0.9907 - val_loss: 2.7155 - val_accuracy: 0.7593\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 2.7424 - val_accuracy: 0.7593\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0136 - accuracy: 0.9907 - val_loss: 2.7938 - val_accuracy: 0.7593\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 0.9953 - val_loss: 2.8358 - val_accuracy: 0.7593\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 2.8061 - val_accuracy: 0.7778\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0172 - accuracy: 0.9907 - val_loss: 2.8466 - val_accuracy: 0.7778\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 2.8693 - val_accuracy: 0.7778\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9907 - val_loss: 2.9027 - val_accuracy: 0.7593\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 2.9479 - val_accuracy: 0.7593\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 2.9515 - val_accuracy: 0.7593\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9953 - val_loss: 2.9399 - val_accuracy: 0.7778\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 0.9907 - val_loss: 2.9427 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 2.9419 - val_accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9907 - val_loss: 2.9237 - val_accuracy: 0.7778\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 2.9427 - val_accuracy: 0.7778\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.9778 - val_accuracy: 0.7778\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9953 - val_loss: 3.0043 - val_accuracy: 0.7778\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 3.0294 - val_accuracy: 0.7778\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 3.0210 - val_accuracy: 0.7778\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9907 - val_loss: 2.9868 - val_accuracy: 0.7778\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 2.9176 - val_accuracy: 0.7778\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9953 - val_loss: 3.0862 - val_accuracy: 0.7407\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 2.8751 - val_accuracy: 0.7778\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.7464 - val_accuracy: 0.7778\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 0.9907 - val_loss: 2.7380 - val_accuracy: 0.7963\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 2.7849 - val_accuracy: 0.7778\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.9953 - val_loss: 2.8462 - val_accuracy: 0.7778\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9907 - val_loss: 2.9152 - val_accuracy: 0.7778\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9907 - val_loss: 2.9390 - val_accuracy: 0.7778\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9907 - val_loss: 2.9554 - val_accuracy: 0.7778\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 2.9945 - val_accuracy: 0.7778\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 2.9834 - val_accuracy: 0.7778\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 2.9821 - val_accuracy: 0.7778\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 3.0173 - val_accuracy: 0.7778\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9953 - val_loss: 3.0578 - val_accuracy: 0.7778\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 3.0869 - val_accuracy: 0.7778\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 0.9953 - val_loss: 3.1013 - val_accuracy: 0.7778\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.9907 - val_loss: 3.0992 - val_accuracy: 0.7778\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BC41D9E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.6484 - accuracy: 0.6869 - val_loss: 0.5047 - val_accuracy: 0.7778\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8037 - val_loss: 0.5523 - val_accuracy: 0.7593\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5207 - accuracy: 0.7991 - val_loss: 0.4971 - val_accuracy: 0.7407\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4785 - accuracy: 0.8037 - val_loss: 0.4653 - val_accuracy: 0.7963\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4855 - accuracy: 0.8037 - val_loss: 0.4578 - val_accuracy: 0.8148\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4860 - accuracy: 0.7991 - val_loss: 0.4966 - val_accuracy: 0.7593\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4883 - accuracy: 0.7991 - val_loss: 0.5084 - val_accuracy: 0.7593\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.8037 - val_loss: 0.4739 - val_accuracy: 0.7778\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.7991 - val_loss: 0.4389 - val_accuracy: 0.8148\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.7991 - val_loss: 0.4435 - val_accuracy: 0.8148\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.8037 - val_loss: 0.4932 - val_accuracy: 0.7778\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7991 - val_loss: 0.4655 - val_accuracy: 0.7963\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.8037 - val_loss: 0.4580 - val_accuracy: 0.7963\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4702 - accuracy: 0.8037 - val_loss: 0.4904 - val_accuracy: 0.7778\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4697 - accuracy: 0.8084 - val_loss: 0.4929 - val_accuracy: 0.7778\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4643 - accuracy: 0.8037 - val_loss: 0.4757 - val_accuracy: 0.7963\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4588 - accuracy: 0.8084 - val_loss: 0.4644 - val_accuracy: 0.7963\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4475 - accuracy: 0.8037 - val_loss: 0.4706 - val_accuracy: 0.7963\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4532 - accuracy: 0.8037 - val_loss: 0.4830 - val_accuracy: 0.7778\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4466 - accuracy: 0.8084 - val_loss: 0.4692 - val_accuracy: 0.7778\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4489 - accuracy: 0.8178 - val_loss: 0.4935 - val_accuracy: 0.7593\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.8084 - val_loss: 0.4767 - val_accuracy: 0.7778\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.8411 - val_loss: 0.4850 - val_accuracy: 0.7593\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8224 - val_loss: 0.4867 - val_accuracy: 0.7778\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.8131 - val_loss: 0.5244 - val_accuracy: 0.7963\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8411 - val_loss: 0.5120 - val_accuracy: 0.7778\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8364 - val_loss: 0.5450 - val_accuracy: 0.7593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4074 - accuracy: 0.8411 - val_loss: 0.5693 - val_accuracy: 0.7593\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3890 - accuracy: 0.8364 - val_loss: 0.5410 - val_accuracy: 0.8148\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8084 - val_loss: 0.5769 - val_accuracy: 0.7593\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8411 - val_loss: 0.5973 - val_accuracy: 0.7593\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8551 - val_loss: 0.6162 - val_accuracy: 0.7963\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.8411 - val_loss: 0.5984 - val_accuracy: 0.7778\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8645 - val_loss: 0.5716 - val_accuracy: 0.7593\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8458 - val_loss: 0.5916 - val_accuracy: 0.7778\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.8598 - val_loss: 0.6164 - val_accuracy: 0.7963\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8692 - val_loss: 0.6904 - val_accuracy: 0.7778\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3385 - accuracy: 0.8645 - val_loss: 0.7578 - val_accuracy: 0.7593\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.8692 - val_loss: 0.6161 - val_accuracy: 0.8148\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8692 - val_loss: 0.7152 - val_accuracy: 0.7778\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.8645 - val_loss: 0.7142 - val_accuracy: 0.7963\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3129 - accuracy: 0.8832 - val_loss: 0.8218 - val_accuracy: 0.7778\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8879 - val_loss: 0.8100 - val_accuracy: 0.7963\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2984 - accuracy: 0.8879 - val_loss: 0.8389 - val_accuracy: 0.7778\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2886 - accuracy: 0.8785 - val_loss: 0.7935 - val_accuracy: 0.7963\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8551 - val_loss: 0.8311 - val_accuracy: 0.7963\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2708 - accuracy: 0.8879 - val_loss: 0.8665 - val_accuracy: 0.7778\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.8879 - val_loss: 0.8477 - val_accuracy: 0.7778\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2649 - accuracy: 0.8879 - val_loss: 0.8586 - val_accuracy: 0.7778\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2703 - accuracy: 0.8972 - val_loss: 0.8497 - val_accuracy: 0.7963\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2528 - accuracy: 0.8972 - val_loss: 0.9114 - val_accuracy: 0.7778\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2677 - accuracy: 0.8925 - val_loss: 0.9299 - val_accuracy: 0.7963\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2336 - accuracy: 0.9065 - val_loss: 0.8888 - val_accuracy: 0.7963\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2267 - accuracy: 0.9159 - val_loss: 1.0442 - val_accuracy: 0.7778\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2294 - accuracy: 0.9065 - val_loss: 0.9991 - val_accuracy: 0.7963\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2557 - accuracy: 0.9019 - val_loss: 1.3130 - val_accuracy: 0.7222\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2656 - accuracy: 0.9019 - val_loss: 1.1479 - val_accuracy: 0.7407\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.9065 - val_loss: 1.1325 - val_accuracy: 0.7778\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.9019 - val_loss: 1.0754 - val_accuracy: 0.7778\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2418 - accuracy: 0.8972 - val_loss: 1.0865 - val_accuracy: 0.7963\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2095 - accuracy: 0.9206 - val_loss: 1.1172 - val_accuracy: 0.7222\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2062 - accuracy: 0.9252 - val_loss: 1.2887 - val_accuracy: 0.7037\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2003 - accuracy: 0.9252 - val_loss: 1.3408 - val_accuracy: 0.7778\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1743 - accuracy: 0.9346 - val_loss: 1.3796 - val_accuracy: 0.7593\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1746 - accuracy: 0.9252 - val_loss: 1.6091 - val_accuracy: 0.7037\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.9393 - val_loss: 1.5289 - val_accuracy: 0.7407\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1578 - accuracy: 0.9252 - val_loss: 1.8503 - val_accuracy: 0.7407\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1640 - accuracy: 0.9393 - val_loss: 1.7115 - val_accuracy: 0.6296\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1434 - accuracy: 0.9439 - val_loss: 1.9216 - val_accuracy: 0.7407\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2072 - accuracy: 0.9393 - val_loss: 1.5861 - val_accuracy: 0.7407\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1453 - accuracy: 0.9579 - val_loss: 1.8166 - val_accuracy: 0.6852\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1367 - accuracy: 0.9486 - val_loss: 1.8252 - val_accuracy: 0.7222\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1168 - accuracy: 0.9579 - val_loss: 1.7479 - val_accuracy: 0.7593\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9533 - val_loss: 1.7811 - val_accuracy: 0.7593\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1001 - accuracy: 0.9673 - val_loss: 2.1409 - val_accuracy: 0.7037\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1229 - accuracy: 0.9720 - val_loss: 1.7929 - val_accuracy: 0.7593\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1148 - accuracy: 0.9579 - val_loss: 2.2590 - val_accuracy: 0.7593\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9673 - val_loss: 2.2343 - val_accuracy: 0.6852\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.9813 - val_loss: 2.2321 - val_accuracy: 0.6667\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9720 - val_loss: 2.1063 - val_accuracy: 0.7407\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1060 - accuracy: 0.9673 - val_loss: 2.3446 - val_accuracy: 0.7407\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1100 - accuracy: 0.9673 - val_loss: 2.2715 - val_accuracy: 0.7222\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0877 - accuracy: 0.9720 - val_loss: 2.2620 - val_accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.9579 - val_loss: 2.0000 - val_accuracy: 0.7222\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.9439 - val_loss: 2.1993 - val_accuracy: 0.7222\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9766 - val_loss: 2.4864 - val_accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9673 - val_loss: 2.1201 - val_accuracy: 0.6852\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1082 - accuracy: 0.9579 - val_loss: 1.8205 - val_accuracy: 0.7407\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1458 - accuracy: 0.9533 - val_loss: 2.5128 - val_accuracy: 0.7037\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1057 - accuracy: 0.9533 - val_loss: 2.2541 - val_accuracy: 0.7037\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0717 - accuracy: 0.9813 - val_loss: 2.2130 - val_accuracy: 0.7037\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0939 - accuracy: 0.9673 - val_loss: 2.1746 - val_accuracy: 0.7037\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0777 - accuracy: 0.9720 - val_loss: 2.0569 - val_accuracy: 0.7778\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.9673 - val_loss: 2.2250 - val_accuracy: 0.6481\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0700 - accuracy: 0.9813 - val_loss: 2.6982 - val_accuracy: 0.7222\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.9813 - val_loss: 2.6766 - val_accuracy: 0.6852\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0720 - accuracy: 0.9813 - val_loss: 2.6968 - val_accuracy: 0.7037\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 2.8008 - val_accuracy: 0.7037\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9813 - val_loss: 2.6042 - val_accuracy: 0.6852\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 2.6495 - val_accuracy: 0.7222\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9813 - val_loss: 2.7090 - val_accuracy: 0.6667\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9907 - val_loss: 2.7593 - val_accuracy: 0.6667\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 2.8354 - val_accuracy: 0.7407\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9813 - val_loss: 2.9981 - val_accuracy: 0.7778\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9907 - val_loss: 2.9143 - val_accuracy: 0.7222\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9766 - val_loss: 2.9925 - val_accuracy: 0.6852\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9860 - val_loss: 3.1373 - val_accuracy: 0.6852\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 3.1493 - val_accuracy: 0.6852\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 3.0959 - val_accuracy: 0.6852\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9907 - val_loss: 3.1616 - val_accuracy: 0.6667\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9907 - val_loss: 3.3820 - val_accuracy: 0.7037\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9813 - val_loss: 3.2018 - val_accuracy: 0.6667\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 2.9984 - val_accuracy: 0.7037\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 3.0195 - val_accuracy: 0.6852\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.9813 - val_loss: 3.0287 - val_accuracy: 0.6667\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9860 - val_loss: 3.1684 - val_accuracy: 0.7222\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9813 - val_loss: 3.0836 - val_accuracy: 0.7037\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9953 - val_loss: 3.0914 - val_accuracy: 0.6296\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0457 - accuracy: 0.9813 - val_loss: 3.4509 - val_accuracy: 0.7037\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 3.3327 - val_accuracy: 0.7037\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9860 - val_loss: 2.9481 - val_accuracy: 0.6852\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1072 - accuracy: 0.9720 - val_loss: 2.9298 - val_accuracy: 0.7593\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9953 - val_loss: 3.2645 - val_accuracy: 0.7407\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9673 - val_loss: 3.3552 - val_accuracy: 0.7037\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9907 - val_loss: 2.6029 - val_accuracy: 0.6481\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0650 - accuracy: 0.9720 - val_loss: 2.6805 - val_accuracy: 0.7407\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9813 - val_loss: 3.0755 - val_accuracy: 0.7778\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9907 - val_loss: 2.8841 - val_accuracy: 0.7407\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9953 - val_loss: 2.6894 - val_accuracy: 0.6852\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9953 - val_loss: 2.9289 - val_accuracy: 0.7407\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9907 - val_loss: 3.5970 - val_accuracy: 0.7407\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9907 - val_loss: 3.4536 - val_accuracy: 0.7037\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 3.2851 - val_accuracy: 0.6667\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 3.2955 - val_accuracy: 0.6852\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 3.4652 - val_accuracy: 0.7407\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 3.6286 - val_accuracy: 0.7222\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 0.9860 - val_loss: 3.5590 - val_accuracy: 0.7037\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9813 - val_loss: 3.7045 - val_accuracy: 0.7407\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 3.7745 - val_accuracy: 0.7593\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9907 - val_loss: 3.3212 - val_accuracy: 0.7222\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 3.2523 - val_accuracy: 0.6667\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 3.6742 - val_accuracy: 0.7222\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 3.8930 - val_accuracy: 0.7407\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 0.9907 - val_loss: 3.3036 - val_accuracy: 0.6481\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9907 - val_loss: 3.3162 - val_accuracy: 0.6667\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9860 - val_loss: 3.4544 - val_accuracy: 0.7407\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 3.5346 - val_accuracy: 0.7222\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 3.6425 - val_accuracy: 0.7222\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9907 - val_loss: 3.9742 - val_accuracy: 0.7222\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 4.2428 - val_accuracy: 0.7407\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.9907 - val_loss: 4.0117 - val_accuracy: 0.7037\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 3.7753 - val_accuracy: 0.7037\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.7773 - val_accuracy: 0.7222\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 3.8378 - val_accuracy: 0.7407\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 4.0259 - val_accuracy: 0.7222\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9907 - val_loss: 4.0643 - val_accuracy: 0.7222\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 3.9688 - val_accuracy: 0.7222\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 0.9907 - val_loss: 3.9468 - val_accuracy: 0.6852\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.9680 - val_accuracy: 0.6667\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 3.9314 - val_accuracy: 0.7037\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9953 - val_loss: 3.9118 - val_accuracy: 0.7037\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 3.9567 - val_accuracy: 0.7037\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9907 - val_loss: 4.1430 - val_accuracy: 0.7593\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 8ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 4.2429 - val_accuracy: 0.7778\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 4.1780 - val_accuracy: 0.7778\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.9953 - val_loss: 4.1244 - val_accuracy: 0.7593\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 0.9953 - val_loss: 4.1173 - val_accuracy: 0.7593\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 4.1662 - val_accuracy: 0.7407\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.1173 - val_accuracy: 0.7037\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 0.9907 - val_loss: 4.1663 - val_accuracy: 0.7037\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 0.9953 - val_loss: 4.2491 - val_accuracy: 0.7037\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9953 - val_loss: 4.2656 - val_accuracy: 0.7037\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9953 - val_loss: 4.2768 - val_accuracy: 0.7222\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9953 - val_loss: 4.2515 - val_accuracy: 0.7222\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9953 - val_loss: 4.2199 - val_accuracy: 0.7222\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9953 - val_loss: 4.2392 - val_accuracy: 0.7407\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9907 - val_loss: 4.2341 - val_accuracy: 0.7222\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9907 - val_loss: 4.3287 - val_accuracy: 0.7407\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 0.9953 - val_loss: 4.3332 - val_accuracy: 0.7222\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 0.9953 - val_loss: 4.3464 - val_accuracy: 0.7407\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9907 - val_loss: 4.3848 - val_accuracy: 0.7407\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.9953 - val_loss: 4.4608 - val_accuracy: 0.7407\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 0.9907 - val_loss: 4.4887 - val_accuracy: 0.7407\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9953 - val_loss: 4.4910 - val_accuracy: 0.7222\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.9953 - val_loss: 4.5205 - val_accuracy: 0.7222\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.5265 - val_accuracy: 0.7222\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9953 - val_loss: 4.5293 - val_accuracy: 0.7222\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.9953 - val_loss: 4.5433 - val_accuracy: 0.7222\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.5003 - val_accuracy: 0.7037\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.9907 - val_loss: 4.4815 - val_accuracy: 0.7222\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.5340 - val_accuracy: 0.7222\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.5992 - val_accuracy: 0.7037\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9953 - val_loss: 4.6376 - val_accuracy: 0.7222\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9953 - val_loss: 4.7832 - val_accuracy: 0.7407\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.8873 - val_accuracy: 0.7222\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9953 - val_loss: 4.8846 - val_accuracy: 0.7222\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 4.6693 - val_accuracy: 0.7037\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.9953 - val_loss: 4.5577 - val_accuracy: 0.7222\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.5516 - val_accuracy: 0.7407\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 5.6410 - val_accuracy: 0.7037\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BE34DFE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.6336 - accuracy: 0.7056 - val_loss: 0.4543 - val_accuracy: 0.7963\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4982 - accuracy: 0.7991 - val_loss: 0.4381 - val_accuracy: 0.7778\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.8084 - val_loss: 0.5843 - val_accuracy: 0.6852\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.7383 - val_loss: 0.4818 - val_accuracy: 0.7963\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.7944 - val_loss: 0.4498 - val_accuracy: 0.7778\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5002 - accuracy: 0.7897 - val_loss: 0.4554 - val_accuracy: 0.7778\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4918 - accuracy: 0.8224 - val_loss: 0.4725 - val_accuracy: 0.7593\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.8224 - val_loss: 0.4644 - val_accuracy: 0.7778\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4805 - accuracy: 0.8084 - val_loss: 0.4583 - val_accuracy: 0.7778\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4867 - accuracy: 0.8084 - val_loss: 0.4694 - val_accuracy: 0.7778\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4521 - accuracy: 0.8178 - val_loss: 0.4838 - val_accuracy: 0.7593\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.8178 - val_loss: 0.4775 - val_accuracy: 0.7593\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.8271 - val_loss: 0.4636 - val_accuracy: 0.7593\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.8131 - val_loss: 0.4650 - val_accuracy: 0.7593\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.8131 - val_loss: 0.4798 - val_accuracy: 0.7778\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.8131 - val_loss: 0.4907 - val_accuracy: 0.7593\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.8224 - val_loss: 0.5072 - val_accuracy: 0.7593\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.8224 - val_loss: 0.4972 - val_accuracy: 0.7593\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8318 - val_loss: 0.5110 - val_accuracy: 0.7593\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8318 - val_loss: 0.5138 - val_accuracy: 0.7593\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.8318 - val_loss: 0.5136 - val_accuracy: 0.7778\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.8271 - val_loss: 0.5590 - val_accuracy: 0.7778\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.8318 - val_loss: 0.5397 - val_accuracy: 0.7778\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.8318 - val_loss: 0.5313 - val_accuracy: 0.7593\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.8318 - val_loss: 0.5439 - val_accuracy: 0.7593\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8364 - val_loss: 0.4801 - val_accuracy: 0.7778\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8318 - val_loss: 0.4894 - val_accuracy: 0.7778\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8364 - val_loss: 0.5547 - val_accuracy: 0.7593\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8411 - val_loss: 0.5683 - val_accuracy: 0.7593\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.8318 - val_loss: 0.5609 - val_accuracy: 0.7593\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8458 - val_loss: 0.4938 - val_accuracy: 0.7778\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.8271 - val_loss: 0.4960 - val_accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.8178 - val_loss: 0.5345 - val_accuracy: 0.7593\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8505 - val_loss: 0.5038 - val_accuracy: 0.7778\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.8364 - val_loss: 0.5418 - val_accuracy: 0.7963\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8364 - val_loss: 0.5745 - val_accuracy: 0.7963\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8458 - val_loss: 0.6041 - val_accuracy: 0.7407\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8458 - val_loss: 0.5801 - val_accuracy: 0.7407\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8551 - val_loss: 0.4752 - val_accuracy: 0.7778\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8458 - val_loss: 0.5639 - val_accuracy: 0.7778\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8364 - val_loss: 0.6510 - val_accuracy: 0.7037\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8645 - val_loss: 0.5893 - val_accuracy: 0.7778\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8505 - val_loss: 0.7065 - val_accuracy: 0.7593\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3775 - accuracy: 0.8551 - val_loss: 0.4819 - val_accuracy: 0.8148\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3678 - accuracy: 0.8645 - val_loss: 0.5918 - val_accuracy: 0.7778\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.8692 - val_loss: 0.7354 - val_accuracy: 0.7407\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3548 - accuracy: 0.8551 - val_loss: 0.5153 - val_accuracy: 0.7778\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3640 - accuracy: 0.8738 - val_loss: 0.6790 - val_accuracy: 0.7593\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3353 - accuracy: 0.8598 - val_loss: 0.5440 - val_accuracy: 0.8148\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3435 - accuracy: 0.8832 - val_loss: 0.6454 - val_accuracy: 0.7778\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3132 - accuracy: 0.8832 - val_loss: 0.7024 - val_accuracy: 0.7593\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3083 - accuracy: 0.8832 - val_loss: 0.5739 - val_accuracy: 0.7778\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2968 - accuracy: 0.8832 - val_loss: 0.7465 - val_accuracy: 0.7963\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2916 - accuracy: 0.8925 - val_loss: 0.6655 - val_accuracy: 0.7407\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8551 - val_loss: 1.1395 - val_accuracy: 0.7222\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3651 - accuracy: 0.8458 - val_loss: 0.4441 - val_accuracy: 0.8519\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8505 - val_loss: 0.4477 - val_accuracy: 0.8148\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3267 - accuracy: 0.8785 - val_loss: 0.6917 - val_accuracy: 0.7593\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3116 - accuracy: 0.8925 - val_loss: 0.6455 - val_accuracy: 0.7963\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2786 - accuracy: 0.9065 - val_loss: 0.6052 - val_accuracy: 0.7778\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.8925 - val_loss: 0.8077 - val_accuracy: 0.7963\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2683 - accuracy: 0.9019 - val_loss: 0.7968 - val_accuracy: 0.7593\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2545 - accuracy: 0.9019 - val_loss: 0.9596 - val_accuracy: 0.7407\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2462 - accuracy: 0.9065 - val_loss: 0.8090 - val_accuracy: 0.7963\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2353 - accuracy: 0.9159 - val_loss: 0.6744 - val_accuracy: 0.7593\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2409 - accuracy: 0.9112 - val_loss: 0.9268 - val_accuracy: 0.7963\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2517 - accuracy: 0.9019 - val_loss: 0.7511 - val_accuracy: 0.7407\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2445 - accuracy: 0.9065 - val_loss: 0.8296 - val_accuracy: 0.7778\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2485 - accuracy: 0.9065 - val_loss: 0.7054 - val_accuracy: 0.7963\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2097 - accuracy: 0.9252 - val_loss: 0.9306 - val_accuracy: 0.7593\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2172 - accuracy: 0.9252 - val_loss: 0.9462 - val_accuracy: 0.7963\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2112 - accuracy: 0.9206 - val_loss: 0.8788 - val_accuracy: 0.7963\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1986 - accuracy: 0.9299 - val_loss: 1.0657 - val_accuracy: 0.7593\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.9159 - val_loss: 0.8438 - val_accuracy: 0.7778\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1960 - accuracy: 0.9206 - val_loss: 1.1041 - val_accuracy: 0.7778\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1957 - accuracy: 0.9252 - val_loss: 1.4732 - val_accuracy: 0.7593\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2070 - accuracy: 0.9299 - val_loss: 1.0215 - val_accuracy: 0.7963\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.9252 - val_loss: 1.0920 - val_accuracy: 0.7222\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.9299 - val_loss: 1.2135 - val_accuracy: 0.7593\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1858 - accuracy: 0.9299 - val_loss: 1.1079 - val_accuracy: 0.7407\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1799 - accuracy: 0.9346 - val_loss: 1.3454 - val_accuracy: 0.7593\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.9439 - val_loss: 1.3755 - val_accuracy: 0.7778\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9299 - val_loss: 1.1606 - val_accuracy: 0.8148\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1752 - accuracy: 0.9252 - val_loss: 1.1781 - val_accuracy: 0.7778\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1663 - accuracy: 0.9393 - val_loss: 1.3320 - val_accuracy: 0.7407\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1613 - accuracy: 0.9393 - val_loss: 1.1975 - val_accuracy: 0.7037\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1395 - accuracy: 0.9486 - val_loss: 1.0391 - val_accuracy: 0.7222\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.9533 - val_loss: 1.2161 - val_accuracy: 0.7593\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9486 - val_loss: 1.3016 - val_accuracy: 0.7778\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1171 - accuracy: 0.9579 - val_loss: 1.3882 - val_accuracy: 0.7778\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1206 - accuracy: 0.9439 - val_loss: 1.1990 - val_accuracy: 0.7963\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1228 - accuracy: 0.9486 - val_loss: 1.4327 - val_accuracy: 0.7963\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.9579 - val_loss: 1.1846 - val_accuracy: 0.7778\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.9533 - val_loss: 1.4574 - val_accuracy: 0.7778\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1591 - accuracy: 0.9533 - val_loss: 2.9662 - val_accuracy: 0.7037\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2311 - accuracy: 0.9159 - val_loss: 1.4038 - val_accuracy: 0.7407\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1845 - accuracy: 0.9346 - val_loss: 1.2735 - val_accuracy: 0.7407\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9206 - val_loss: 1.5168 - val_accuracy: 0.7778\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1691 - accuracy: 0.9346 - val_loss: 1.9057 - val_accuracy: 0.7963\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1820 - accuracy: 0.9206 - val_loss: 0.8497 - val_accuracy: 0.7593\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1852 - accuracy: 0.9346 - val_loss: 1.8467 - val_accuracy: 0.7222\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2846 - accuracy: 0.8972 - val_loss: 0.8667 - val_accuracy: 0.8148\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2319 - accuracy: 0.8738 - val_loss: 0.8310 - val_accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1658 - accuracy: 0.9439 - val_loss: 1.0966 - val_accuracy: 0.7963\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1808 - accuracy: 0.9393 - val_loss: 0.7529 - val_accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1488 - accuracy: 0.9346 - val_loss: 0.7643 - val_accuracy: 0.7593\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9533 - val_loss: 1.1364 - val_accuracy: 0.7963\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.9533 - val_loss: 1.1527 - val_accuracy: 0.7963\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9720 - val_loss: 0.9848 - val_accuracy: 0.8148\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9579 - val_loss: 1.1277 - val_accuracy: 0.8148\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9720 - val_loss: 1.2803 - val_accuracy: 0.7963\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0898 - accuracy: 0.9626 - val_loss: 1.3207 - val_accuracy: 0.7963\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0780 - accuracy: 0.9860 - val_loss: 1.3651 - val_accuracy: 0.7963\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0738 - accuracy: 0.9766 - val_loss: 1.3101 - val_accuracy: 0.8148\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0816 - accuracy: 0.9626 - val_loss: 1.5392 - val_accuracy: 0.7963\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0721 - accuracy: 0.9860 - val_loss: 1.4035 - val_accuracy: 0.7963\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0561 - accuracy: 0.9860 - val_loss: 1.3479 - val_accuracy: 0.7778\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0491 - accuracy: 0.9813 - val_loss: 1.5696 - val_accuracy: 0.8148\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9813 - val_loss: 1.4589 - val_accuracy: 0.7963\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9860 - val_loss: 1.5053 - val_accuracy: 0.7963\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 1.5324 - val_accuracy: 0.7778\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9766 - val_loss: 1.9072 - val_accuracy: 0.7963\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9860 - val_loss: 2.5970 - val_accuracy: 0.7593\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0978 - accuracy: 0.9579 - val_loss: 1.8597 - val_accuracy: 0.6111\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1422 - accuracy: 0.9486 - val_loss: 2.0197 - val_accuracy: 0.7593\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1197 - accuracy: 0.9533 - val_loss: 1.9965 - val_accuracy: 0.7593\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9720 - val_loss: 1.9072 - val_accuracy: 0.7593\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9766 - val_loss: 1.5113 - val_accuracy: 0.7778\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0638 - accuracy: 0.9860 - val_loss: 1.5745 - val_accuracy: 0.7593\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 0.9860 - val_loss: 1.9367 - val_accuracy: 0.7407\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 1.7939 - val_accuracy: 0.7778\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9813 - val_loss: 2.0471 - val_accuracy: 0.7593\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9860 - val_loss: 1.8586 - val_accuracy: 0.7407\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 1.6368 - val_accuracy: 0.7778\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 1.6827 - val_accuracy: 0.7593\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0240 - accuracy: 0.9907 - val_loss: 1.8969 - val_accuracy: 0.7963\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0422 - accuracy: 0.9813 - val_loss: 1.8893 - val_accuracy: 0.7963\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.9907 - val_loss: 1.9012 - val_accuracy: 0.7593\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9907 - val_loss: 2.1422 - val_accuracy: 0.7593\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9907 - val_loss: 2.1223 - val_accuracy: 0.7963\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 2.1437 - val_accuracy: 0.7963\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 2.4303 - val_accuracy: 0.7222\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 2.2212 - val_accuracy: 0.7963\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 2.1507 - val_accuracy: 0.7963\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 2.1473 - val_accuracy: 0.7963\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 0.9907 - val_loss: 2.2166 - val_accuracy: 0.7778\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.2908 - val_accuracy: 0.7963\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 0.9907 - val_loss: 2.2690 - val_accuracy: 0.7778\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9953 - val_loss: 2.3579 - val_accuracy: 0.8148\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9907 - val_loss: 2.3575 - val_accuracy: 0.8148\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.4442 - val_accuracy: 0.7778\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 0.9907 - val_loss: 2.2898 - val_accuracy: 0.8148\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9907 - val_loss: 1.9171 - val_accuracy: 0.7407\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 2.4572 - val_accuracy: 0.7593\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 2.2275 - val_accuracy: 0.7778\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.98 - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9860 - val_loss: 2.2184 - val_accuracy: 0.7778\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9953 - val_loss: 2.4068 - val_accuracy: 0.7593\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 2.3678 - val_accuracy: 0.7593\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 2.1652 - val_accuracy: 0.7593\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 2.1533 - val_accuracy: 0.7593\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9953 - val_loss: 2.2925 - val_accuracy: 0.7593\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 2.6144 - val_accuracy: 0.7407\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.5740 - val_accuracy: 0.7407\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 2.4397 - val_accuracy: 0.7963\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 2.3712 - val_accuracy: 0.8148\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 2.3122 - val_accuracy: 0.8148\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9953 - val_loss: 2.3108 - val_accuracy: 0.7778\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9907 - val_loss: 2.3386 - val_accuracy: 0.7963\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 2.3618 - val_accuracy: 0.7963\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 2.3952 - val_accuracy: 0.7963\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 2.4388 - val_accuracy: 0.7963\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 0.9953 - val_loss: 2.4686 - val_accuracy: 0.8148\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 0.9953 - val_loss: 2.5068 - val_accuracy: 0.8148\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 0.9953 - val_loss: 2.5515 - val_accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 0.9907 - val_loss: 2.6031 - val_accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9907 - val_loss: 2.6507 - val_accuracy: 0.7778\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 2.6163 - val_accuracy: 0.7963\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 2.5364 - val_accuracy: 0.8148\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 0.9953 - val_loss: 2.4839 - val_accuracy: 0.8148\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.9953 - val_loss: 2.4576 - val_accuracy: 0.8148\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 0.9953 - val_loss: 2.4713 - val_accuracy: 0.7963\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9953 - val_loss: 2.5193 - val_accuracy: 0.7963\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 0.9907 - val_loss: 2.5703 - val_accuracy: 0.7963\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9907 - val_loss: 2.5754 - val_accuracy: 0.7963\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9953 - val_loss: 2.5827 - val_accuracy: 0.7963\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9907 - val_loss: 2.5634 - val_accuracy: 0.7963\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.9953 - val_loss: 2.5310 - val_accuracy: 0.8148\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5229 - val_accuracy: 0.8148\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9953 - val_loss: 2.5720 - val_accuracy: 0.7963\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 0.9953 - val_loss: 2.6442 - val_accuracy: 0.7778\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9953 - val_loss: 2.7637 - val_accuracy: 0.7593\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 2.7511 - val_accuracy: 0.7778\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.9953 - val_loss: 2.6354 - val_accuracy: 0.8148\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.9953 - val_loss: 2.5726 - val_accuracy: 0.8148\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 0.9953 - val_loss: 2.5503 - val_accuracy: 0.8148\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0093 - accuracy: 0.9953 - val_loss: 2.5597 - val_accuracy: 0.8148\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9907 - val_loss: 2.5768 - val_accuracy: 0.8148\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5924 - val_accuracy: 0.7963\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9907 - val_loss: 2.5881 - val_accuracy: 0.7963\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0098 - accuracy: 0.9907 - val_loss: 2.6217 - val_accuracy: 0.7963\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BD788E550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.6260 - accuracy: 0.7488 - val_loss: 0.5860 - val_accuracy: 0.7358\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4400 - accuracy: 0.8140 - val_loss: 0.9528 - val_accuracy: 0.7547\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4822 - accuracy: 0.8186 - val_loss: 0.6880 - val_accuracy: 0.7547\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4382 - accuracy: 0.8047 - val_loss: 0.6171 - val_accuracy: 0.7547\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8000 - val_loss: 0.6321 - val_accuracy: 0.7547\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.8186 - val_loss: 0.7271 - val_accuracy: 0.7358\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.8140 - val_loss: 0.7405 - val_accuracy: 0.7547\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8140 - val_loss: 0.7002 - val_accuracy: 0.7358\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.8093 - val_loss: 0.6399 - val_accuracy: 0.7358\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.8093 - val_loss: 0.6470 - val_accuracy: 0.7547\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.8093 - val_loss: 0.6514 - val_accuracy: 0.7358\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4213 - accuracy: 0.8186 - val_loss: 0.6644 - val_accuracy: 0.7358\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.8047 - val_loss: 0.6718 - val_accuracy: 0.7547\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4325 - accuracy: 0.8233 - val_loss: 0.7291 - val_accuracy: 0.7547\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8279 - val_loss: 0.6844 - val_accuracy: 0.7547\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8326 - val_loss: 0.6918 - val_accuracy: 0.7547\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4312 - accuracy: 0.8279 - val_loss: 0.6899 - val_accuracy: 0.7358\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4282 - accuracy: 0.8279 - val_loss: 0.7244 - val_accuracy: 0.7547\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3970 - accuracy: 0.8372 - val_loss: 0.7492 - val_accuracy: 0.7547\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4119 - accuracy: 0.8372 - val_loss: 0.7469 - val_accuracy: 0.7547\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3935 - accuracy: 0.8372 - val_loss: 0.6996 - val_accuracy: 0.7358\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4079 - accuracy: 0.8279 - val_loss: 0.6813 - val_accuracy: 0.7547\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3979 - accuracy: 0.8326 - val_loss: 0.7802 - val_accuracy: 0.7358\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8419 - val_loss: 0.8571 - val_accuracy: 0.7547\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4084 - accuracy: 0.8372 - val_loss: 0.6565 - val_accuracy: 0.7547\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4001 - accuracy: 0.8512 - val_loss: 0.6039 - val_accuracy: 0.7736\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3863 - accuracy: 0.8512 - val_loss: 0.7496 - val_accuracy: 0.7547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3810 - accuracy: 0.8465 - val_loss: 0.8209 - val_accuracy: 0.7547\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.8558 - val_loss: 0.6564 - val_accuracy: 0.7925\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3591 - accuracy: 0.8791 - val_loss: 0.6932 - val_accuracy: 0.7547\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3731 - accuracy: 0.8605 - val_loss: 0.7400 - val_accuracy: 0.7547\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3636 - accuracy: 0.8651 - val_loss: 0.6095 - val_accuracy: 0.7547\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.8837 - val_loss: 0.7546 - val_accuracy: 0.7358\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3658 - accuracy: 0.8558 - val_loss: 0.7327 - val_accuracy: 0.7547\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3323 - accuracy: 0.8744 - val_loss: 0.6838 - val_accuracy: 0.7736\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3235 - accuracy: 0.8930 - val_loss: 0.6308 - val_accuracy: 0.7736\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3177 - accuracy: 0.8837 - val_loss: 0.7525 - val_accuracy: 0.7736\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3278 - accuracy: 0.8884 - val_loss: 0.7332 - val_accuracy: 0.7736\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2885 - accuracy: 0.8930 - val_loss: 0.7022 - val_accuracy: 0.7547\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2901 - accuracy: 0.8977 - val_loss: 0.6219 - val_accuracy: 0.7925\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2718 - accuracy: 0.9070 - val_loss: 0.7635 - val_accuracy: 0.7547\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.8884 - val_loss: 0.6658 - val_accuracy: 0.7736\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2530 - accuracy: 0.9116 - val_loss: 0.6958 - val_accuracy: 0.7736\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2333 - accuracy: 0.9116 - val_loss: 0.8700 - val_accuracy: 0.7736\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2604 - accuracy: 0.8977 - val_loss: 0.7491 - val_accuracy: 0.7736\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2244 - accuracy: 0.9256 - val_loss: 0.7116 - val_accuracy: 0.7170\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2222 - accuracy: 0.9256 - val_loss: 1.0781 - val_accuracy: 0.6604\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2437 - accuracy: 0.9163 - val_loss: 1.0647 - val_accuracy: 0.7170\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2543 - accuracy: 0.8977 - val_loss: 0.9737 - val_accuracy: 0.7358\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2466 - accuracy: 0.9070 - val_loss: 0.8093 - val_accuracy: 0.7547\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2314 - accuracy: 0.9116 - val_loss: 0.7338 - val_accuracy: 0.6981\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2116 - accuracy: 0.9256 - val_loss: 0.8741 - val_accuracy: 0.7736\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2168 - accuracy: 0.9163 - val_loss: 0.9420 - val_accuracy: 0.7736\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2042 - accuracy: 0.9349 - val_loss: 0.8301 - val_accuracy: 0.7170\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9349 - val_loss: 0.8945 - val_accuracy: 0.6981\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1823 - accuracy: 0.9395 - val_loss: 0.9272 - val_accuracy: 0.7547\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1779 - accuracy: 0.9349 - val_loss: 0.9017 - val_accuracy: 0.7547\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1740 - accuracy: 0.9442 - val_loss: 1.1392 - val_accuracy: 0.7547\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1981 - accuracy: 0.9302 - val_loss: 1.1732 - val_accuracy: 0.6981\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2264 - accuracy: 0.9163 - val_loss: 0.8532 - val_accuracy: 0.7547\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2197 - accuracy: 0.9302 - val_loss: 1.0462 - val_accuracy: 0.7170\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2333 - accuracy: 0.9256 - val_loss: 1.1027 - val_accuracy: 0.7170\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2179 - accuracy: 0.9163 - val_loss: 1.0180 - val_accuracy: 0.7925\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.9256 - val_loss: 0.9951 - val_accuracy: 0.6981\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1782 - accuracy: 0.9302 - val_loss: 0.8575 - val_accuracy: 0.7547\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1982 - accuracy: 0.9349 - val_loss: 0.9694 - val_accuracy: 0.6981\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1675 - accuracy: 0.9442 - val_loss: 1.0748 - val_accuracy: 0.7170\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1652 - accuracy: 0.9349 - val_loss: 1.0424 - val_accuracy: 0.7925\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1598 - accuracy: 0.9349 - val_loss: 1.0603 - val_accuracy: 0.6981\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1538 - accuracy: 0.9442 - val_loss: 1.0159 - val_accuracy: 0.7170\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1473 - accuracy: 0.9535 - val_loss: 0.9861 - val_accuracy: 0.7736\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.9535 - val_loss: 1.0683 - val_accuracy: 0.7736\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1322 - accuracy: 0.9442 - val_loss: 1.4884 - val_accuracy: 0.6981\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1549 - accuracy: 0.9535 - val_loss: 1.3228 - val_accuracy: 0.7925\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1695 - accuracy: 0.9256 - val_loss: 1.1239 - val_accuracy: 0.7170\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1350 - accuracy: 0.9535 - val_loss: 1.3237 - val_accuracy: 0.7170\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1411 - accuracy: 0.9535 - val_loss: 1.2186 - val_accuracy: 0.7358\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1293 - accuracy: 0.9581 - val_loss: 1.3358 - val_accuracy: 0.7547\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1099 - accuracy: 0.9628 - val_loss: 1.3483 - val_accuracy: 0.7736\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9535 - val_loss: 1.3980 - val_accuracy: 0.7925\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1070 - accuracy: 0.9535 - val_loss: 1.5904 - val_accuracy: 0.7925\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9721 - val_loss: 1.5776 - val_accuracy: 0.7547\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1077 - accuracy: 0.9535 - val_loss: 1.6471 - val_accuracy: 0.7736\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1044 - accuracy: 0.9535 - val_loss: 1.5017 - val_accuracy: 0.7736\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1068 - accuracy: 0.9628 - val_loss: 1.7605 - val_accuracy: 0.7170\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0862 - accuracy: 0.9628 - val_loss: 1.8103 - val_accuracy: 0.7358\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0902 - accuracy: 0.9721 - val_loss: 1.9233 - val_accuracy: 0.7547\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0971 - accuracy: 0.9535 - val_loss: 1.5577 - val_accuracy: 0.8113\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0944 - accuracy: 0.9628 - val_loss: 1.6766 - val_accuracy: 0.7736\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9814 - val_loss: 1.8585 - val_accuracy: 0.6981\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9674 - val_loss: 2.0443 - val_accuracy: 0.7547\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0961 - accuracy: 0.9721 - val_loss: 1.8204 - val_accuracy: 0.7358\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0564 - accuracy: 0.9721 - val_loss: 2.0259 - val_accuracy: 0.7358\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9721 - val_loss: 2.0574 - val_accuracy: 0.7925\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0748 - accuracy: 0.9767 - val_loss: 1.8442 - val_accuracy: 0.7170\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.9674 - val_loss: 1.8081 - val_accuracy: 0.7547\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 1.8645 - val_accuracy: 0.7736\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.9721 - val_loss: 1.9527 - val_accuracy: 0.7170\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9814 - val_loss: 1.6827 - val_accuracy: 0.7925\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9721 - val_loss: 1.6791 - val_accuracy: 0.7736\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9814 - val_loss: 2.1885 - val_accuracy: 0.6981\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.9628 - val_loss: 1.9744 - val_accuracy: 0.7358\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1533 - accuracy: 0.9349 - val_loss: 1.6778 - val_accuracy: 0.7736\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0953 - accuracy: 0.9628 - val_loss: 1.5958 - val_accuracy: 0.7736\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0925 - accuracy: 0.9674 - val_loss: 2.3415 - val_accuracy: 0.6981\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9674 - val_loss: 1.5383 - val_accuracy: 0.7170\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1360 - accuracy: 0.9581 - val_loss: 2.1064 - val_accuracy: 0.6981\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9674 - val_loss: 1.5543 - val_accuracy: 0.7170\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0763 - accuracy: 0.9721 - val_loss: 2.0290 - val_accuracy: 0.6792\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1748 - accuracy: 0.9721 - val_loss: 2.2718 - val_accuracy: 0.6415\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1395 - accuracy: 0.9581 - val_loss: 1.5737 - val_accuracy: 0.7547\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1049 - accuracy: 0.9535 - val_loss: 1.4505 - val_accuracy: 0.7736\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9674 - val_loss: 1.5019 - val_accuracy: 0.7358\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1074 - accuracy: 0.9488 - val_loss: 1.6801 - val_accuracy: 0.7170\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0648 - accuracy: 0.9860 - val_loss: 1.2472 - val_accuracy: 0.7358\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0593 - accuracy: 0.9814 - val_loss: 1.5026 - val_accuracy: 0.7736\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.9814 - val_loss: 1.6942 - val_accuracy: 0.6981\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9767 - val_loss: 1.6177 - val_accuracy: 0.7170\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 1.6673 - val_accuracy: 0.7547\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 2.0541 - val_accuracy: 0.6792\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0439 - accuracy: 0.9814 - val_loss: 1.8980 - val_accuracy: 0.7547\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 1.8972 - val_accuracy: 0.7547\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.9716 - val_accuracy: 0.6981\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0323 - accuracy: 0.9860 - val_loss: 1.7588 - val_accuracy: 0.7736\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0375 - accuracy: 0.9767 - val_loss: 1.8396 - val_accuracy: 0.7736\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.1243 - val_accuracy: 0.6792\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9860 - val_loss: 2.0412 - val_accuracy: 0.7170\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.9773 - val_accuracy: 0.7736\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.0212 - val_accuracy: 0.7925\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.1307 - val_accuracy: 0.7170\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9860 - val_loss: 2.1178 - val_accuracy: 0.7358\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.1113 - val_accuracy: 0.7925\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 0.9907 - val_loss: 2.1853 - val_accuracy: 0.7736\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.3680 - val_accuracy: 0.7170\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.4805 - val_accuracy: 0.6981\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.4966 - val_accuracy: 0.7358\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5018 - val_accuracy: 0.7547\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.5234 - val_accuracy: 0.7547\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.5714 - val_accuracy: 0.6981\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5563 - val_accuracy: 0.7358\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.5537 - val_accuracy: 0.7547\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5611 - val_accuracy: 0.7547\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5837 - val_accuracy: 0.6981\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5898 - val_accuracy: 0.6981\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5484 - val_accuracy: 0.7736\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5447 - val_accuracy: 0.7736\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5697 - val_accuracy: 0.7736\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5916 - val_accuracy: 0.7736\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6272 - val_accuracy: 0.7736\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6851 - val_accuracy: 0.7547\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7254 - val_accuracy: 0.7547\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.5865e-04 - accuracy: 1.0000 - val_loss: 2.7604 - val_accuracy: 0.7547\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.7694 - val_accuracy: 0.7736\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7276 - val_accuracy: 0.7547\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7035 - val_accuracy: 0.7736\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7290 - val_accuracy: 0.7736\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8187 - val_accuracy: 0.7547\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8811 - val_accuracy: 0.7358\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8910 - val_accuracy: 0.7736\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9005 - val_accuracy: 0.7547\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.6981\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8617 - val_accuracy: 0.7547\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.4204e-04 - accuracy: 1.0000 - val_loss: 2.8729 - val_accuracy: 0.7925\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9171 - val_accuracy: 0.8113\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.9472 - val_accuracy: 0.8113\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.8585e-04 - accuracy: 1.0000 - val_loss: 2.9707 - val_accuracy: 0.7925\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0009 - val_accuracy: 0.7547\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.5378e-04 - accuracy: 1.0000 - val_loss: 3.0209 - val_accuracy: 0.7358\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.1360e-04 - accuracy: 1.0000 - val_loss: 3.0229 - val_accuracy: 0.7547\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0531 - val_accuracy: 0.7358\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.0082 - val_accuracy: 0.7736\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0017 - val_accuracy: 0.7736\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0362 - val_accuracy: 0.7736\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.1279 - val_accuracy: 0.7170\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2130 - val_accuracy: 0.6981\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5732e-04 - accuracy: 1.0000 - val_loss: 3.2616 - val_accuracy: 0.6981\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.2307 - val_accuracy: 0.7547\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 0.9953 - val_loss: 3.2245 - val_accuracy: 0.7736\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1714 - val_accuracy: 0.7736\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.5899e-04 - accuracy: 1.0000 - val_loss: 3.1451 - val_accuracy: 0.7547\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1323 - val_accuracy: 0.7547\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1250 - val_accuracy: 0.7547\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.2196e-04 - accuracy: 1.0000 - val_loss: 3.1263 - val_accuracy: 0.7736\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2478e-04 - accuracy: 1.0000 - val_loss: 3.1383 - val_accuracy: 0.7736\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.0648e-04 - accuracy: 1.0000 - val_loss: 3.1604 - val_accuracy: 0.7736\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1776 - val_accuracy: 0.7547\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2278 - val_accuracy: 0.7170\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1726 - val_accuracy: 0.7170\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0921 - val_accuracy: 0.7736\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.6696e-04 - accuracy: 1.0000 - val_loss: 3.1023 - val_accuracy: 0.7925\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1684 - val_accuracy: 0.7925\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.4238 - val_accuracy: 0.7170\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.6819 - val_accuracy: 0.6792\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.8182e-04 - accuracy: 1.0000 - val_loss: 3.5518 - val_accuracy: 0.7736\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 3.5186 - val_accuracy: 0.6792\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.2252 - val_accuracy: 0.7170\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.0375 - val_accuracy: 0.7925\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0447 - val_accuracy: 0.7925\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0990 - val_accuracy: 0.7925\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1653 - val_accuracy: 0.7547\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BE221D4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.6539 - accuracy: 0.6930 - val_loss: 0.4883 - val_accuracy: 0.8302\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5070 - accuracy: 0.7814 - val_loss: 0.4020 - val_accuracy: 0.8491\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5514 - accuracy: 0.7814 - val_loss: 0.4042 - val_accuracy: 0.8491\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5042 - accuracy: 0.7814 - val_loss: 0.4364 - val_accuracy: 0.8302\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4997 - accuracy: 0.7907 - val_loss: 0.4514 - val_accuracy: 0.8302\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4950 - accuracy: 0.7907 - val_loss: 0.4283 - val_accuracy: 0.8302\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.7814 - val_loss: 0.4098 - val_accuracy: 0.8302\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4903 - accuracy: 0.7860 - val_loss: 0.4180 - val_accuracy: 0.8302\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4905 - accuracy: 0.7860 - val_loss: 0.4337 - val_accuracy: 0.8302\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4995 - accuracy: 0.7907 - val_loss: 0.4483 - val_accuracy: 0.7547\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4841 - accuracy: 0.8140 - val_loss: 0.4238 - val_accuracy: 0.8113\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4810 - accuracy: 0.8000 - val_loss: 0.4121 - val_accuracy: 0.8113\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4857 - accuracy: 0.7907 - val_loss: 0.4208 - val_accuracy: 0.8113\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4742 - accuracy: 0.7907 - val_loss: 0.4482 - val_accuracy: 0.8113\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8140 - val_loss: 0.4447 - val_accuracy: 0.8113\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4758 - accuracy: 0.8140 - val_loss: 0.4354 - val_accuracy: 0.8113\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4621 - accuracy: 0.8000 - val_loss: 0.4521 - val_accuracy: 0.7358\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4705 - accuracy: 0.8047 - val_loss: 0.4384 - val_accuracy: 0.8113\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4563 - accuracy: 0.8186 - val_loss: 0.4272 - val_accuracy: 0.8302\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4515 - accuracy: 0.8000 - val_loss: 0.4412 - val_accuracy: 0.8113\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4630 - accuracy: 0.8186 - val_loss: 0.4582 - val_accuracy: 0.7925\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4546 - accuracy: 0.8186 - val_loss: 0.4414 - val_accuracy: 0.8302\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4443 - accuracy: 0.8233 - val_loss: 0.4528 - val_accuracy: 0.8302\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4512 - accuracy: 0.8186 - val_loss: 0.4563 - val_accuracy: 0.8113\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4484 - accuracy: 0.8233 - val_loss: 0.4537 - val_accuracy: 0.8113\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4419 - accuracy: 0.8233 - val_loss: 0.4551 - val_accuracy: 0.8302\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4551 - accuracy: 0.8233 - val_loss: 0.5043 - val_accuracy: 0.7547\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4382 - accuracy: 0.8233 - val_loss: 0.4569 - val_accuracy: 0.8302\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4107 - accuracy: 0.8372 - val_loss: 0.4446 - val_accuracy: 0.8302\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4284 - accuracy: 0.8279 - val_loss: 0.4616 - val_accuracy: 0.8302\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4036 - accuracy: 0.8372 - val_loss: 0.4945 - val_accuracy: 0.8113\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4121 - accuracy: 0.8233 - val_loss: 0.4540 - val_accuracy: 0.8491\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8465 - val_loss: 0.4890 - val_accuracy: 0.8302\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3991 - accuracy: 0.8372 - val_loss: 0.5004 - val_accuracy: 0.8302\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3877 - accuracy: 0.8651 - val_loss: 0.4983 - val_accuracy: 0.8302\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3797 - accuracy: 0.8465 - val_loss: 0.4953 - val_accuracy: 0.8302\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3533 - accuracy: 0.8512 - val_loss: 0.5342 - val_accuracy: 0.8302\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3495 - accuracy: 0.8744 - val_loss: 0.6056 - val_accuracy: 0.8113\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3430 - accuracy: 0.8651 - val_loss: 0.5618 - val_accuracy: 0.7358\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4576 - accuracy: 0.8140 - val_loss: 0.6103 - val_accuracy: 0.8113\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3868 - accuracy: 0.8140 - val_loss: 0.6086 - val_accuracy: 0.8113\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3544 - accuracy: 0.8791 - val_loss: 0.5001 - val_accuracy: 0.8491\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8372 - val_loss: 0.4992 - val_accuracy: 0.8302\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3592 - accuracy: 0.8605 - val_loss: 0.5672 - val_accuracy: 0.8113\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3314 - accuracy: 0.8744 - val_loss: 0.5918 - val_accuracy: 0.7925\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3406 - accuracy: 0.8884 - val_loss: 0.6540 - val_accuracy: 0.7736\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8698 - val_loss: 0.6930 - val_accuracy: 0.7736\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3142 - accuracy: 0.8791 - val_loss: 0.5758 - val_accuracy: 0.8113\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3048 - accuracy: 0.8837 - val_loss: 0.6273 - val_accuracy: 0.7925\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3114 - accuracy: 0.8884 - val_loss: 0.7622 - val_accuracy: 0.7358\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3022 - accuracy: 0.8884 - val_loss: 0.6271 - val_accuracy: 0.8113\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2821 - accuracy: 0.8884 - val_loss: 0.6592 - val_accuracy: 0.8113\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2791 - accuracy: 0.8837 - val_loss: 0.8117 - val_accuracy: 0.7925\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2563 - accuracy: 0.9023 - val_loss: 0.7925 - val_accuracy: 0.7736\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2405 - accuracy: 0.9163 - val_loss: 0.8470 - val_accuracy: 0.7925\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2567 - accuracy: 0.9070 - val_loss: 0.8080 - val_accuracy: 0.7925\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2330 - accuracy: 0.9209 - val_loss: 0.8796 - val_accuracy: 0.7736\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2306 - accuracy: 0.9302 - val_loss: 0.8724 - val_accuracy: 0.7736\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.9116 - val_loss: 0.8434 - val_accuracy: 0.7736\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2276 - accuracy: 0.9070 - val_loss: 1.1402 - val_accuracy: 0.7358\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2744 - accuracy: 0.8977 - val_loss: 1.2233 - val_accuracy: 0.7358\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2774 - accuracy: 0.8837 - val_loss: 0.7140 - val_accuracy: 0.8113\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3388 - accuracy: 0.8791 - val_loss: 1.0970 - val_accuracy: 0.6981\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2847 - accuracy: 0.8837 - val_loss: 0.9391 - val_accuracy: 0.7736\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2609 - accuracy: 0.9070 - val_loss: 0.7843 - val_accuracy: 0.7925\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2824 - accuracy: 0.8884 - val_loss: 0.8297 - val_accuracy: 0.8113\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2523 - accuracy: 0.9070 - val_loss: 1.0661 - val_accuracy: 0.7736\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2375 - accuracy: 0.9070 - val_loss: 1.1760 - val_accuracy: 0.7170\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2252 - accuracy: 0.9256 - val_loss: 1.1200 - val_accuracy: 0.7547\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2241 - accuracy: 0.9209 - val_loss: 1.2970 - val_accuracy: 0.7358\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2175 - accuracy: 0.9209 - val_loss: 1.1140 - val_accuracy: 0.7736\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2010 - accuracy: 0.9349 - val_loss: 1.0451 - val_accuracy: 0.7736\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2062 - accuracy: 0.9302 - val_loss: 1.1429 - val_accuracy: 0.7736\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1909 - accuracy: 0.9256 - val_loss: 1.1602 - val_accuracy: 0.7925\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1822 - accuracy: 0.9395 - val_loss: 1.2881 - val_accuracy: 0.7736\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1804 - accuracy: 0.9349 - val_loss: 1.3356 - val_accuracy: 0.7736\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1779 - accuracy: 0.9302 - val_loss: 1.2422 - val_accuracy: 0.8113\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1849 - accuracy: 0.9302 - val_loss: 1.3080 - val_accuracy: 0.7925\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 0.9442 - val_loss: 1.6247 - val_accuracy: 0.7170\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.9395 - val_loss: 1.4253 - val_accuracy: 0.7925\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1625 - accuracy: 0.9442 - val_loss: 1.3677 - val_accuracy: 0.8113\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1554 - accuracy: 0.9395 - val_loss: 1.4003 - val_accuracy: 0.8113\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1486 - accuracy: 0.9488 - val_loss: 1.4868 - val_accuracy: 0.8113\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1560 - accuracy: 0.9488 - val_loss: 1.4009 - val_accuracy: 0.8113\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1577 - accuracy: 0.9442 - val_loss: 1.6292 - val_accuracy: 0.7925\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1678 - accuracy: 0.9349 - val_loss: 1.5662 - val_accuracy: 0.7925\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1683 - accuracy: 0.9349 - val_loss: 1.9447 - val_accuracy: 0.7170\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1855 - accuracy: 0.9349 - val_loss: 1.3865 - val_accuracy: 0.8113\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2330 - accuracy: 0.8837 - val_loss: 1.5545 - val_accuracy: 0.7736\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2191 - accuracy: 0.9256 - val_loss: 1.4926 - val_accuracy: 0.7736\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1622 - accuracy: 0.9395 - val_loss: 1.0895 - val_accuracy: 0.7736\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1860 - accuracy: 0.9256 - val_loss: 1.2778 - val_accuracy: 0.7925\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1926 - accuracy: 0.9395 - val_loss: 1.5902 - val_accuracy: 0.7358\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.9488 - val_loss: 1.7214 - val_accuracy: 0.7358\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.9442 - val_loss: 1.9187 - val_accuracy: 0.6792\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1467 - accuracy: 0.9488 - val_loss: 1.8261 - val_accuracy: 0.7170\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.9488 - val_loss: 1.5224 - val_accuracy: 0.7547\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1308 - accuracy: 0.9581 - val_loss: 1.4837 - val_accuracy: 0.7736\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9581 - val_loss: 1.4954 - val_accuracy: 0.7925\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1266 - accuracy: 0.9535 - val_loss: 1.5694 - val_accuracy: 0.8113\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1196 - accuracy: 0.9581 - val_loss: 1.6243 - val_accuracy: 0.7925\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1259 - accuracy: 0.9535 - val_loss: 1.6531 - val_accuracy: 0.7736\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9581 - val_loss: 1.6661 - val_accuracy: 0.7925\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1090 - accuracy: 0.9581 - val_loss: 1.7125 - val_accuracy: 0.7925\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1213 - accuracy: 0.9581 - val_loss: 1.7569 - val_accuracy: 0.7925\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1056 - accuracy: 0.9581 - val_loss: 1.8279 - val_accuracy: 0.7736\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1101 - accuracy: 0.9535 - val_loss: 1.8304 - val_accuracy: 0.7925\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1164 - accuracy: 0.9488 - val_loss: 1.7722 - val_accuracy: 0.8113\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1102 - accuracy: 0.9581 - val_loss: 1.8641 - val_accuracy: 0.7925\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1168 - accuracy: 0.9535 - val_loss: 1.7824 - val_accuracy: 0.7736\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1034 - accuracy: 0.9628 - val_loss: 1.7466 - val_accuracy: 0.7925\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0979 - accuracy: 0.9535 - val_loss: 1.7571 - val_accuracy: 0.7736\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1111 - accuracy: 0.9628 - val_loss: 1.7946 - val_accuracy: 0.7736\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0928 - accuracy: 0.9721 - val_loss: 1.9125 - val_accuracy: 0.7925\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0843 - accuracy: 0.9674 - val_loss: 1.9673 - val_accuracy: 0.7925\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9767 - val_loss: 2.3844 - val_accuracy: 0.7358\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2051 - accuracy: 0.9256 - val_loss: 1.4761 - val_accuracy: 0.7925\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2157 - accuracy: 0.9302 - val_loss: 1.4058 - val_accuracy: 0.7736\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1694 - accuracy: 0.9349 - val_loss: 1.5436 - val_accuracy: 0.7925\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1460 - accuracy: 0.9395 - val_loss: 1.2506 - val_accuracy: 0.8113\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1521 - accuracy: 0.9442 - val_loss: 1.7441 - val_accuracy: 0.7170\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1649 - accuracy: 0.9349 - val_loss: 1.4204 - val_accuracy: 0.7925\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1341 - accuracy: 0.9488 - val_loss: 1.1785 - val_accuracy: 0.8302\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1298 - accuracy: 0.9488 - val_loss: 1.3201 - val_accuracy: 0.7736\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1269 - accuracy: 0.9628 - val_loss: 1.5593 - val_accuracy: 0.7547\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 0.9488 - val_loss: 1.5191 - val_accuracy: 0.7358\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1059 - accuracy: 0.9628 - val_loss: 1.3300 - val_accuracy: 0.7925\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1159 - accuracy: 0.9488 - val_loss: 1.5083 - val_accuracy: 0.7925\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1077 - accuracy: 0.9674 - val_loss: 2.1299 - val_accuracy: 0.6981\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0843 - accuracy: 0.9721 - val_loss: 2.2994 - val_accuracy: 0.6981\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9674 - val_loss: 2.3044 - val_accuracy: 0.6981\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9767 - val_loss: 2.3629 - val_accuracy: 0.7170\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 1.00 - 0s 9ms/step - loss: 0.0937 - accuracy: 0.9674 - val_loss: 2.1406 - val_accuracy: 0.7547\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 2.1068 - val_accuracy: 0.7736\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0819 - accuracy: 0.9674 - val_loss: 2.0824 - val_accuracy: 0.7358\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9860 - val_loss: 2.0917 - val_accuracy: 0.7358\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0587 - accuracy: 0.9860 - val_loss: 2.0795 - val_accuracy: 0.7736\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9721 - val_loss: 2.0833 - val_accuracy: 0.7736\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 2.1337 - val_accuracy: 0.7547\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9907 - val_loss: 2.2490 - val_accuracy: 0.7736\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0666 - accuracy: 0.9767 - val_loss: 2.3396 - val_accuracy: 0.7547\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 2.4243 - val_accuracy: 0.7547\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0514 - accuracy: 0.9767 - val_loss: 2.4247 - val_accuracy: 0.7547\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9767 - val_loss: 2.4090 - val_accuracy: 0.7358\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9907 - val_loss: 2.4117 - val_accuracy: 0.7358\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9860 - val_loss: 2.4771 - val_accuracy: 0.7736\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0352 - accuracy: 0.9767 - val_loss: 2.4946 - val_accuracy: 0.7736\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 2.2712 - val_accuracy: 0.7736\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0760 - accuracy: 0.9860 - val_loss: 2.2451 - val_accuracy: 0.7547\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 2.5715 - val_accuracy: 0.6604\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0356 - accuracy: 0.9907 - val_loss: 2.6712 - val_accuracy: 0.6604\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9767 - val_loss: 2.7112 - val_accuracy: 0.7358\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9907 - val_loss: 2.7544 - val_accuracy: 0.6792\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9953 - val_loss: 2.8388 - val_accuracy: 0.7358\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0308 - accuracy: 0.9814 - val_loss: 2.8893 - val_accuracy: 0.6981\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0380 - accuracy: 0.9907 - val_loss: 2.9228 - val_accuracy: 0.6981\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9907 - val_loss: 2.9795 - val_accuracy: 0.7358\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9907 - val_loss: 2.9074 - val_accuracy: 0.6792\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 2.7528 - val_accuracy: 0.7736\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9721 - val_loss: 2.4984 - val_accuracy: 0.7547\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1197 - accuracy: 0.9721 - val_loss: 2.7046 - val_accuracy: 0.7170\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0752 - accuracy: 0.9628 - val_loss: 2.1129 - val_accuracy: 0.6981\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0848 - accuracy: 0.9581 - val_loss: 1.8889 - val_accuracy: 0.7736\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1251 - accuracy: 0.9767 - val_loss: 1.8530 - val_accuracy: 0.7925\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0647 - accuracy: 0.9721 - val_loss: 1.7888 - val_accuracy: 0.7547\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9953 - val_loss: 1.9114 - val_accuracy: 0.7736\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9907 - val_loss: 1.9967 - val_accuracy: 0.7547\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.0235 - val_accuracy: 0.7736\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9953 - val_loss: 1.9780 - val_accuracy: 0.7736\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 1.9088 - val_accuracy: 0.7736\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 1.9314 - val_accuracy: 0.7736\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.0495 - val_accuracy: 0.7736\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 2.0555 - val_accuracy: 0.7925\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.1052 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 2.1900 - val_accuracy: 0.7736\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.2707 - val_accuracy: 0.7736\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.3123 - val_accuracy: 0.7736\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.3494 - val_accuracy: 0.7736\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.4226 - val_accuracy: 0.7736\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5513 - val_accuracy: 0.7736\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5328 - val_accuracy: 0.7736\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.4658 - val_accuracy: 0.7736\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 2.2144 - val_accuracy: 0.7547\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1721 - val_accuracy: 0.7736\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2796 - val_accuracy: 0.7736\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.3686 - val_accuracy: 0.7736\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 2.4314 - val_accuracy: 0.7736\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4827 - val_accuracy: 0.7736\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 2.3844 - val_accuracy: 0.7547\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 2.2419 - val_accuracy: 0.7547\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 2.1599 - val_accuracy: 0.7736\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 2.3174 - val_accuracy: 0.7925\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9907 - val_loss: 2.3014 - val_accuracy: 0.7547\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9907 - val_loss: 2.4125 - val_accuracy: 0.7547\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9860 - val_loss: 2.6449 - val_accuracy: 0.7736\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 0.9860 - val_loss: 2.5090 - val_accuracy: 0.7547\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.3630 - val_accuracy: 0.7925\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.3213 - val_accuracy: 0.8113\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 2.2374 - val_accuracy: 0.7736\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.1758 - val_accuracy: 0.7736\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000179FC46B280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/'+'Fire/'+'/CDI_Based/Intensity/CSV/'+'Gray'+'.csv',index_col=0)\n",
    "\n",
    "y=data['Class'].values\n",
    "X=data.drop(['Class'], axis=1).values\n",
    "#X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    std =StandardScaler()\n",
    "    X_train=std.fit_transform(X[train])\n",
    "    X_test=std.transform(X[test])\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    input_tensor = Input(shape=(input_shape))\n",
    "\n",
    "    x = layers.Conv1D(128, 5, padding='valid', activation='relu', strides=1)(input_tensor)\n",
    "    x = layers.Conv1D(128, 5, padding='valid', activation='relu', strides=1)(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(256, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "    x = layers.Conv1D(256, 3, padding='valid', activation='relu', strides=1)(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(drop_out_rate)(x)\n",
    "    #x = layers.Flatten()(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                         optimizer=Adam(lr = lr),\n",
    "                         metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=\"1d+cnn.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "    history=model.fit(X_train, y[train],\n",
    "                epochs=200,\n",
    "                batch_size=64,\n",
    "                validation_data=(X_test, y[test]),\n",
    "                verbose=1,\n",
    "                callbacks=[checkpointer]).history\n",
    "    model=load_model('1d+cnn.h5')\n",
    "    y_prob = model.predict(X_test, verbose=0)\n",
    "    fpr_test,tpr_test,_ = roc_curve(y[test],y_prob)     \n",
    "    auc_test = auc(fpr_test,tpr_test)  \n",
    "    interp_tpr = np.interp(mean_fpr,fpr_test, tpr_test)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(auc_test)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='dodgerblue',label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title='ROC of gray'+ ' on Dataset ')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T15:41:08.570398Z",
     "start_time": "2020-09-26T15:40:09.210712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.6517 - accuracy: 0.6355 - val_loss: 0.5747 - val_accuracy: 0.8148\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5015 - accuracy: 0.7804 - val_loss: 0.5329 - val_accuracy: 0.8148\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4709 - accuracy: 0.8037 - val_loss: 0.5138 - val_accuracy: 0.8148\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4679 - accuracy: 0.7991 - val_loss: 0.5014 - val_accuracy: 0.8148\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4421 - accuracy: 0.8224 - val_loss: 0.4985 - val_accuracy: 0.7963\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4362 - accuracy: 0.8224 - val_loss: 0.4972 - val_accuracy: 0.7963\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4221 - accuracy: 0.8131 - val_loss: 0.4975 - val_accuracy: 0.7963\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4035 - accuracy: 0.8411 - val_loss: 0.4971 - val_accuracy: 0.7963\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3829 - accuracy: 0.8598 - val_loss: 0.4978 - val_accuracy: 0.7963\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3989 - accuracy: 0.8224 - val_loss: 0.5068 - val_accuracy: 0.7963\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3708 - accuracy: 0.8505 - val_loss: 0.5187 - val_accuracy: 0.7963\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3397 - accuracy: 0.8738 - val_loss: 0.5211 - val_accuracy: 0.7778\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3756 - accuracy: 0.8598 - val_loss: 0.5222 - val_accuracy: 0.7593\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3419 - accuracy: 0.8785 - val_loss: 0.5261 - val_accuracy: 0.7963\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3216 - accuracy: 0.8692 - val_loss: 0.5300 - val_accuracy: 0.7963\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3338 - accuracy: 0.8785 - val_loss: 0.5323 - val_accuracy: 0.8148\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.8925 - val_loss: 0.5452 - val_accuracy: 0.8148\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3375 - accuracy: 0.8645 - val_loss: 0.5463 - val_accuracy: 0.7593\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3060 - accuracy: 0.8832 - val_loss: 0.5482 - val_accuracy: 0.7407\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3135 - accuracy: 0.8925 - val_loss: 0.5539 - val_accuracy: 0.7593\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2860 - accuracy: 0.8832 - val_loss: 0.5656 - val_accuracy: 0.7593\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2767 - accuracy: 0.8925 - val_loss: 0.5800 - val_accuracy: 0.7222\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2644 - accuracy: 0.9159 - val_loss: 0.5689 - val_accuracy: 0.7222\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2699 - accuracy: 0.9065 - val_loss: 0.5585 - val_accuracy: 0.7407\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2613 - accuracy: 0.9112 - val_loss: 0.5548 - val_accuracy: 0.7222\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9019 - val_loss: 0.5653 - val_accuracy: 0.6852\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2374 - accuracy: 0.9065 - val_loss: 0.5751 - val_accuracy: 0.6852\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2407 - accuracy: 0.9112 - val_loss: 0.5860 - val_accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2044 - accuracy: 0.9299 - val_loss: 0.5995 - val_accuracy: 0.6296\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2228 - accuracy: 0.9299 - val_loss: 0.6021 - val_accuracy: 0.6481\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1855 - accuracy: 0.9439 - val_loss: 0.5993 - val_accuracy: 0.6481\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2322 - accuracy: 0.9159 - val_loss: 0.5859 - val_accuracy: 0.6481\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1960 - accuracy: 0.9065 - val_loss: 0.6004 - val_accuracy: 0.6296\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2210 - accuracy: 0.9206 - val_loss: 0.6076 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1789 - accuracy: 0.9439 - val_loss: 0.5968 - val_accuracy: 0.7407\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9252 - val_loss: 0.5696 - val_accuracy: 0.7037\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1937 - accuracy: 0.9346 - val_loss: 0.5870 - val_accuracy: 0.6481\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1794 - accuracy: 0.9393 - val_loss: 0.5856 - val_accuracy: 0.6852\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1904 - accuracy: 0.9299 - val_loss: 0.6191 - val_accuracy: 0.6296\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2178 - accuracy: 0.9065 - val_loss: 0.5962 - val_accuracy: 0.6481\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1690 - accuracy: 0.9533 - val_loss: 0.5626 - val_accuracy: 0.7407\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1934 - accuracy: 0.9206 - val_loss: 0.5332 - val_accuracy: 0.7407\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9439 - val_loss: 0.5380 - val_accuracy: 0.7593\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1617 - accuracy: 0.9439 - val_loss: 0.5553 - val_accuracy: 0.7593\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1577 - accuracy: 0.9486 - val_loss: 0.5654 - val_accuracy: 0.7593\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1701 - accuracy: 0.9486 - val_loss: 0.5622 - val_accuracy: 0.7407\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1890 - accuracy: 0.9299 - val_loss: 0.5320 - val_accuracy: 0.7593\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1763 - accuracy: 0.9299 - val_loss: 0.4876 - val_accuracy: 0.7593\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1971 - accuracy: 0.9159 - val_loss: 0.5244 - val_accuracy: 0.7407\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1802 - accuracy: 0.9252 - val_loss: 0.5607 - val_accuracy: 0.7037\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1560 - accuracy: 0.9439 - val_loss: 0.5293 - val_accuracy: 0.7222\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.9299 - val_loss: 0.5329 - val_accuracy: 0.7222\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1684 - accuracy: 0.9346 - val_loss: 0.5459 - val_accuracy: 0.7407\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1363 - accuracy: 0.9533 - val_loss: 0.5524 - val_accuracy: 0.7407\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1416 - accuracy: 0.9439 - val_loss: 0.5272 - val_accuracy: 0.7222\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1415 - accuracy: 0.9393 - val_loss: 0.5291 - val_accuracy: 0.7222\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1129 - accuracy: 0.9486 - val_loss: 0.5132 - val_accuracy: 0.7222\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.9626 - val_loss: 0.5251 - val_accuracy: 0.7407\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9766 - val_loss: 0.5280 - val_accuracy: 0.7222\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1021 - accuracy: 0.9533 - val_loss: 0.5225 - val_accuracy: 0.7407\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0788 - accuracy: 0.9720 - val_loss: 0.5124 - val_accuracy: 0.7222\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9579 - val_loss: 0.5122 - val_accuracy: 0.7222\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0871 - accuracy: 0.9626 - val_loss: 0.5589 - val_accuracy: 0.7222\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0938 - accuracy: 0.9720 - val_loss: 0.5456 - val_accuracy: 0.7037\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9720 - val_loss: 0.5281 - val_accuracy: 0.7037\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 0.9673 - val_loss: 0.5074 - val_accuracy: 0.7037\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0957 - accuracy: 0.9579 - val_loss: 0.4959 - val_accuracy: 0.7222\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0808 - accuracy: 0.9673 - val_loss: 0.5796 - val_accuracy: 0.7037\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0788 - accuracy: 0.9720 - val_loss: 0.5708 - val_accuracy: 0.7037\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9626 - val_loss: 0.5463 - val_accuracy: 0.7222\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9720 - val_loss: 0.5453 - val_accuracy: 0.7407\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1059 - accuracy: 0.9626 - val_loss: 0.5593 - val_accuracy: 0.7222\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1133 - accuracy: 0.9626 - val_loss: 0.5608 - val_accuracy: 0.7222\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0951 - accuracy: 0.9720 - val_loss: 0.4876 - val_accuracy: 0.7593\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.9439 - val_loss: 0.4973 - val_accuracy: 0.7407\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0948 - accuracy: 0.9626 - val_loss: 0.5005 - val_accuracy: 0.7407\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0819 - accuracy: 0.9720 - val_loss: 0.4894 - val_accuracy: 0.7593\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9673 - val_loss: 0.5141 - val_accuracy: 0.7407\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0591 - accuracy: 0.9813 - val_loss: 0.5526 - val_accuracy: 0.7222\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1061 - accuracy: 0.9533 - val_loss: 0.5257 - val_accuracy: 0.7407\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1118 - accuracy: 0.9673 - val_loss: 0.5331 - val_accuracy: 0.7593\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0700 - accuracy: 0.9720 - val_loss: 0.5729 - val_accuracy: 0.7593\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0962 - accuracy: 0.9673 - val_loss: 0.5595 - val_accuracy: 0.7593\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9720 - val_loss: 0.5289 - val_accuracy: 0.7222\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9720 - val_loss: 0.5539 - val_accuracy: 0.7407\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9766 - val_loss: 0.6224 - val_accuracy: 0.7407\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.7593\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0537 - accuracy: 0.9907 - val_loss: 0.5889 - val_accuracy: 0.7407\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9860 - val_loss: 0.6426 - val_accuracy: 0.7037\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9673 - val_loss: 0.6439 - val_accuracy: 0.7778\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 0.5736 - val_accuracy: 0.7593\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0988 - accuracy: 0.9720 - val_loss: 0.5477 - val_accuracy: 0.7778\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1062 - accuracy: 0.9579 - val_loss: 0.5322 - val_accuracy: 0.7963\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9766 - val_loss: 0.6383 - val_accuracy: 0.7222\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1243 - accuracy: 0.9533 - val_loss: 0.5594 - val_accuracy: 0.7778\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 0.9579 - val_loss: 0.5833 - val_accuracy: 0.7593\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1230 - accuracy: 0.9439 - val_loss: 0.6893 - val_accuracy: 0.7222\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9860 - val_loss: 0.6916 - val_accuracy: 0.7963\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9766 - val_loss: 0.7127 - val_accuracy: 0.7963\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0798 - accuracy: 0.9626 - val_loss: 0.7525 - val_accuracy: 0.7963\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0572 - accuracy: 0.9766 - val_loss: 0.6670 - val_accuracy: 0.8148\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0698 - accuracy: 0.9720 - val_loss: 0.6822 - val_accuracy: 0.7778\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.9766 - val_loss: 0.6638 - val_accuracy: 0.8519\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9907 - val_loss: 0.6422 - val_accuracy: 0.8148\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1045 - accuracy: 0.9626 - val_loss: 0.6959 - val_accuracy: 0.8148\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0488 - accuracy: 0.9860 - val_loss: 0.7320 - val_accuracy: 0.8148\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0640 - accuracy: 0.9860 - val_loss: 0.7338 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9860 - val_loss: 0.7388 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9953 - val_loss: 0.7372 - val_accuracy: 0.8148\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9907 - val_loss: 0.7348 - val_accuracy: 0.7963\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9907 - val_loss: 0.7537 - val_accuracy: 0.7963\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9766 - val_loss: 0.8158 - val_accuracy: 0.7593\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.8336 - val_accuracy: 0.7593\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9907 - val_loss: 0.8481 - val_accuracy: 0.7593\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.8296 - val_accuracy: 0.7593\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.8015 - val_accuracy: 0.7407\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.7747 - val_accuracy: 0.7593\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.7675 - val_accuracy: 0.7778\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9860 - val_loss: 0.7557 - val_accuracy: 0.7593\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9860 - val_loss: 0.7567 - val_accuracy: 0.7963\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.8777 - val_accuracy: 0.7593\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.8634 - val_accuracy: 0.7778\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9813 - val_loss: 0.9284 - val_accuracy: 0.7778\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9766 - val_loss: 0.9397 - val_accuracy: 0.7778\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.8728 - val_accuracy: 0.7963\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.9813 - val_loss: 0.8601 - val_accuracy: 0.7963\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 0.9907 - val_loss: 0.7917 - val_accuracy: 0.8148\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9907 - val_loss: 0.8219 - val_accuracy: 0.7593\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9813 - val_loss: 0.8526 - val_accuracy: 0.7222\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.8975 - val_accuracy: 0.7222\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9813 - val_loss: 0.9647 - val_accuracy: 0.7222\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 1.0311 - val_accuracy: 0.7222\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0433 - accuracy: 0.9720 - val_loss: 0.9119 - val_accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9860 - val_loss: 0.8556 - val_accuracy: 0.7963\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9907 - val_loss: 0.8939 - val_accuracy: 0.7593\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9860 - val_loss: 0.9780 - val_accuracy: 0.7963\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.7963\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9860 - val_loss: 1.1717 - val_accuracy: 0.7593\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9953 - val_loss: 1.0629 - val_accuracy: 0.7778\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9813 - val_loss: 0.8846 - val_accuracy: 0.8519\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9953 - val_loss: 0.8710 - val_accuracy: 0.8519\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.8752 - val_accuracy: 0.8519\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.8947 - val_accuracy: 0.8148\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.9313 - val_accuracy: 0.7963\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9860 - val_loss: 0.8516 - val_accuracy: 0.8148\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9907 - val_loss: 0.8327 - val_accuracy: 0.8704\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0397 - accuracy: 0.9813 - val_loss: 0.9139 - val_accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9907 - val_loss: 1.0230 - val_accuracy: 0.7593\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9907 - val_loss: 1.1302 - val_accuracy: 0.7593\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.1069 - val_accuracy: 0.7963\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 1.0763 - val_accuracy: 0.7778\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9953 - val_loss: 1.1100 - val_accuracy: 0.7963\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 1.1936 - val_accuracy: 0.7778\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9860 - val_loss: 1.1947 - val_accuracy: 0.7593\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 1.1717 - val_accuracy: 0.7778\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9907 - val_loss: 1.1665 - val_accuracy: 0.7593\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9907 - val_loss: 1.1515 - val_accuracy: 0.7778\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 1.1543 - val_accuracy: 0.7778\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9953 - val_loss: 1.1493 - val_accuracy: 0.7778\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9953 - val_loss: 1.1561 - val_accuracy: 0.7778\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.7778\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9953 - val_loss: 1.1785 - val_accuracy: 0.7778\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.7593\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9907 - val_loss: 1.2501 - val_accuracy: 0.7407\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.2689 - val_accuracy: 0.7407\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 1.2514 - val_accuracy: 0.7407\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 1.2620 - val_accuracy: 0.7407\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 1.2960 - val_accuracy: 0.6852\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9813 - val_loss: 1.1196 - val_accuracy: 0.7593\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 0.9907 - val_loss: 0.9999 - val_accuracy: 0.8148\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9907 - val_loss: 0.9833 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 1.0150 - val_accuracy: 0.8148\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9953 - val_loss: 1.0344 - val_accuracy: 0.7963\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.9924 - val_accuracy: 0.8148\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 1.0401 - val_accuracy: 0.8519\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 1.0460 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9907 - val_loss: 1.0738 - val_accuracy: 0.8148\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9907 - val_loss: 1.0700 - val_accuracy: 0.8519\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 1.0978 - val_accuracy: 0.8519\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 1.1155 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 1.0912 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 0.9907 - val_loss: 1.0627 - val_accuracy: 0.8333\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0457 - val_accuracy: 0.8148\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 1.0371 - val_accuracy: 0.8148\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 1.0225 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 1.0156 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.9973 - val_accuracy: 0.8148\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.8148\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.8148\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.9907 - val_loss: 0.9964 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0168 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.0352 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 1.0499 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9907 - val_loss: 1.0657 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0950 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 0.9907 - val_loss: 1.1009 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 1.1208 - val_accuracy: 0.8333\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.9953 - val_loss: 1.1171 - val_accuracy: 0.8333\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BD8C2BDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.6249 - accuracy: 0.6682 - val_loss: 0.6095 - val_accuracy: 0.7407\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4829 - accuracy: 0.7897 - val_loss: 0.5628 - val_accuracy: 0.7407\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4396 - accuracy: 0.8084 - val_loss: 0.5456 - val_accuracy: 0.7407\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4217 - accuracy: 0.8271 - val_loss: 0.5445 - val_accuracy: 0.7407\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.8224 - val_loss: 0.5462 - val_accuracy: 0.7407\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4217 - accuracy: 0.8598 - val_loss: 0.5538 - val_accuracy: 0.7593\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3840 - accuracy: 0.8271 - val_loss: 0.5647 - val_accuracy: 0.7593\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8411 - val_loss: 0.5749 - val_accuracy: 0.7407\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3613 - accuracy: 0.8505 - val_loss: 0.5764 - val_accuracy: 0.7593\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3613 - accuracy: 0.8645 - val_loss: 0.5833 - val_accuracy: 0.7593\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3422 - accuracy: 0.8551 - val_loss: 0.5858 - val_accuracy: 0.7778\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3462 - accuracy: 0.8645 - val_loss: 0.5815 - val_accuracy: 0.7593\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2922 - accuracy: 0.8785 - val_loss: 0.5867 - val_accuracy: 0.7778\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.8551 - val_loss: 0.5929 - val_accuracy: 0.7778\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2968 - accuracy: 0.8832 - val_loss: 0.5907 - val_accuracy: 0.7778\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2758 - accuracy: 0.8925 - val_loss: 0.5905 - val_accuracy: 0.7593\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2763 - accuracy: 0.8972 - val_loss: 0.5965 - val_accuracy: 0.7407\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2621 - accuracy: 0.9019 - val_loss: 0.6136 - val_accuracy: 0.7407\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2388 - accuracy: 0.9206 - val_loss: 0.6258 - val_accuracy: 0.7407\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2843 - accuracy: 0.9065 - val_loss: 0.6158 - val_accuracy: 0.7222\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2329 - accuracy: 0.9019 - val_loss: 0.6125 - val_accuracy: 0.7037\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2245 - accuracy: 0.9112 - val_loss: 0.6206 - val_accuracy: 0.7037\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2331 - accuracy: 0.9112 - val_loss: 0.6145 - val_accuracy: 0.7407\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2194 - accuracy: 0.9299 - val_loss: 0.6073 - val_accuracy: 0.7778\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2120 - accuracy: 0.9299 - val_loss: 0.6143 - val_accuracy: 0.7407\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1929 - accuracy: 0.9299 - val_loss: 0.6196 - val_accuracy: 0.7407\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1788 - accuracy: 0.9346 - val_loss: 0.6207 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.96 - 0s 10ms/step - loss: 0.1816 - accuracy: 0.9393 - val_loss: 0.6240 - val_accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1679 - accuracy: 0.9486 - val_loss: 0.6240 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1521 - accuracy: 0.9533 - val_loss: 0.6251 - val_accuracy: 0.6481\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1504 - accuracy: 0.9439 - val_loss: 0.6300 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1813 - accuracy: 0.9393 - val_loss: 0.6384 - val_accuracy: 0.7037\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9486 - val_loss: 0.6372 - val_accuracy: 0.6481\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1662 - accuracy: 0.9439 - val_loss: 0.6241 - val_accuracy: 0.7222\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1512 - accuracy: 0.9393 - val_loss: 0.6274 - val_accuracy: 0.5926\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1733 - accuracy: 0.9439 - val_loss: 0.6124 - val_accuracy: 0.6296\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.9393 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1055 - accuracy: 0.9720 - val_loss: 0.6159 - val_accuracy: 0.7037\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1126 - accuracy: 0.9673 - val_loss: 0.6104 - val_accuracy: 0.7407\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1018 - accuracy: 0.9486 - val_loss: 0.5969 - val_accuracy: 0.7407\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9766 - val_loss: 0.6000 - val_accuracy: 0.7593\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1153 - accuracy: 0.9579 - val_loss: 0.5850 - val_accuracy: 0.7593\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9393 - val_loss: 0.5783 - val_accuracy: 0.7593\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1171 - accuracy: 0.9626 - val_loss: 0.6091 - val_accuracy: 0.6852\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.9533 - val_loss: 0.5837 - val_accuracy: 0.7407\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.9486 - val_loss: 0.5888 - val_accuracy: 0.7222\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9346 - val_loss: 0.6258 - val_accuracy: 0.6296\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1206 - accuracy: 0.9579 - val_loss: 0.6686 - val_accuracy: 0.6481\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1068 - accuracy: 0.9533 - val_loss: 0.6934 - val_accuracy: 0.6296\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0766 - accuracy: 0.9766 - val_loss: 0.7032 - val_accuracy: 0.5926\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1073 - accuracy: 0.9533 - val_loss: 0.7015 - val_accuracy: 0.6296\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0965 - accuracy: 0.9673 - val_loss: 0.6876 - val_accuracy: 0.6481\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 0.9673 - val_loss: 0.6805 - val_accuracy: 0.6481\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9720 - val_loss: 0.6683 - val_accuracy: 0.7037\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0967 - accuracy: 0.9673 - val_loss: 0.6511 - val_accuracy: 0.7037\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0714 - accuracy: 0.9766 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.9813 - val_loss: 0.6767 - val_accuracy: 0.6852\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9720 - val_loss: 0.6810 - val_accuracy: 0.6296\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9673 - val_loss: 0.6690 - val_accuracy: 0.6296\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9860 - val_loss: 0.6338 - val_accuracy: 0.7037\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9579 - val_loss: 0.6298 - val_accuracy: 0.7037\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9720 - val_loss: 0.6861 - val_accuracy: 0.7222\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0853 - accuracy: 0.9720 - val_loss: 0.7526 - val_accuracy: 0.7222\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0808 - accuracy: 0.9626 - val_loss: 0.7370 - val_accuracy: 0.6481\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0659 - accuracy: 0.9813 - val_loss: 0.7392 - val_accuracy: 0.7222\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 0.9720 - val_loss: 0.7262 - val_accuracy: 0.7407\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 0.7184 - val_accuracy: 0.7037\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.7371 - val_accuracy: 0.6481\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9953 - val_loss: 0.7980 - val_accuracy: 0.6667\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.9626 - val_loss: 0.7904 - val_accuracy: 0.6667\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9720 - val_loss: 0.7475 - val_accuracy: 0.6667\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9626 - val_loss: 0.6946 - val_accuracy: 0.6667\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0677 - accuracy: 0.9813 - val_loss: 0.6318 - val_accuracy: 0.7407\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1014 - accuracy: 0.9579 - val_loss: 0.6340 - val_accuracy: 0.7037\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.9626 - val_loss: 0.6423 - val_accuracy: 0.7037\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1133 - accuracy: 0.9626 - val_loss: 0.6231 - val_accuracy: 0.7222\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1288 - accuracy: 0.9486 - val_loss: 0.5942 - val_accuracy: 0.7963\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9720 - val_loss: 0.5953 - val_accuracy: 0.7778\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.9533 - val_loss: 0.5981 - val_accuracy: 0.7407\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0895 - accuracy: 0.9579 - val_loss: 0.5833 - val_accuracy: 0.7037\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9813 - val_loss: 0.5788 - val_accuracy: 0.6852\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9720 - val_loss: 0.5842 - val_accuracy: 0.6852\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9907 - val_loss: 0.6307 - val_accuracy: 0.6667\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0527 - accuracy: 0.9860 - val_loss: 0.6594 - val_accuracy: 0.7593\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9766 - val_loss: 0.6759 - val_accuracy: 0.7037\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0443 - accuracy: 0.9953 - val_loss: 0.7151 - val_accuracy: 0.7407\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0673 - accuracy: 0.9766 - val_loss: 0.7772 - val_accuracy: 0.7778\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.7548 - val_accuracy: 0.7593\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9860 - val_loss: 0.7321 - val_accuracy: 0.7407\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 0.7222 - val_accuracy: 0.7593\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9813 - val_loss: 0.7595 - val_accuracy: 0.7778\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 0.9860 - val_loss: 0.7256 - val_accuracy: 0.7593\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9860 - val_loss: 0.6671 - val_accuracy: 0.7407\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9673 - val_loss: 0.7098 - val_accuracy: 0.7407\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9766 - val_loss: 0.7781 - val_accuracy: 0.7778\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0545 - accuracy: 0.9813 - val_loss: 0.7405 - val_accuracy: 0.7407\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0628 - accuracy: 0.9860 - val_loss: 0.7934 - val_accuracy: 0.7222\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0550 - accuracy: 0.9720 - val_loss: 0.8345 - val_accuracy: 0.7037\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0759 - accuracy: 0.9673 - val_loss: 0.8786 - val_accuracy: 0.7407\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0573 - accuracy: 0.9813 - val_loss: 0.8502 - val_accuracy: 0.7222\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9766 - val_loss: 0.8349 - val_accuracy: 0.7222\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0627 - accuracy: 0.9813 - val_loss: 0.8356 - val_accuracy: 0.7593\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0736 - accuracy: 0.9720 - val_loss: 0.8139 - val_accuracy: 0.7222\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.8143 - val_accuracy: 0.6667\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9860 - val_loss: 0.8482 - val_accuracy: 0.7222\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9813 - val_loss: 0.8528 - val_accuracy: 0.7407\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.8596 - val_accuracy: 0.6667\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9907 - val_loss: 0.9304 - val_accuracy: 0.7407\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9813 - val_loss: 0.9344 - val_accuracy: 0.7407\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 0.9907 - val_loss: 0.9697 - val_accuracy: 0.7407\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1095 - accuracy: 0.9720 - val_loss: 0.9949 - val_accuracy: 0.7407\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0790 - accuracy: 0.9720 - val_loss: 0.9420 - val_accuracy: 0.6852\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9953 - val_loss: 0.9138 - val_accuracy: 0.6852\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0422 - accuracy: 0.9860 - val_loss: 0.9204 - val_accuracy: 0.7407\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0585 - accuracy: 0.9766 - val_loss: 0.9242 - val_accuracy: 0.7407\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 0.9907 - val_loss: 0.9426 - val_accuracy: 0.7222\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0423 - accuracy: 0.9907 - val_loss: 0.9682 - val_accuracy: 0.7037\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9860 - val_loss: 0.9885 - val_accuracy: 0.7037\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0386 - accuracy: 0.9813 - val_loss: 1.0152 - val_accuracy: 0.7037\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 1.0335 - val_accuracy: 0.7222\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 1.0284 - val_accuracy: 0.7222\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 1.0227 - val_accuracy: 0.7407\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 1.0210 - val_accuracy: 0.7407\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 1.0432 - val_accuracy: 0.7407\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 0.9860 - val_loss: 1.0667 - val_accuracy: 0.7222\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9907 - val_loss: 1.0866 - val_accuracy: 0.7407\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 1.0975 - val_accuracy: 0.7407\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 1.1151 - val_accuracy: 0.7037\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9907 - val_loss: 1.1338 - val_accuracy: 0.7222\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9907 - val_loss: 1.1475 - val_accuracy: 0.7222\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.1648 - val_accuracy: 0.7407\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9907 - val_loss: 1.1967 - val_accuracy: 0.7222\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.7222\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 1.2362 - val_accuracy: 0.7222\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 1.2484 - val_accuracy: 0.7407\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0148 - accuracy: 0.9907 - val_loss: 1.2577 - val_accuracy: 0.7222\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2887 - val_accuracy: 0.7593\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9907 - val_loss: 1.2825 - val_accuracy: 0.7778\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 1.2857 - val_accuracy: 0.7407\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.9953 - val_loss: 1.3176 - val_accuracy: 0.7407\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3346 - val_accuracy: 0.7778\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 1.3311 - val_accuracy: 0.7778\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 1.3082 - val_accuracy: 0.7037\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9907 - val_loss: 1.3534 - val_accuracy: 0.6667\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.9813 - val_loss: 1.3846 - val_accuracy: 0.7778\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9860 - val_loss: 1.3356 - val_accuracy: 0.7222\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 1.3419 - val_accuracy: 0.6667\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 1.4487 - val_accuracy: 0.6667\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 1.5485 - val_accuracy: 0.6852\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 0.9953 - val_loss: 1.4569 - val_accuracy: 0.6481\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9860 - val_loss: 1.5753 - val_accuracy: 0.6667\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 1.6834 - val_accuracy: 0.6852\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 1.6655 - val_accuracy: 0.6667\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 1.6318 - val_accuracy: 0.6852\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9813 - val_loss: 1.5135 - val_accuracy: 0.6852\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9860 - val_loss: 1.5393 - val_accuracy: 0.6667\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 1.6377 - val_accuracy: 0.6852\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9907 - val_loss: 1.7014 - val_accuracy: 0.7037\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9813 - val_loss: 1.5862 - val_accuracy: 0.6852\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9860 - val_loss: 1.4385 - val_accuracy: 0.6852\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9813 - val_loss: 1.5709 - val_accuracy: 0.7222\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 0.9813 - val_loss: 1.6737 - val_accuracy: 0.7407\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 1.7211 - val_accuracy: 0.7222\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 1.6630 - val_accuracy: 0.6852\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9907 - val_loss: 1.6869 - val_accuracy: 0.7037\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9907 - val_loss: 1.7098 - val_accuracy: 0.7222\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.7013 - val_accuracy: 0.7222\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 1.7041 - val_accuracy: 0.7407\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 1.7222 - val_accuracy: 0.7037\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 1.7370 - val_accuracy: 0.7037\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9907 - val_loss: 1.7376 - val_accuracy: 0.7037\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.7519 - val_accuracy: 0.7222\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.7672 - val_accuracy: 0.7222\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 1.7821 - val_accuracy: 0.7037\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.7963 - val_accuracy: 0.7037\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9907 - val_loss: 1.8235 - val_accuracy: 0.7037\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 1.8430 - val_accuracy: 0.7037\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9907 - val_loss: 1.8384 - val_accuracy: 0.7037\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.9953 - val_loss: 1.8270 - val_accuracy: 0.7222\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 0.9953 - val_loss: 1.8151 - val_accuracy: 0.7407\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9907 - val_loss: 1.8140 - val_accuracy: 0.7407\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 1.8165 - val_accuracy: 0.7407\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.8259 - val_accuracy: 0.7593\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9907 - val_loss: 1.8441 - val_accuracy: 0.7222\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 1.8396 - val_accuracy: 0.7407\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 1.8532 - val_accuracy: 0.7222\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 0.9953 - val_loss: 1.8679 - val_accuracy: 0.7037\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9907 - val_loss: 1.8785 - val_accuracy: 0.7037\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 0.9907 - val_loss: 1.8853 - val_accuracy: 0.7037\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9953 - val_loss: 1.8882 - val_accuracy: 0.7037\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0093 - accuracy: 0.9953 - val_loss: 1.8797 - val_accuracy: 0.7037\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 0.9953 - val_loss: 1.8675 - val_accuracy: 0.7222\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.8728 - val_accuracy: 0.7222\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9907 - val_loss: 1.8930 - val_accuracy: 0.7222\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9907 - val_loss: 1.9216 - val_accuracy: 0.7037\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 0.9907 - val_loss: 1.9511 - val_accuracy: 0.7037\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9907 - val_loss: 1.9483 - val_accuracy: 0.7037\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 1.9478 - val_accuracy: 0.7037\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 1.9464 - val_accuracy: 0.7037\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.9396 - val_accuracy: 0.7037\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BDEE8F820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.5923 - accuracy: 0.6776 - val_loss: 0.5997 - val_accuracy: 0.8889\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4711 - accuracy: 0.7944 - val_loss: 0.5533 - val_accuracy: 0.8704\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4515 - accuracy: 0.8131 - val_loss: 0.5349 - val_accuracy: 0.8519\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4133 - accuracy: 0.8318 - val_loss: 0.5259 - val_accuracy: 0.8704\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4311 - accuracy: 0.8271 - val_loss: 0.5210 - val_accuracy: 0.8333\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3870 - accuracy: 0.8364 - val_loss: 0.5171 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3823 - accuracy: 0.8458 - val_loss: 0.5172 - val_accuracy: 0.8148\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3976 - accuracy: 0.8224 - val_loss: 0.5129 - val_accuracy: 0.7778\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3870 - accuracy: 0.8364 - val_loss: 0.5182 - val_accuracy: 0.7778\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3784 - accuracy: 0.8318 - val_loss: 0.5197 - val_accuracy: 0.7778\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3671 - accuracy: 0.8364 - val_loss: 0.5253 - val_accuracy: 0.7778\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3205 - accuracy: 0.8458 - val_loss: 0.5393 - val_accuracy: 0.7778\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3407 - accuracy: 0.8738 - val_loss: 0.5482 - val_accuracy: 0.7593\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3173 - accuracy: 0.8738 - val_loss: 0.5395 - val_accuracy: 0.7593\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.8645 - val_loss: 0.5301 - val_accuracy: 0.7593\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3380 - accuracy: 0.8598 - val_loss: 0.5391 - val_accuracy: 0.7593\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2930 - accuracy: 0.8879 - val_loss: 0.5525 - val_accuracy: 0.7778\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.8785 - val_loss: 0.5538 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3055 - accuracy: 0.8832 - val_loss: 0.5533 - val_accuracy: 0.8148\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2742 - accuracy: 0.9019 - val_loss: 0.5452 - val_accuracy: 0.8333\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3148 - accuracy: 0.8879 - val_loss: 0.5645 - val_accuracy: 0.7778\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2847 - accuracy: 0.8925 - val_loss: 0.5717 - val_accuracy: 0.7963\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2799 - accuracy: 0.9065 - val_loss: 0.5614 - val_accuracy: 0.8148\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2619 - accuracy: 0.9019 - val_loss: 0.5538 - val_accuracy: 0.7778\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2756 - accuracy: 0.8879 - val_loss: 0.5563 - val_accuracy: 0.7963\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2761 - accuracy: 0.8925 - val_loss: 0.5576 - val_accuracy: 0.7778\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2357 - accuracy: 0.9065 - val_loss: 0.5696 - val_accuracy: 0.7778\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2503 - accuracy: 0.9159 - val_loss: 0.5633 - val_accuracy: 0.7778\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2258 - accuracy: 0.9112 - val_loss: 0.5484 - val_accuracy: 0.7593\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2309 - accuracy: 0.8972 - val_loss: 0.5647 - val_accuracy: 0.7593\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2137 - accuracy: 0.9159 - val_loss: 0.5425 - val_accuracy: 0.7778\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1881 - accuracy: 0.9346 - val_loss: 0.5460 - val_accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2147 - accuracy: 0.9206 - val_loss: 0.5699 - val_accuracy: 0.7778\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.9346 - val_loss: 0.5537 - val_accuracy: 0.7778\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2012 - accuracy: 0.9393 - val_loss: 0.5335 - val_accuracy: 0.7963\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1789 - accuracy: 0.9439 - val_loss: 0.4958 - val_accuracy: 0.8148\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1716 - accuracy: 0.9299 - val_loss: 0.4913 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1848 - accuracy: 0.9299 - val_loss: 0.5047 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1652 - accuracy: 0.9346 - val_loss: 0.5215 - val_accuracy: 0.8148\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1408 - accuracy: 0.9486 - val_loss: 0.5247 - val_accuracy: 0.7593\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.9486 - val_loss: 0.5642 - val_accuracy: 0.7407\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1547 - accuracy: 0.9486 - val_loss: 0.5855 - val_accuracy: 0.5926\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.9439 - val_loss: 0.5942 - val_accuracy: 0.5741\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1560 - accuracy: 0.9486 - val_loss: 0.6045 - val_accuracy: 0.5741\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1683 - accuracy: 0.9393 - val_loss: 0.5503 - val_accuracy: 0.7778\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1370 - accuracy: 0.9439 - val_loss: 0.5627 - val_accuracy: 0.7407\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1465 - accuracy: 0.9486 - val_loss: 0.5481 - val_accuracy: 0.7778\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1273 - accuracy: 0.9626 - val_loss: 0.5382 - val_accuracy: 0.7963\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 0.9439 - val_loss: 0.5733 - val_accuracy: 0.7407\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1298 - accuracy: 0.9626 - val_loss: 0.5495 - val_accuracy: 0.7407\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1046 - accuracy: 0.9533 - val_loss: 0.5374 - val_accuracy: 0.7407\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1067 - accuracy: 0.9626 - val_loss: 0.5170 - val_accuracy: 0.7778\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1218 - accuracy: 0.9673 - val_loss: 0.5077 - val_accuracy: 0.8148\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1521 - accuracy: 0.9393 - val_loss: 0.5563 - val_accuracy: 0.7593\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0983 - accuracy: 0.9813 - val_loss: 0.5377 - val_accuracy: 0.7593\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1241 - accuracy: 0.9393 - val_loss: 0.5315 - val_accuracy: 0.7593\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0811 - accuracy: 0.9673 - val_loss: 0.5225 - val_accuracy: 0.7222\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0834 - accuracy: 0.9673 - val_loss: 0.5349 - val_accuracy: 0.7222\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0530 - accuracy: 0.9860 - val_loss: 0.5463 - val_accuracy: 0.7222\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9813 - val_loss: 0.5609 - val_accuracy: 0.7222\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0742 - accuracy: 0.9813 - val_loss: 0.5541 - val_accuracy: 0.7222\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0766 - accuracy: 0.9673 - val_loss: 0.6136 - val_accuracy: 0.6667\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0587 - accuracy: 0.9813 - val_loss: 0.5752 - val_accuracy: 0.7037\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0582 - accuracy: 0.9813 - val_loss: 0.5593 - val_accuracy: 0.7037\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 0.9907 - val_loss: 0.6145 - val_accuracy: 0.7037\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0690 - accuracy: 0.9766 - val_loss: 0.5552 - val_accuracy: 0.7222\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0794 - accuracy: 0.9766 - val_loss: 0.5436 - val_accuracy: 0.7407\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0771 - accuracy: 0.9673 - val_loss: 0.6476 - val_accuracy: 0.7407\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9766 - val_loss: 0.5897 - val_accuracy: 0.7037\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9579 - val_loss: 0.6473 - val_accuracy: 0.7037\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9720 - val_loss: 0.7195 - val_accuracy: 0.6852\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0797 - accuracy: 0.9766 - val_loss: 0.6302 - val_accuracy: 0.7037\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 0.9720 - val_loss: 0.7050 - val_accuracy: 0.6667\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1702 - accuracy: 0.9299 - val_loss: 0.7042 - val_accuracy: 0.6852\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1021 - accuracy: 0.9673 - val_loss: 0.6932 - val_accuracy: 0.6667\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.7405 - val_accuracy: 0.6852\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9766 - val_loss: 0.7283 - val_accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0755 - accuracy: 0.9626 - val_loss: 0.7565 - val_accuracy: 0.6852\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0706 - accuracy: 0.9720 - val_loss: 0.8560 - val_accuracy: 0.6667\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9626 - val_loss: 0.7157 - val_accuracy: 0.6852\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0824 - accuracy: 0.9720 - val_loss: 0.7346 - val_accuracy: 0.6852\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0606 - accuracy: 0.9766 - val_loss: 0.8034 - val_accuracy: 0.6296\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0683 - accuracy: 0.9907 - val_loss: 0.7095 - val_accuracy: 0.6852\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0619 - accuracy: 0.9766 - val_loss: 0.7432 - val_accuracy: 0.6852\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9860 - val_loss: 0.8026 - val_accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9953 - val_loss: 0.7799 - val_accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.7037\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0497 - accuracy: 0.9813 - val_loss: 0.8130 - val_accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.8174 - val_accuracy: 0.6667\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.8301 - val_accuracy: 0.7037\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.8443 - val_accuracy: 0.7037\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0675 - accuracy: 0.9720 - val_loss: 0.8022 - val_accuracy: 0.6852\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9813 - val_loss: 0.8320 - val_accuracy: 0.7037\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9860 - val_loss: 0.9575 - val_accuracy: 0.7037\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9673 - val_loss: 0.8872 - val_accuracy: 0.6852\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9299 - val_loss: 1.0064 - val_accuracy: 0.7407\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9766 - val_loss: 1.0660 - val_accuracy: 0.7037\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0619 - accuracy: 0.9766 - val_loss: 0.9379 - val_accuracy: 0.7222\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9813 - val_loss: 0.9916 - val_accuracy: 0.7222\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 1.1018 - val_accuracy: 0.6852\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0996 - accuracy: 0.9626 - val_loss: 1.0375 - val_accuracy: 0.7037\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.9813 - val_loss: 0.9746 - val_accuracy: 0.6852\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1401 - accuracy: 0.9673 - val_loss: 1.0927 - val_accuracy: 0.6852\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0900 - accuracy: 0.9673 - val_loss: 1.2738 - val_accuracy: 0.6481\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9813 - val_loss: 1.2535 - val_accuracy: 0.6667\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9766 - val_loss: 1.3161 - val_accuracy: 0.6667\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0718 - accuracy: 0.9766 - val_loss: 1.3068 - val_accuracy: 0.6852\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9766 - val_loss: 1.3246 - val_accuracy: 0.6667\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0515 - accuracy: 0.9766 - val_loss: 1.5010 - val_accuracy: 0.6667\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0479 - accuracy: 0.9766 - val_loss: 1.5081 - val_accuracy: 0.6852\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9860 - val_loss: 1.2437 - val_accuracy: 0.7037\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9813 - val_loss: 1.2446 - val_accuracy: 0.7407\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0429 - accuracy: 0.9766 - val_loss: 1.2685 - val_accuracy: 0.7037\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2358 - val_accuracy: 0.7037\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 1.2233 - val_accuracy: 0.7037\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 1.2582 - val_accuracy: 0.7037\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 1.3580 - val_accuracy: 0.6852\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 1.4161 - val_accuracy: 0.6667\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 1.4314 - val_accuracy: 0.6667\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9907 - val_loss: 1.4121 - val_accuracy: 0.6481\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9953 - val_loss: 1.3679 - val_accuracy: 0.6481\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9907 - val_loss: 1.3206 - val_accuracy: 0.7037\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 1.3158 - val_accuracy: 0.7037\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 0.9907 - val_loss: 1.3775 - val_accuracy: 0.6481\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 1.4448 - val_accuracy: 0.6481\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 1.4833 - val_accuracy: 0.6481\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 1.4347 - val_accuracy: 0.6481\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9907 - val_loss: 1.3979 - val_accuracy: 0.6852\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9860 - val_loss: 1.4360 - val_accuracy: 0.6667\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.4590 - val_accuracy: 0.6481\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.9953 - val_loss: 1.4674 - val_accuracy: 0.6852\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9907 - val_loss: 1.5059 - val_accuracy: 0.6852\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 1.5149 - val_accuracy: 0.6852\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9907 - val_loss: 1.4242 - val_accuracy: 0.6667\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.6667\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 1.4154 - val_accuracy: 0.7037\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 1.4420 - val_accuracy: 0.6852\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9860 - val_loss: 1.5384 - val_accuracy: 0.6852\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 1.6314 - val_accuracy: 0.6852\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9907 - val_loss: 1.6520 - val_accuracy: 0.6852\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 1.6404 - val_accuracy: 0.6852\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.6462 - val_accuracy: 0.6852\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 0.9953 - val_loss: 1.6235 - val_accuracy: 0.6852\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9860 - val_loss: 1.5063 - val_accuracy: 0.7037\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9907 - val_loss: 1.1689 - val_accuracy: 0.7593\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0652 - accuracy: 0.9720 - val_loss: 1.4440 - val_accuracy: 0.7593\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9766 - val_loss: 1.4342 - val_accuracy: 0.7407\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1102 - accuracy: 0.9720 - val_loss: 1.4800 - val_accuracy: 0.7407\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0720 - accuracy: 0.9720 - val_loss: 1.8552 - val_accuracy: 0.6296\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1443 - accuracy: 0.9486 - val_loss: 1.5060 - val_accuracy: 0.6667\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 0.9720 - val_loss: 1.4498 - val_accuracy: 0.6852\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9813 - val_loss: 1.6215 - val_accuracy: 0.6852\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0525 - accuracy: 0.9907 - val_loss: 1.7432 - val_accuracy: 0.6296\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0551 - accuracy: 0.9720 - val_loss: 1.6554 - val_accuracy: 0.6852\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.7455 - val_accuracy: 0.6481\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0776 - accuracy: 0.9720 - val_loss: 1.8972 - val_accuracy: 0.6296\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9953 - val_loss: 1.9776 - val_accuracy: 0.5741\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9907 - val_loss: 1.8957 - val_accuracy: 0.5926\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9953 - val_loss: 1.8833 - val_accuracy: 0.5926\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9860 - val_loss: 1.9526 - val_accuracy: 0.6296\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9953 - val_loss: 1.9348 - val_accuracy: 0.6296\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 1.7346 - val_accuracy: 0.6296\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 1.7834 - val_accuracy: 0.6296\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9860 - val_loss: 2.1254 - val_accuracy: 0.6111\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9907 - val_loss: 2.0988 - val_accuracy: 0.6111\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.6111\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 2.0110 - val_accuracy: 0.6111\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.6296\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.0566 - val_accuracy: 0.6296\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 0.9907 - val_loss: 2.0834 - val_accuracy: 0.6481\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 2.0805 - val_accuracy: 0.6481\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 2.0758 - val_accuracy: 0.6481\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9907 - val_loss: 2.0869 - val_accuracy: 0.6296\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.9953 - val_loss: 2.0917 - val_accuracy: 0.5926\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9907 - val_loss: 2.0805 - val_accuracy: 0.5926\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 2.0288 - val_accuracy: 0.5926\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 2.0710 - val_accuracy: 0.5926\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 2.1050 - val_accuracy: 0.5926\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 0.9907 - val_loss: 2.1294 - val_accuracy: 0.5926\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 2.1448 - val_accuracy: 0.5926\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.9953 - val_loss: 2.1480 - val_accuracy: 0.5926\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 2.1440 - val_accuracy: 0.5926\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 2.1278 - val_accuracy: 0.6111\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9953 - val_loss: 2.1242 - val_accuracy: 0.6111\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1278 - val_accuracy: 0.6111\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9907 - val_loss: 2.1244 - val_accuracy: 0.6111\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 2.1032 - val_accuracy: 0.6296\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9907 - val_loss: 2.0838 - val_accuracy: 0.6296\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0721 - val_accuracy: 0.6296\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9907 - val_loss: 2.0656 - val_accuracy: 0.6481\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 2.0704 - val_accuracy: 0.6481\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9953 - val_loss: 2.0843 - val_accuracy: 0.6296\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1014 - val_accuracy: 0.6481\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 2.1135 - val_accuracy: 0.6481\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 2.1020 - val_accuracy: 0.6481\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 2.1028 - val_accuracy: 0.6481\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 2.1048 - val_accuracy: 0.6667\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1077 - val_accuracy: 0.6667\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1112 - val_accuracy: 0.6667\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1143 - val_accuracy: 0.6667\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017989B1D790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.7158 - accuracy: 0.6093 - val_loss: 0.6323 - val_accuracy: 0.7358\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5219 - accuracy: 0.7070 - val_loss: 0.6078 - val_accuracy: 0.7547\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4887 - accuracy: 0.7535 - val_loss: 0.5901 - val_accuracy: 0.7547\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4825 - accuracy: 0.7860 - val_loss: 0.5798 - val_accuracy: 0.7547\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4667 - accuracy: 0.7953 - val_loss: 0.5742 - val_accuracy: 0.7736\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4529 - accuracy: 0.7814 - val_loss: 0.5773 - val_accuracy: 0.7547\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4167 - accuracy: 0.8233 - val_loss: 0.5860 - val_accuracy: 0.7547\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.8140 - val_loss: 0.6026 - val_accuracy: 0.7547\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8000 - val_loss: 0.6272 - val_accuracy: 0.6981\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3852 - accuracy: 0.8372 - val_loss: 0.6601 - val_accuracy: 0.6604\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3484 - accuracy: 0.8465 - val_loss: 0.6983 - val_accuracy: 0.6792\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3390 - accuracy: 0.8744 - val_loss: 0.7384 - val_accuracy: 0.6792\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 0.8279 - val_loss: 0.7795 - val_accuracy: 0.6792\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.8326 - val_loss: 0.8165 - val_accuracy: 0.6792\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3043 - accuracy: 0.8837 - val_loss: 0.8443 - val_accuracy: 0.6792\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2939 - accuracy: 0.8930 - val_loss: 0.8807 - val_accuracy: 0.6604\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2961 - accuracy: 0.8884 - val_loss: 0.9796 - val_accuracy: 0.5849\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2687 - accuracy: 0.9256 - val_loss: 1.1503 - val_accuracy: 0.5094\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2611 - accuracy: 0.8977 - val_loss: 1.1721 - val_accuracy: 0.4906\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2862 - accuracy: 0.8977 - val_loss: 1.2335 - val_accuracy: 0.5094\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2683 - accuracy: 0.8977 - val_loss: 1.3500 - val_accuracy: 0.5094\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2420 - accuracy: 0.9256 - val_loss: 1.3371 - val_accuracy: 0.5094\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2334 - accuracy: 0.9349 - val_loss: 1.3502 - val_accuracy: 0.5094\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2006 - accuracy: 0.9488 - val_loss: 1.3140 - val_accuracy: 0.5094\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2100 - accuracy: 0.9302 - val_loss: 1.3268 - val_accuracy: 0.5094\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1878 - accuracy: 0.9628 - val_loss: 1.3348 - val_accuracy: 0.5094\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1988 - accuracy: 0.9349 - val_loss: 1.3024 - val_accuracy: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1888 - accuracy: 0.9395 - val_loss: 1.3621 - val_accuracy: 0.5094\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1773 - accuracy: 0.9442 - val_loss: 1.4098 - val_accuracy: 0.4906\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1673 - accuracy: 0.9349 - val_loss: 1.3984 - val_accuracy: 0.4906\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1683 - accuracy: 0.9581 - val_loss: 1.4304 - val_accuracy: 0.4906\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1694 - accuracy: 0.9488 - val_loss: 1.3939 - val_accuracy: 0.5094\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1551 - accuracy: 0.9442 - val_loss: 1.3147 - val_accuracy: 0.5283\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1142 - accuracy: 0.9814 - val_loss: 1.2768 - val_accuracy: 0.5283\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1097 - accuracy: 0.9581 - val_loss: 1.2672 - val_accuracy: 0.5472\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1300 - accuracy: 0.9628 - val_loss: 1.3768 - val_accuracy: 0.5094\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9674 - val_loss: 1.4304 - val_accuracy: 0.5660\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0991 - accuracy: 0.9767 - val_loss: 1.3481 - val_accuracy: 0.5660\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0876 - accuracy: 0.9721 - val_loss: 1.4191 - val_accuracy: 0.5283\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0909 - accuracy: 0.9767 - val_loss: 1.2362 - val_accuracy: 0.5660\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 0.9907 - val_loss: 1.2116 - val_accuracy: 0.5660\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 0.9814 - val_loss: 1.2141 - val_accuracy: 0.5660\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0909 - accuracy: 0.9721 - val_loss: 1.2666 - val_accuracy: 0.5660\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9767 - val_loss: 1.3546 - val_accuracy: 0.5660\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9767 - val_loss: 1.4666 - val_accuracy: 0.5660\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.9721 - val_loss: 1.4993 - val_accuracy: 0.5660\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0728 - accuracy: 0.9814 - val_loss: 1.5491 - val_accuracy: 0.5849\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0620 - accuracy: 0.9860 - val_loss: 1.5774 - val_accuracy: 0.5660\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0885 - accuracy: 0.9860 - val_loss: 1.4358 - val_accuracy: 0.5660\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0879 - accuracy: 0.9721 - val_loss: 1.3933 - val_accuracy: 0.5660\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0748 - accuracy: 0.9814 - val_loss: 1.3903 - val_accuracy: 0.5660\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9860 - val_loss: 1.3229 - val_accuracy: 0.5660\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0904 - accuracy: 0.9721 - val_loss: 1.4143 - val_accuracy: 0.5660\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0654 - accuracy: 0.9860 - val_loss: 1.4450 - val_accuracy: 0.5660\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9860 - val_loss: 1.4006 - val_accuracy: 0.5660\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9814 - val_loss: 1.4634 - val_accuracy: 0.5660\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0680 - accuracy: 0.9860 - val_loss: 1.4296 - val_accuracy: 0.5660\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 1.3780 - val_accuracy: 0.5849\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9907 - val_loss: 1.3932 - val_accuracy: 0.5849\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9907 - val_loss: 1.3618 - val_accuracy: 0.5849\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0693 - accuracy: 0.9860 - val_loss: 1.3254 - val_accuracy: 0.5849\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9907 - val_loss: 1.2980 - val_accuracy: 0.5849\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0592 - accuracy: 0.9860 - val_loss: 1.2192 - val_accuracy: 0.6792\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9907 - val_loss: 1.1878 - val_accuracy: 0.6792\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0484 - accuracy: 0.9814 - val_loss: 1.1762 - val_accuracy: 0.6792\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0427 - accuracy: 0.9907 - val_loss: 1.1826 - val_accuracy: 0.6792\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 1.1821 - val_accuracy: 0.6792\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.1895 - val_accuracy: 0.6792\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.1990 - val_accuracy: 0.6981\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 1.1627 - val_accuracy: 0.6981\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.7170\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 1.1283 - val_accuracy: 0.6981\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.1710 - val_accuracy: 0.7170\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 1.1176 - val_accuracy: 0.6981\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.7170\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.7170\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1211 - val_accuracy: 0.6981\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.6981\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1269 - val_accuracy: 0.7170\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.2144 - val_accuracy: 0.7170\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.2633 - val_accuracy: 0.7170\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9953 - val_loss: 1.2630 - val_accuracy: 0.6981\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.6981\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.2937 - val_accuracy: 0.6981\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 0.6981\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3497 - val_accuracy: 0.6981\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 1.3709 - val_accuracy: 0.6981\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.6981\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.4070 - val_accuracy: 0.7170\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4020 - val_accuracy: 0.6981\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4030 - val_accuracy: 0.6981\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3949 - val_accuracy: 0.6981\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.3931 - val_accuracy: 0.7170\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.4082 - val_accuracy: 0.7358\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4396 - val_accuracy: 0.7358\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.4531 - val_accuracy: 0.7547\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.4620 - val_accuracy: 0.7547\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.4512 - val_accuracy: 0.7358\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4769 - val_accuracy: 0.7358\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.7358\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6247 - val_accuracy: 0.7736\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9953 - val_loss: 1.6169 - val_accuracy: 0.7736\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.5611 - val_accuracy: 0.7170\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.9674 - val_loss: 1.5575 - val_accuracy: 0.7358\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9907 - val_loss: 1.5859 - val_accuracy: 0.7736\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0580 - accuracy: 0.9814 - val_loss: 1.6142 - val_accuracy: 0.7736\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.9721 - val_loss: 1.3860 - val_accuracy: 0.7358\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1596 - accuracy: 0.9395 - val_loss: 1.5325 - val_accuracy: 0.7358\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2073 - accuracy: 0.9488 - val_loss: 1.5610 - val_accuracy: 0.7170\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1508 - accuracy: 0.9535 - val_loss: 1.4255 - val_accuracy: 0.7358\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1263 - accuracy: 0.9628 - val_loss: 1.5356 - val_accuracy: 0.6981\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 0.9488 - val_loss: 1.4161 - val_accuracy: 0.6792\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1474 - accuracy: 0.9302 - val_loss: 1.5397 - val_accuracy: 0.6604\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1207 - accuracy: 0.9535 - val_loss: 1.6231 - val_accuracy: 0.7170\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9488 - val_loss: 1.5157 - val_accuracy: 0.7170\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 1.4087 - val_accuracy: 0.6981\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9628 - val_loss: 1.4303 - val_accuracy: 0.6981\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0627 - accuracy: 0.9860 - val_loss: 1.4933 - val_accuracy: 0.7358\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9860 - val_loss: 1.5664 - val_accuracy: 0.7170\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 1.5856 - val_accuracy: 0.7358\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.9767 - val_loss: 1.5454 - val_accuracy: 0.6981\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0791 - accuracy: 0.9674 - val_loss: 1.6216 - val_accuracy: 0.6981\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 1.5973 - val_accuracy: 0.6981\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 0.9814 - val_loss: 1.5333 - val_accuracy: 0.6981\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 1.4451 - val_accuracy: 0.6604\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1243 - accuracy: 0.9442 - val_loss: 1.5581 - val_accuracy: 0.7170\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9767 - val_loss: 1.6043 - val_accuracy: 0.7358\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0976 - accuracy: 0.9674 - val_loss: 1.4471 - val_accuracy: 0.7925\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0509 - accuracy: 0.9814 - val_loss: 1.3466 - val_accuracy: 0.6604\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 1.3401 - val_accuracy: 0.6981\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 1.4214 - val_accuracy: 0.7547\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 1.5339 - val_accuracy: 0.7358\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9860 - val_loss: 1.5517 - val_accuracy: 0.7547\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.5828 - val_accuracy: 0.7547\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.5414 - val_accuracy: 0.7358\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.6276 - val_accuracy: 0.7358\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 1.6894 - val_accuracy: 0.7547\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 1.7207 - val_accuracy: 0.7547\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.7328 - val_accuracy: 0.7547\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.7366 - val_accuracy: 0.7547\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 1.7146 - val_accuracy: 0.7358\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.5839 - val_accuracy: 0.7358\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 1.7306 - val_accuracy: 0.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.8680 - val_accuracy: 0.7358\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9907 - val_loss: 1.7920 - val_accuracy: 0.7358\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.7547\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.6583 - val_accuracy: 0.7547\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.6591 - val_accuracy: 0.7358\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6888 - val_accuracy: 0.7547\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.7605 - val_accuracy: 0.7547\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9907 - val_loss: 1.7329 - val_accuracy: 0.7358\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.8665 - val_accuracy: 0.6792\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 1.8504 - val_accuracy: 0.6792\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 1.7933 - val_accuracy: 0.7547\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 1.8670 - val_accuracy: 0.7358\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 1.8471 - val_accuracy: 0.7170\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9953 - val_loss: 1.9010 - val_accuracy: 0.6981\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.9237 - val_accuracy: 0.6981\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.9907 - val_loss: 1.8917 - val_accuracy: 0.6981\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.9407 - val_accuracy: 0.6981\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9907 - val_loss: 1.9804 - val_accuracy: 0.7170\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.0208 - val_accuracy: 0.7358\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.0372 - val_accuracy: 0.6792\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9907 - val_loss: 1.9926 - val_accuracy: 0.7358\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.9389 - val_accuracy: 0.7547\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 1.9083 - val_accuracy: 0.7547\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.9277 - val_accuracy: 0.6792\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.9800 - val_accuracy: 0.6792\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 0.9953 - val_loss: 2.0053 - val_accuracy: 0.6981\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 2.0389 - val_accuracy: 0.6981\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.0572 - val_accuracy: 0.7170\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.0795 - val_accuracy: 0.7358\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.9953 - val_loss: 1.9927 - val_accuracy: 0.7170\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0496 - accuracy: 0.9814 - val_loss: 1.9317 - val_accuracy: 0.6981\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 2.0765 - val_accuracy: 0.6792\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9907 - val_loss: 2.0724 - val_accuracy: 0.7170\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9860 - val_loss: 2.1197 - val_accuracy: 0.6792\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1138 - val_accuracy: 0.6792\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.1755 - val_accuracy: 0.6604\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.2311 - val_accuracy: 0.6981\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 2.2500 - val_accuracy: 0.6981\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.2422 - val_accuracy: 0.7170\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 2.1995 - val_accuracy: 0.7170\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 1.9788 - val_accuracy: 0.6981\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 1.9973 - val_accuracy: 0.6981\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 2.1523 - val_accuracy: 0.6981\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.2668 - val_accuracy: 0.6792\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9953 - val_loss: 2.2951 - val_accuracy: 0.6792\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 2.2445 - val_accuracy: 0.6981\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.2276 - val_accuracy: 0.6792\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2304 - val_accuracy: 0.6792\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.2755 - val_accuracy: 0.6792\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.3258 - val_accuracy: 0.6981\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3537 - val_accuracy: 0.6981\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.3768 - val_accuracy: 0.6981\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4137 - val_accuracy: 0.6792\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.4386 - val_accuracy: 0.6792\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4483 - val_accuracy: 0.6792\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4634 - val_accuracy: 0.6604\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4715 - val_accuracy: 0.6604\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000179CDBCB790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.6389 - accuracy: 0.6326 - val_loss: 0.5777 - val_accuracy: 0.8113\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5075 - accuracy: 0.7907 - val_loss: 0.5300 - val_accuracy: 0.7736\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4644 - accuracy: 0.7953 - val_loss: 0.5080 - val_accuracy: 0.8113\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4697 - accuracy: 0.8186 - val_loss: 0.4984 - val_accuracy: 0.8302\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4384 - accuracy: 0.8140 - val_loss: 0.4989 - val_accuracy: 0.8113\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.8233 - val_loss: 0.5110 - val_accuracy: 0.8113\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3981 - accuracy: 0.8419 - val_loss: 0.5228 - val_accuracy: 0.8302\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.8465 - val_loss: 0.5293 - val_accuracy: 0.8302\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4188 - accuracy: 0.8372 - val_loss: 0.5302 - val_accuracy: 0.8491\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3825 - accuracy: 0.8512 - val_loss: 0.5307 - val_accuracy: 0.8302\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3633 - accuracy: 0.8558 - val_loss: 0.5323 - val_accuracy: 0.8302\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.8558 - val_loss: 0.5426 - val_accuracy: 0.8113\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3443 - accuracy: 0.8744 - val_loss: 0.5532 - val_accuracy: 0.8113\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3538 - accuracy: 0.8605 - val_loss: 0.5661 - val_accuracy: 0.7925\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.8419 - val_loss: 0.5559 - val_accuracy: 0.7736\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3433 - accuracy: 0.8744 - val_loss: 0.5585 - val_accuracy: 0.7925\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.8605 - val_loss: 0.5882 - val_accuracy: 0.7358\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2876 - accuracy: 0.9023 - val_loss: 0.5988 - val_accuracy: 0.7358\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8791 - val_loss: 0.5836 - val_accuracy: 0.7358\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3225 - accuracy: 0.8837 - val_loss: 0.5973 - val_accuracy: 0.7170\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3075 - accuracy: 0.8837 - val_loss: 0.5900 - val_accuracy: 0.6792\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2839 - accuracy: 0.8837 - val_loss: 0.5804 - val_accuracy: 0.6792\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2629 - accuracy: 0.9023 - val_loss: 0.5888 - val_accuracy: 0.6792\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2560 - accuracy: 0.8930 - val_loss: 0.6112 - val_accuracy: 0.6415\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2510 - accuracy: 0.8930 - val_loss: 0.6363 - val_accuracy: 0.6226\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2581 - accuracy: 0.9116 - val_loss: 0.6092 - val_accuracy: 0.6604\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2484 - accuracy: 0.9163 - val_loss: 0.5964 - val_accuracy: 0.6792\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2608 - accuracy: 0.8837 - val_loss: 0.6049 - val_accuracy: 0.6415\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2008 - accuracy: 0.8977 - val_loss: 0.6197 - val_accuracy: 0.6226\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2195 - accuracy: 0.9256 - val_loss: 0.6037 - val_accuracy: 0.6415\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2029 - accuracy: 0.9302 - val_loss: 0.5975 - val_accuracy: 0.6792\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1943 - accuracy: 0.9256 - val_loss: 0.6156 - val_accuracy: 0.6415\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1907 - accuracy: 0.9209 - val_loss: 0.6251 - val_accuracy: 0.6226\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1910 - accuracy: 0.9256 - val_loss: 0.5798 - val_accuracy: 0.7358\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2045 - accuracy: 0.9163 - val_loss: 0.5778 - val_accuracy: 0.7170\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1968 - accuracy: 0.9256 - val_loss: 0.6093 - val_accuracy: 0.6792\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1823 - accuracy: 0.9395 - val_loss: 0.5922 - val_accuracy: 0.7358\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1817 - accuracy: 0.9209 - val_loss: 0.5643 - val_accuracy: 0.8113\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1661 - accuracy: 0.9256 - val_loss: 0.5786 - val_accuracy: 0.8113\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1697 - accuracy: 0.9302 - val_loss: 0.5996 - val_accuracy: 0.7736\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1561 - accuracy: 0.9442 - val_loss: 0.5950 - val_accuracy: 0.7358\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1605 - accuracy: 0.9395 - val_loss: 0.5931 - val_accuracy: 0.7170\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1540 - accuracy: 0.9442 - val_loss: 0.6128 - val_accuracy: 0.6604\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1777 - accuracy: 0.9070 - val_loss: 0.6432 - val_accuracy: 0.5283\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1825 - accuracy: 0.9302 - val_loss: 0.5950 - val_accuracy: 0.7736\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1610 - accuracy: 0.9349 - val_loss: 0.5575 - val_accuracy: 0.8113\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1822 - accuracy: 0.9023 - val_loss: 0.5718 - val_accuracy: 0.8302\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1463 - accuracy: 0.9535 - val_loss: 0.5598 - val_accuracy: 0.8113\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.9442 - val_loss: 0.5572 - val_accuracy: 0.8113\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1482 - accuracy: 0.9349 - val_loss: 0.5550 - val_accuracy: 0.8113\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1570 - accuracy: 0.9349 - val_loss: 0.5565 - val_accuracy: 0.8113\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1401 - accuracy: 0.9581 - val_loss: 0.5487 - val_accuracy: 0.7925\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1295 - accuracy: 0.9628 - val_loss: 0.5203 - val_accuracy: 0.8302\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9256 - val_loss: 0.5795 - val_accuracy: 0.7925\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1224 - accuracy: 0.9535 - val_loss: 0.5663 - val_accuracy: 0.8302\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1165 - accuracy: 0.9535 - val_loss: 0.5461 - val_accuracy: 0.8679\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1054 - accuracy: 0.9535 - val_loss: 0.5548 - val_accuracy: 0.8302\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0965 - accuracy: 0.9721 - val_loss: 0.5683 - val_accuracy: 0.8113\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9674 - val_loss: 0.5612 - val_accuracy: 0.8113\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1044 - accuracy: 0.9581 - val_loss: 0.5641 - val_accuracy: 0.7925\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.9628 - val_loss: 0.5634 - val_accuracy: 0.8302\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9814 - val_loss: 0.5678 - val_accuracy: 0.8113\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0805 - accuracy: 0.9814 - val_loss: 0.5648 - val_accuracy: 0.8302\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0680 - accuracy: 0.9721 - val_loss: 0.5675 - val_accuracy: 0.8491\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0528 - accuracy: 0.9953 - val_loss: 0.5723 - val_accuracy: 0.7925\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0811 - accuracy: 0.9721 - val_loss: 0.5161 - val_accuracy: 0.8302\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1028 - accuracy: 0.9581 - val_loss: 0.5830 - val_accuracy: 0.7170\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9767 - val_loss: 0.5769 - val_accuracy: 0.6981\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0774 - accuracy: 0.9721 - val_loss: 0.5135 - val_accuracy: 0.8302\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 0.9907 - val_loss: 0.5123 - val_accuracy: 0.8302\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0979 - accuracy: 0.9674 - val_loss: 0.5325 - val_accuracy: 0.7925\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0794 - accuracy: 0.9767 - val_loss: 0.5480 - val_accuracy: 0.7547\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9767 - val_loss: 0.5535 - val_accuracy: 0.7170\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 0.9674 - val_loss: 0.5536 - val_accuracy: 0.7547\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9814 - val_loss: 0.5818 - val_accuracy: 0.5660\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0811 - accuracy: 0.9674 - val_loss: 0.5267 - val_accuracy: 0.8113\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9721 - val_loss: 0.5266 - val_accuracy: 0.7547\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1092 - accuracy: 0.9581 - val_loss: 0.5019 - val_accuracy: 0.7925\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0785 - accuracy: 0.9628 - val_loss: 0.4798 - val_accuracy: 0.8302\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.9628 - val_loss: 0.5340 - val_accuracy: 0.7736\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0848 - accuracy: 0.9814 - val_loss: 0.5543 - val_accuracy: 0.7547\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.9860 - val_loss: 0.5614 - val_accuracy: 0.7170\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.5605 - val_accuracy: 0.6792\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0379 - accuracy: 0.9953 - val_loss: 0.5320 - val_accuracy: 0.7547\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0712 - accuracy: 0.9767 - val_loss: 0.5712 - val_accuracy: 0.6981\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 0.7197 - val_accuracy: 0.6604\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1181 - accuracy: 0.9488 - val_loss: 0.5050 - val_accuracy: 0.8302\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1059 - accuracy: 0.9581 - val_loss: 0.6269 - val_accuracy: 0.6792\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1324 - accuracy: 0.9628 - val_loss: 0.5592 - val_accuracy: 0.7547\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1382 - accuracy: 0.9395 - val_loss: 0.5391 - val_accuracy: 0.7925\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1037 - accuracy: 0.9628 - val_loss: 0.7046 - val_accuracy: 0.6981\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1055 - accuracy: 0.9488 - val_loss: 0.5417 - val_accuracy: 0.8302\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0796 - accuracy: 0.9628 - val_loss: 0.5372 - val_accuracy: 0.8491\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1006 - accuracy: 0.9628 - val_loss: 0.5823 - val_accuracy: 0.7925\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 0.9814 - val_loss: 0.5692 - val_accuracy: 0.7547\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9860 - val_loss: 0.6081 - val_accuracy: 0.7925\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9907 - val_loss: 0.6872 - val_accuracy: 0.7547\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0768 - accuracy: 0.9721 - val_loss: 0.6916 - val_accuracy: 0.7925\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.6646 - val_accuracy: 0.8113\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0505 - accuracy: 0.9767 - val_loss: 0.6932 - val_accuracy: 0.7736\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.7925\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9860 - val_loss: 0.6333 - val_accuracy: 0.7925\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.6074 - val_accuracy: 0.8302\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.6323 - val_accuracy: 0.7736\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0409 - accuracy: 0.9907 - val_loss: 0.7152 - val_accuracy: 0.7736\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.7925\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9860 - val_loss: 0.6744 - val_accuracy: 0.8113\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 0.7382 - val_accuracy: 0.7736\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.7943 - val_accuracy: 0.7358\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 0.7584 - val_accuracy: 0.7925\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9953 - val_loss: 0.7282 - val_accuracy: 0.8302\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.7376 - val_accuracy: 0.8302\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.7925\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.8525 - val_accuracy: 0.7358\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7547\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.7547\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8873 - val_accuracy: 0.7736\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.7736\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.8756 - val_accuracy: 0.7925\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.8901 - val_accuracy: 0.7925\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.9181 - val_accuracy: 0.7925\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.7925\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.7925\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9787 - val_accuracy: 0.7925\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.8113\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.8113\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.7925\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9953 - val_loss: 1.0083 - val_accuracy: 0.7925\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.7925\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.0133 - val_accuracy: 0.7925\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0266 - val_accuracy: 0.7925\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.8113\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.7925\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0762 - val_accuracy: 0.7925\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.0987 - val_accuracy: 0.7925\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1207 - val_accuracy: 0.7925\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1327 - val_accuracy: 0.7925\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.7925\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.7925\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1598 - val_accuracy: 0.7925\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.8302\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.1140 - val_accuracy: 0.8113\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.8113\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 1.0672 - val_accuracy: 0.8302\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0563 - val_accuracy: 0.8113\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.8113\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9907 - val_loss: 1.0701 - val_accuracy: 0.8113\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 0.9814 - val_loss: 1.0930 - val_accuracy: 0.7925\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0856 - accuracy: 0.9767 - val_loss: 0.9998 - val_accuracy: 0.8302\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.9721 - val_loss: 0.9936 - val_accuracy: 0.8113\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.9256 - val_loss: 0.9857 - val_accuracy: 0.8491\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0973 - accuracy: 0.9721 - val_loss: 0.9632 - val_accuracy: 0.7925\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1017 - accuracy: 0.9535 - val_loss: 1.0369 - val_accuracy: 0.7736\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9721 - val_loss: 0.9421 - val_accuracy: 0.7736\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1187 - accuracy: 0.9581 - val_loss: 0.9248 - val_accuracy: 0.7736\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1154 - accuracy: 0.9488 - val_loss: 1.0244 - val_accuracy: 0.7736\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0896 - accuracy: 0.9628 - val_loss: 1.0607 - val_accuracy: 0.7925\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.9721 - val_loss: 1.0057 - val_accuracy: 0.7736\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1190 - accuracy: 0.9721 - val_loss: 1.0312 - val_accuracy: 0.7547\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9860 - val_loss: 1.2029 - val_accuracy: 0.7358\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1045 - accuracy: 0.9628 - val_loss: 0.9387 - val_accuracy: 0.8113\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9674 - val_loss: 0.9843 - val_accuracy: 0.7925\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0819 - accuracy: 0.9767 - val_loss: 0.9690 - val_accuracy: 0.7736\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0583 - accuracy: 0.9814 - val_loss: 0.9432 - val_accuracy: 0.7925\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0395 - accuracy: 0.9907 - val_loss: 0.9566 - val_accuracy: 0.7736\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0379 - accuracy: 0.9907 - val_loss: 0.9602 - val_accuracy: 0.8113\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.9544 - val_accuracy: 0.8113\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9860 - val_loss: 0.9752 - val_accuracy: 0.8113\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 1.0879 - val_accuracy: 0.8113\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.9953 - val_loss: 1.1928 - val_accuracy: 0.7925\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 0.9814 - val_loss: 1.2329 - val_accuracy: 0.8113\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9907 - val_loss: 1.3267 - val_accuracy: 0.7925\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9628 - val_loss: 1.3306 - val_accuracy: 0.7925\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9907 - val_loss: 1.3365 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.3945 - val_accuracy: 0.7925\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9721 - val_loss: 1.4923 - val_accuracy: 0.7358\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 0.9860 - val_loss: 1.5113 - val_accuracy: 0.7547\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0354 - accuracy: 0.9860 - val_loss: 1.4975 - val_accuracy: 0.7736\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0467 - accuracy: 0.9814 - val_loss: 1.5335 - val_accuracy: 0.7547\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9767 - val_loss: 1.5367 - val_accuracy: 0.7547\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 1.5326 - val_accuracy: 0.7547\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 1.4692 - val_accuracy: 0.8113\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 0.8113\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.4627 - val_accuracy: 0.7925\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.5287 - val_accuracy: 0.7736\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.9953 - val_loss: 1.6061 - val_accuracy: 0.7358\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 0.9953 - val_loss: 1.6332 - val_accuracy: 0.7358\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.6316 - val_accuracy: 0.7358\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6268 - val_accuracy: 0.7358\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 1.5696 - val_accuracy: 0.7547\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5388 - val_accuracy: 0.7547\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 0.9907 - val_loss: 1.5431 - val_accuracy: 0.7736\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5637 - val_accuracy: 0.7736\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.6056 - val_accuracy: 0.7547\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6495 - val_accuracy: 0.7358\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6777 - val_accuracy: 0.7358\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 0.9907 - val_loss: 1.6646 - val_accuracy: 0.7547\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6629 - val_accuracy: 0.7547\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9953 - val_loss: 1.6784 - val_accuracy: 0.7547\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.7716 - val_accuracy: 0.7358\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BDBC55CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/'+'Fire/'+'/CDI_Based/Intensity/CSV/'+'Gray'+'.csv',index_col=0)\n",
    "\n",
    "y=data['Class'].values\n",
    "X=data.drop(['Class'], axis=1).values\n",
    "#X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    std =StandardScaler()\n",
    "    X_train=std.fit_transform(X[train])\n",
    "    X_test=std.transform(X[test])\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    intput_shape=(X_train.shape[1], 1)\n",
    "    model.add(Conv1D(128, kernel_size=3,padding = 'same',activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Conv1D(128,kernel_size=3,padding = 'same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                         optimizer=Adam(lr = lr),\n",
    "                         metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=\"1d+cnn.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "    history=model.fit(X_train, y[train],\n",
    "                epochs=200,\n",
    "                batch_size=64,\n",
    "                validation_data=(X_test, y[test]),\n",
    "                verbose=1,\n",
    "                callbacks=[checkpointer]).history\n",
    "    model=load_model('1d+cnn.h5')\n",
    "    y_prob = model.predict(X_test, verbose=0)\n",
    "    fpr_test,tpr_test,_ = roc_curve(y[test],y_prob)     \n",
    "    auc_test = auc(fpr_test,tpr_test)  \n",
    "    interp_tpr = np.interp(mean_fpr,fpr_test, tpr_test)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(auc_test)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='dodgerblue',label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title='ROC of gray'+ ' on Dataset ')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T01:51:31.805333Z",
     "start_time": "2020-10-03T01:49:53.696927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.7147 - accuracy: 0.5000 - val_loss: 0.5729 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6425 - accuracy: 0.6262 - val_loss: 0.5043 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5995 - accuracy: 0.6869 - val_loss: 0.4528 - val_accuracy: 0.8519\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5710 - accuracy: 0.6822 - val_loss: 0.3968 - val_accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5166 - accuracy: 0.7523 - val_loss: 0.3796 - val_accuracy: 0.8519\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5464 - accuracy: 0.7617 - val_loss: 0.3792 - val_accuracy: 0.8148\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4784 - accuracy: 0.7850 - val_loss: 0.3455 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4723 - accuracy: 0.7897 - val_loss: 0.3344 - val_accuracy: 0.7963\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4467 - accuracy: 0.8364 - val_loss: 0.3274 - val_accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4779 - accuracy: 0.7944 - val_loss: 0.3207 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4640 - accuracy: 0.7757 - val_loss: 0.3401 - val_accuracy: 0.8519\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5008 - accuracy: 0.7617 - val_loss: 0.3347 - val_accuracy: 0.8148\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4926 - accuracy: 0.7897 - val_loss: 0.3517 - val_accuracy: 0.8519\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4988 - accuracy: 0.7617 - val_loss: 0.3313 - val_accuracy: 0.8148\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4960 - accuracy: 0.7664 - val_loss: 0.3346 - val_accuracy: 0.8148\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4597 - accuracy: 0.7991 - val_loss: 0.3453 - val_accuracy: 0.8148\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4889 - accuracy: 0.7804 - val_loss: 0.3682 - val_accuracy: 0.8704\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4735 - accuracy: 0.8084 - val_loss: 0.3647 - val_accuracy: 0.8519\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4637 - accuracy: 0.7944 - val_loss: 0.3639 - val_accuracy: 0.8519\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4569 - accuracy: 0.8178 - val_loss: 0.3947 - val_accuracy: 0.8519\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4434 - accuracy: 0.8037 - val_loss: 0.3649 - val_accuracy: 0.8704\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4720 - accuracy: 0.7897 - val_loss: 0.3375 - val_accuracy: 0.8519\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4812 - accuracy: 0.7944 - val_loss: 0.3496 - val_accuracy: 0.8704\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4467 - accuracy: 0.8084 - val_loss: 0.3731 - val_accuracy: 0.8519\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4639 - accuracy: 0.7850 - val_loss: 0.3447 - val_accuracy: 0.8704\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4575 - accuracy: 0.7897 - val_loss: 0.3560 - val_accuracy: 0.8519\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4350 - accuracy: 0.8131 - val_loss: 0.3491 - val_accuracy: 0.8704\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4599 - accuracy: 0.7944 - val_loss: 0.3727 - val_accuracy: 0.8704\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4829 - accuracy: 0.7944 - val_loss: 0.3548 - val_accuracy: 0.8704\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4687 - accuracy: 0.7850 - val_loss: 0.3450 - val_accuracy: 0.8519\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4501 - accuracy: 0.8364 - val_loss: 0.3667 - val_accuracy: 0.8704\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.7944 - val_loss: 0.3604 - val_accuracy: 0.8519\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4617 - accuracy: 0.8224 - val_loss: 0.3714 - val_accuracy: 0.8704\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4709 - accuracy: 0.8037 - val_loss: 0.3794 - val_accuracy: 0.8519\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4614 - accuracy: 0.7897 - val_loss: 0.3649 - val_accuracy: 0.8704\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4703 - accuracy: 0.7710 - val_loss: 0.3622 - val_accuracy: 0.8704\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4376 - accuracy: 0.8131 - val_loss: 0.3554 - val_accuracy: 0.8704\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4656 - accuracy: 0.8131 - val_loss: 0.3610 - val_accuracy: 0.8704\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4464 - accuracy: 0.8131 - val_loss: 0.3564 - val_accuracy: 0.8519\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4628 - accuracy: 0.7944 - val_loss: 0.3588 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4403 - accuracy: 0.7757 - val_loss: 0.3793 - val_accuracy: 0.8704\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4539 - accuracy: 0.8131 - val_loss: 0.3744 - val_accuracy: 0.8519\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4328 - accuracy: 0.8037 - val_loss: 0.3539 - val_accuracy: 0.8519\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4739 - accuracy: 0.7944 - val_loss: 0.3623 - val_accuracy: 0.8519\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4725 - accuracy: 0.8084 - val_loss: 0.3740 - val_accuracy: 0.8704\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4389 - accuracy: 0.8178 - val_loss: 0.3934 - val_accuracy: 0.8704\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4856 - accuracy: 0.7710 - val_loss: 0.3863 - val_accuracy: 0.8704\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4774 - accuracy: 0.7757 - val_loss: 0.3694 - val_accuracy: 0.8704\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4482 - accuracy: 0.8084 - val_loss: 0.3908 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4593 - accuracy: 0.7850 - val_loss: 0.3734 - val_accuracy: 0.8704\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4684 - accuracy: 0.8037 - val_loss: 0.3491 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4677 - accuracy: 0.7944 - val_loss: 0.3777 - val_accuracy: 0.8519\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4801 - accuracy: 0.7664 - val_loss: 0.3707 - val_accuracy: 0.8704\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4340 - accuracy: 0.8224 - val_loss: 0.3891 - val_accuracy: 0.8704\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4573 - accuracy: 0.7944 - val_loss: 0.3955 - val_accuracy: 0.8704\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4736 - accuracy: 0.8037 - val_loss: 0.3689 - val_accuracy: 0.8704\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4128 - accuracy: 0.8178 - val_loss: 0.3533 - val_accuracy: 0.8519\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4562 - accuracy: 0.7850 - val_loss: 0.3602 - val_accuracy: 0.8704\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4324 - accuracy: 0.7897 - val_loss: 0.3959 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8271 - val_loss: 0.3620 - val_accuracy: 0.8704\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4597 - accuracy: 0.7850 - val_loss: 0.3501 - val_accuracy: 0.8519\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4756 - accuracy: 0.7944 - val_loss: 0.3869 - val_accuracy: 0.8519\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4416 - accuracy: 0.7991 - val_loss: 0.3597 - val_accuracy: 0.8519\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4735 - accuracy: 0.7991 - val_loss: 0.3576 - val_accuracy: 0.8519\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4403 - accuracy: 0.7991 - val_loss: 0.3684 - val_accuracy: 0.8519\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4542 - accuracy: 0.7944 - val_loss: 0.3575 - val_accuracy: 0.8704\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4308 - accuracy: 0.8131 - val_loss: 0.3587 - val_accuracy: 0.8704\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4410 - accuracy: 0.8084 - val_loss: 0.3559 - val_accuracy: 0.8519\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4528 - accuracy: 0.8131 - val_loss: 0.3908 - val_accuracy: 0.8704\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4548 - accuracy: 0.8084 - val_loss: 0.3462 - val_accuracy: 0.8519\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4308 - accuracy: 0.8224 - val_loss: 0.3442 - val_accuracy: 0.8519\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4472 - accuracy: 0.8084 - val_loss: 0.3867 - val_accuracy: 0.8704\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4349 - accuracy: 0.7944 - val_loss: 0.3789 - val_accuracy: 0.8704\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4572 - accuracy: 0.8224 - val_loss: 0.3768 - val_accuracy: 0.8704\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8178 - val_loss: 0.3853 - val_accuracy: 0.8704\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4418 - accuracy: 0.7850 - val_loss: 0.4146 - val_accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4276 - accuracy: 0.7850 - val_loss: 0.3956 - val_accuracy: 0.8704\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4221 - accuracy: 0.8037 - val_loss: 0.4091 - val_accuracy: 0.8519\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4966 - accuracy: 0.7850 - val_loss: 0.3936 - val_accuracy: 0.8704\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.8131 - val_loss: 0.3550 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4771 - accuracy: 0.7710 - val_loss: 0.3659 - val_accuracy: 0.8519\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4363 - accuracy: 0.8037 - val_loss: 0.3845 - val_accuracy: 0.8519\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4682 - accuracy: 0.7897 - val_loss: 0.4120 - val_accuracy: 0.8519\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4376 - accuracy: 0.8131 - val_loss: 0.3700 - val_accuracy: 0.8519\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4151 - accuracy: 0.8318 - val_loss: 0.3519 - val_accuracy: 0.8704\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4602 - accuracy: 0.8084 - val_loss: 0.3666 - val_accuracy: 0.8704\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4310 - accuracy: 0.8084 - val_loss: 0.3633 - val_accuracy: 0.8704\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4408 - accuracy: 0.7850 - val_loss: 0.3421 - val_accuracy: 0.8704\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.8037 - val_loss: 0.3548 - val_accuracy: 0.8704\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4516 - accuracy: 0.8037 - val_loss: 0.3996 - val_accuracy: 0.8148\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4600 - accuracy: 0.7944 - val_loss: 0.3813 - val_accuracy: 0.8519\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4313 - accuracy: 0.8131 - val_loss: 0.3831 - val_accuracy: 0.8704\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4133 - accuracy: 0.8037 - val_loss: 0.3902 - val_accuracy: 0.8704\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4614 - accuracy: 0.7617 - val_loss: 0.3682 - val_accuracy: 0.8704\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4373 - accuracy: 0.8178 - val_loss: 0.3849 - val_accuracy: 0.8704\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4424 - accuracy: 0.7897 - val_loss: 0.3890 - val_accuracy: 0.8519\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4435 - accuracy: 0.8224 - val_loss: 0.3918 - val_accuracy: 0.8519\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4291 - accuracy: 0.8131 - val_loss: 0.3858 - val_accuracy: 0.8519\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3934 - accuracy: 0.8364 - val_loss: 0.3777 - val_accuracy: 0.8704\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4234 - accuracy: 0.8131 - val_loss: 0.3830 - val_accuracy: 0.8704\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4139 - accuracy: 0.8037 - val_loss: 0.3889 - val_accuracy: 0.8519\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.8131 - val_loss: 0.3703 - val_accuracy: 0.8704\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4231 - accuracy: 0.8131 - val_loss: 0.3656 - val_accuracy: 0.8704\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4242 - accuracy: 0.8178 - val_loss: 0.3739 - val_accuracy: 0.8704\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4043 - accuracy: 0.8131 - val_loss: 0.4250 - val_accuracy: 0.7963\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4507 - accuracy: 0.7897 - val_loss: 0.4200 - val_accuracy: 0.8148\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4587 - accuracy: 0.7850 - val_loss: 0.3874 - val_accuracy: 0.8704\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4215 - accuracy: 0.8271 - val_loss: 0.3814 - val_accuracy: 0.8704\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4284 - accuracy: 0.7991 - val_loss: 0.3743 - val_accuracy: 0.8704\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4078 - accuracy: 0.8318 - val_loss: 0.3728 - val_accuracy: 0.8704\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4750 - accuracy: 0.8224 - val_loss: 0.3989 - val_accuracy: 0.8704\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4453 - accuracy: 0.8131 - val_loss: 0.3844 - val_accuracy: 0.8704\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.8037 - val_loss: 0.3662 - val_accuracy: 0.8704\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4492 - accuracy: 0.8037 - val_loss: 0.4003 - val_accuracy: 0.8519\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4375 - accuracy: 0.8084 - val_loss: 0.4007 - val_accuracy: 0.8704\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4185 - accuracy: 0.8364 - val_loss: 0.3519 - val_accuracy: 0.8519\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4224 - accuracy: 0.8131 - val_loss: 0.3834 - val_accuracy: 0.8704\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4758 - accuracy: 0.7757 - val_loss: 0.4266 - val_accuracy: 0.7778\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4050 - accuracy: 0.8411 - val_loss: 0.3716 - val_accuracy: 0.8704\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4256 - accuracy: 0.8037 - val_loss: 0.3585 - val_accuracy: 0.8704\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.7944 - val_loss: 0.4248 - val_accuracy: 0.7963\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4481 - accuracy: 0.7991 - val_loss: 0.4230 - val_accuracy: 0.7963\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4036 - accuracy: 0.8178 - val_loss: 0.3612 - val_accuracy: 0.8704\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4500 - accuracy: 0.8037 - val_loss: 0.3694 - val_accuracy: 0.8704\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4113 - accuracy: 0.8318 - val_loss: 0.4152 - val_accuracy: 0.8148\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4290 - accuracy: 0.8271 - val_loss: 0.4202 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4139 - accuracy: 0.8178 - val_loss: 0.3689 - val_accuracy: 0.8704\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4196 - accuracy: 0.8178 - val_loss: 0.3667 - val_accuracy: 0.8704\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4412 - accuracy: 0.8131 - val_loss: 0.3899 - val_accuracy: 0.8704\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4296 - accuracy: 0.8037 - val_loss: 0.4106 - val_accuracy: 0.8704\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4280 - accuracy: 0.8318 - val_loss: 0.3747 - val_accuracy: 0.8704\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4105 - accuracy: 0.8131 - val_loss: 0.3810 - val_accuracy: 0.8704\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4147 - accuracy: 0.8037 - val_loss: 0.4235 - val_accuracy: 0.8704\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4035 - accuracy: 0.8318 - val_loss: 0.4246 - val_accuracy: 0.8704\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3956 - accuracy: 0.8224 - val_loss: 0.3830 - val_accuracy: 0.8704\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4341 - accuracy: 0.7850 - val_loss: 0.3655 - val_accuracy: 0.8704\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4125 - accuracy: 0.8271 - val_loss: 0.4605 - val_accuracy: 0.7963\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4404 - accuracy: 0.8131 - val_loss: 0.3994 - val_accuracy: 0.8704\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4440 - accuracy: 0.7991 - val_loss: 0.3622 - val_accuracy: 0.8704\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4256 - accuracy: 0.8458 - val_loss: 0.3775 - val_accuracy: 0.8704\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4278 - accuracy: 0.8037 - val_loss: 0.4797 - val_accuracy: 0.7963\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4816 - accuracy: 0.7617 - val_loss: 0.3975 - val_accuracy: 0.8704\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3861 - accuracy: 0.8458 - val_loss: 0.3762 - val_accuracy: 0.8704\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.8037 - val_loss: 0.3941 - val_accuracy: 0.8704\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4103 - accuracy: 0.7991 - val_loss: 0.4382 - val_accuracy: 0.7963\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4369 - accuracy: 0.7757 - val_loss: 0.3877 - val_accuracy: 0.8704\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4333 - accuracy: 0.8224 - val_loss: 0.3626 - val_accuracy: 0.8519\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3853 - accuracy: 0.8318 - val_loss: 0.3945 - val_accuracy: 0.8519\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4361 - accuracy: 0.7991 - val_loss: 0.3908 - val_accuracy: 0.8519\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4240 - accuracy: 0.8364 - val_loss: 0.3616 - val_accuracy: 0.8704\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4268 - accuracy: 0.8131 - val_loss: 0.3977 - val_accuracy: 0.8704\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4053 - accuracy: 0.8271 - val_loss: 0.3733 - val_accuracy: 0.8704\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4053 - accuracy: 0.8131 - val_loss: 0.3949 - val_accuracy: 0.8704\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3997 - accuracy: 0.8131 - val_loss: 0.4210 - val_accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4067 - accuracy: 0.8318 - val_loss: 0.4125 - val_accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.8178 - val_loss: 0.3822 - val_accuracy: 0.8704\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.8271 - val_loss: 0.3686 - val_accuracy: 0.8704\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4297 - accuracy: 0.8084 - val_loss: 0.3857 - val_accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4194 - accuracy: 0.7991 - val_loss: 0.4503 - val_accuracy: 0.7778\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.7944 - val_loss: 0.4116 - val_accuracy: 0.8704\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4028 - accuracy: 0.7991 - val_loss: 0.3729 - val_accuracy: 0.8519\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4372 - accuracy: 0.8037 - val_loss: 0.3844 - val_accuracy: 0.8704\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4343 - accuracy: 0.7991 - val_loss: 0.4438 - val_accuracy: 0.7778\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4242 - accuracy: 0.8318 - val_loss: 0.4010 - val_accuracy: 0.8704\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.7804 - val_loss: 0.3523 - val_accuracy: 0.8704\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4322 - accuracy: 0.7897 - val_loss: 0.4109 - val_accuracy: 0.8704\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4327 - accuracy: 0.8084 - val_loss: 0.3999 - val_accuracy: 0.8704\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4217 - accuracy: 0.7991 - val_loss: 0.3808 - val_accuracy: 0.8704\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4100 - accuracy: 0.8318 - val_loss: 0.3912 - val_accuracy: 0.8704\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4166 - accuracy: 0.8224 - val_loss: 0.3813 - val_accuracy: 0.8704\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.8364 - val_loss: 0.3672 - val_accuracy: 0.8704\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4329 - accuracy: 0.7991 - val_loss: 0.3909 - val_accuracy: 0.8519\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4113 - accuracy: 0.8271 - val_loss: 0.4092 - val_accuracy: 0.8148\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.8224 - val_loss: 0.4094 - val_accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4126 - accuracy: 0.7944 - val_loss: 0.3814 - val_accuracy: 0.8704\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3963 - accuracy: 0.8364 - val_loss: 0.3966 - val_accuracy: 0.8704\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4268 - accuracy: 0.8271 - val_loss: 0.4320 - val_accuracy: 0.8148\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4016 - accuracy: 0.8084 - val_loss: 0.3579 - val_accuracy: 0.8704\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4299 - accuracy: 0.8318 - val_loss: 0.3569 - val_accuracy: 0.8704\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4055 - accuracy: 0.7944 - val_loss: 0.3841 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4071 - accuracy: 0.8178 - val_loss: 0.4056 - val_accuracy: 0.8148\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4292 - accuracy: 0.8131 - val_loss: 0.4011 - val_accuracy: 0.8704\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4351 - accuracy: 0.8084 - val_loss: 0.4017 - val_accuracy: 0.8704\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4178 - accuracy: 0.8037 - val_loss: 0.4021 - val_accuracy: 0.8704\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.8131 - val_loss: 0.4050 - val_accuracy: 0.8704\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.8318 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3739 - accuracy: 0.8364 - val_loss: 0.3811 - val_accuracy: 0.8704\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3856 - accuracy: 0.8364 - val_loss: 0.4067 - val_accuracy: 0.8704\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4029 - accuracy: 0.8318 - val_loss: 0.4302 - val_accuracy: 0.8148\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4073 - accuracy: 0.8318 - val_loss: 0.4096 - val_accuracy: 0.8704\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3789 - accuracy: 0.8364 - val_loss: 0.4038 - val_accuracy: 0.8704\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3626 - accuracy: 0.8411 - val_loss: 0.4103 - val_accuracy: 0.8333\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4270 - accuracy: 0.8131 - val_loss: 0.4508 - val_accuracy: 0.8148\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3984 - accuracy: 0.8224 - val_loss: 0.3978 - val_accuracy: 0.8704\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3845 - accuracy: 0.8364 - val_loss: 0.4071 - val_accuracy: 0.8704\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4045 - accuracy: 0.8458 - val_loss: 0.4446 - val_accuracy: 0.8519\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8224 - val_loss: 0.4376 - val_accuracy: 0.8148\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4000 - accuracy: 0.8458 - val_loss: 0.4056 - val_accuracy: 0.8704\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4183 - accuracy: 0.8131 - val_loss: 0.4009 - val_accuracy: 0.8704\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3701 - accuracy: 0.8458 - val_loss: 0.4256 - val_accuracy: 0.8704\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B95416CF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.6831 - accuracy: 0.5467 - val_loss: 0.6022 - val_accuracy: 0.5370\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6071 - accuracy: 0.6636 - val_loss: 0.5453 - val_accuracy: 0.8333\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5871 - accuracy: 0.6776 - val_loss: 0.5046 - val_accuracy: 0.8333\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5192 - accuracy: 0.7897 - val_loss: 0.4783 - val_accuracy: 0.8148\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5064 - accuracy: 0.7430 - val_loss: 0.4644 - val_accuracy: 0.7778\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5132 - accuracy: 0.7804 - val_loss: 0.4427 - val_accuracy: 0.8148\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4971 - accuracy: 0.7804 - val_loss: 0.4309 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4945 - accuracy: 0.7710 - val_loss: 0.4400 - val_accuracy: 0.8148\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4821 - accuracy: 0.7850 - val_loss: 0.4660 - val_accuracy: 0.7593\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4590 - accuracy: 0.8131 - val_loss: 0.4340 - val_accuracy: 0.8333\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.7757 - val_loss: 0.4460 - val_accuracy: 0.8148\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.7991 - val_loss: 0.4532 - val_accuracy: 0.7963\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4322 - accuracy: 0.8131 - val_loss: 0.4383 - val_accuracy: 0.8148\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4447 - accuracy: 0.7944 - val_loss: 0.4435 - val_accuracy: 0.8148\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4739 - accuracy: 0.7850 - val_loss: 0.4378 - val_accuracy: 0.8148\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4607 - accuracy: 0.7757 - val_loss: 0.4338 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4508 - accuracy: 0.7897 - val_loss: 0.4334 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4593 - accuracy: 0.7757 - val_loss: 0.4317 - val_accuracy: 0.8148\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4509 - accuracy: 0.8178 - val_loss: 0.4349 - val_accuracy: 0.8148\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4584 - accuracy: 0.7944 - val_loss: 0.4531 - val_accuracy: 0.8148\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4368 - accuracy: 0.7757 - val_loss: 0.4547 - val_accuracy: 0.7963\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4381 - accuracy: 0.7897 - val_loss: 0.4472 - val_accuracy: 0.8148\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4554 - accuracy: 0.8084 - val_loss: 0.4554 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4556 - accuracy: 0.8131 - val_loss: 0.4624 - val_accuracy: 0.8148\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4891 - accuracy: 0.7991 - val_loss: 0.4688 - val_accuracy: 0.8148\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4711 - accuracy: 0.7710 - val_loss: 0.4761 - val_accuracy: 0.8148\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4274 - accuracy: 0.8178 - val_loss: 0.4842 - val_accuracy: 0.8333\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4775 - accuracy: 0.8178 - val_loss: 0.4839 - val_accuracy: 0.8148\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4638 - accuracy: 0.7850 - val_loss: 0.4870 - val_accuracy: 0.8148\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4201 - accuracy: 0.7944 - val_loss: 0.4838 - val_accuracy: 0.8148\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4520 - accuracy: 0.7944 - val_loss: 0.4815 - val_accuracy: 0.8148\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4587 - accuracy: 0.7850 - val_loss: 0.4800 - val_accuracy: 0.8519\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4298 - accuracy: 0.8131 - val_loss: 0.4758 - val_accuracy: 0.8148\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.7944 - val_loss: 0.4827 - val_accuracy: 0.8148\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4355 - accuracy: 0.8084 - val_loss: 0.4936 - val_accuracy: 0.8148\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4571 - accuracy: 0.8037 - val_loss: 0.5115 - val_accuracy: 0.8148\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4297 - accuracy: 0.8224 - val_loss: 0.4945 - val_accuracy: 0.8148\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4322 - accuracy: 0.8084 - val_loss: 0.4748 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4524 - accuracy: 0.8271 - val_loss: 0.4928 - val_accuracy: 0.8519\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4547 - accuracy: 0.7804 - val_loss: 0.5239 - val_accuracy: 0.7778\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4494 - accuracy: 0.7710 - val_loss: 0.5041 - val_accuracy: 0.8148\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4604 - accuracy: 0.7991 - val_loss: 0.5008 - val_accuracy: 0.8148\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4469 - accuracy: 0.8037 - val_loss: 0.5071 - val_accuracy: 0.8148\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4537 - accuracy: 0.8084 - val_loss: 0.5055 - val_accuracy: 0.8148\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4165 - accuracy: 0.8084 - val_loss: 0.4998 - val_accuracy: 0.8333\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4233 - accuracy: 0.8037 - val_loss: 0.4974 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4164 - accuracy: 0.7897 - val_loss: 0.5045 - val_accuracy: 0.8148\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4157 - accuracy: 0.7991 - val_loss: 0.4956 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4307 - accuracy: 0.8037 - val_loss: 0.5110 - val_accuracy: 0.8148\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4299 - accuracy: 0.7944 - val_loss: 0.5072 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4006 - accuracy: 0.8458 - val_loss: 0.5006 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.7944 - val_loss: 0.5077 - val_accuracy: 0.8519\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4259 - accuracy: 0.8224 - val_loss: 0.5039 - val_accuracy: 0.8519\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.7897 - val_loss: 0.5127 - val_accuracy: 0.8333\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4202 - accuracy: 0.8037 - val_loss: 0.5175 - val_accuracy: 0.8519\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4293 - accuracy: 0.8084 - val_loss: 0.5293 - val_accuracy: 0.8519\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.7991 - val_loss: 0.5343 - val_accuracy: 0.8148\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4167 - accuracy: 0.8178 - val_loss: 0.5275 - val_accuracy: 0.8148\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4213 - accuracy: 0.8037 - val_loss: 0.5370 - val_accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4345 - accuracy: 0.8271 - val_loss: 0.5326 - val_accuracy: 0.8519\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3958 - accuracy: 0.8131 - val_loss: 0.5582 - val_accuracy: 0.8148\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4212 - accuracy: 0.8178 - val_loss: 0.5650 - val_accuracy: 0.8148\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4310 - accuracy: 0.8084 - val_loss: 0.5483 - val_accuracy: 0.8519\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4289 - accuracy: 0.8364 - val_loss: 0.5445 - val_accuracy: 0.8519\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8131 - val_loss: 0.5474 - val_accuracy: 0.8148\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3965 - accuracy: 0.8131 - val_loss: 0.5476 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4301 - accuracy: 0.7850 - val_loss: 0.5510 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4225 - accuracy: 0.7850 - val_loss: 0.5642 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4315 - accuracy: 0.8084 - val_loss: 0.5593 - val_accuracy: 0.8148\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4325 - accuracy: 0.8131 - val_loss: 0.5674 - val_accuracy: 0.8148\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4141 - accuracy: 0.8364 - val_loss: 0.5660 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3982 - accuracy: 0.8224 - val_loss: 0.5875 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4240 - accuracy: 0.7944 - val_loss: 0.5712 - val_accuracy: 0.7963\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4230 - accuracy: 0.8037 - val_loss: 0.5753 - val_accuracy: 0.7963\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4091 - accuracy: 0.7991 - val_loss: 0.5869 - val_accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4249 - accuracy: 0.7991 - val_loss: 0.5885 - val_accuracy: 0.8519\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4206 - accuracy: 0.8037 - val_loss: 0.5789 - val_accuracy: 0.8148\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.8224 - val_loss: 0.5897 - val_accuracy: 0.8148\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4002 - accuracy: 0.8131 - val_loss: 0.5871 - val_accuracy: 0.8148\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4444 - accuracy: 0.7991 - val_loss: 0.6020 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.8037 - val_loss: 0.5959 - val_accuracy: 0.8148\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4200 - accuracy: 0.8318 - val_loss: 0.6018 - val_accuracy: 0.8148\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4202 - accuracy: 0.7944 - val_loss: 0.6099 - val_accuracy: 0.7963\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4156 - accuracy: 0.7944 - val_loss: 0.6084 - val_accuracy: 0.7963\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4125 - accuracy: 0.8131 - val_loss: 0.5968 - val_accuracy: 0.8148\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4037 - accuracy: 0.7804 - val_loss: 0.6047 - val_accuracy: 0.8519\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4133 - accuracy: 0.8318 - val_loss: 0.6100 - val_accuracy: 0.7963\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8178 - val_loss: 0.6031 - val_accuracy: 0.7963\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4059 - accuracy: 0.8084 - val_loss: 0.6046 - val_accuracy: 0.8148\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4003 - accuracy: 0.8224 - val_loss: 0.6008 - val_accuracy: 0.8148\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3771 - accuracy: 0.8084 - val_loss: 0.6028 - val_accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4238 - accuracy: 0.8318 - val_loss: 0.6203 - val_accuracy: 0.8148\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3998 - accuracy: 0.8271 - val_loss: 0.6095 - val_accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3905 - accuracy: 0.8178 - val_loss: 0.6228 - val_accuracy: 0.7963\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4141 - accuracy: 0.8131 - val_loss: 0.6141 - val_accuracy: 0.8148\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.8084 - val_loss: 0.6419 - val_accuracy: 0.8148\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4279 - accuracy: 0.7897 - val_loss: 0.6164 - val_accuracy: 0.7963\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.8178 - val_loss: 0.6122 - val_accuracy: 0.7963\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4202 - accuracy: 0.8084 - val_loss: 0.6230 - val_accuracy: 0.8148\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4283 - accuracy: 0.7944 - val_loss: 0.6280 - val_accuracy: 0.8148\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3881 - accuracy: 0.8131 - val_loss: 0.6316 - val_accuracy: 0.7963\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.7991 - val_loss: 0.6352 - val_accuracy: 0.7963\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4238 - accuracy: 0.8084 - val_loss: 0.6337 - val_accuracy: 0.8519\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3906 - accuracy: 0.8458 - val_loss: 0.6389 - val_accuracy: 0.8148\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3765 - accuracy: 0.8318 - val_loss: 0.6403 - val_accuracy: 0.7963\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3993 - accuracy: 0.8224 - val_loss: 0.6368 - val_accuracy: 0.7963\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3891 - accuracy: 0.8458 - val_loss: 0.6458 - val_accuracy: 0.8148\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3635 - accuracy: 0.8224 - val_loss: 0.6476 - val_accuracy: 0.7963\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3766 - accuracy: 0.8224 - val_loss: 0.6489 - val_accuracy: 0.8148\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3991 - accuracy: 0.8178 - val_loss: 0.6469 - val_accuracy: 0.7963\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4308 - accuracy: 0.8084 - val_loss: 0.6720 - val_accuracy: 0.7593\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4072 - accuracy: 0.8131 - val_loss: 0.6572 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4113 - accuracy: 0.8271 - val_loss: 0.7048 - val_accuracy: 0.8148\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4692 - accuracy: 0.7897 - val_loss: 0.6514 - val_accuracy: 0.7963\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4142 - accuracy: 0.8318 - val_loss: 0.6530 - val_accuracy: 0.7963\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.8037 - val_loss: 0.6525 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3997 - accuracy: 0.8224 - val_loss: 0.6425 - val_accuracy: 0.8148\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4081 - accuracy: 0.7991 - val_loss: 0.6461 - val_accuracy: 0.7963\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4044 - accuracy: 0.8131 - val_loss: 0.6503 - val_accuracy: 0.7963\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3709 - accuracy: 0.8271 - val_loss: 0.6428 - val_accuracy: 0.8148\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3767 - accuracy: 0.8224 - val_loss: 0.6429 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3537 - accuracy: 0.8411 - val_loss: 0.6656 - val_accuracy: 0.7963\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4482 - accuracy: 0.8131 - val_loss: 0.6603 - val_accuracy: 0.7963\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3908 - accuracy: 0.8084 - val_loss: 0.6655 - val_accuracy: 0.7963\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3686 - accuracy: 0.8364 - val_loss: 0.6699 - val_accuracy: 0.8148\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3840 - accuracy: 0.8364 - val_loss: 0.6799 - val_accuracy: 0.7963\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8364 - val_loss: 0.6801 - val_accuracy: 0.7963\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4118 - accuracy: 0.8084 - val_loss: 0.6857 - val_accuracy: 0.7963\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3837 - accuracy: 0.8224 - val_loss: 0.6986 - val_accuracy: 0.7963\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3848 - accuracy: 0.8084 - val_loss: 0.7013 - val_accuracy: 0.7963\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3931 - accuracy: 0.8505 - val_loss: 0.7146 - val_accuracy: 0.7963\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4332 - accuracy: 0.7897 - val_loss: 0.7350 - val_accuracy: 0.7963\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3880 - accuracy: 0.8178 - val_loss: 0.7457 - val_accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4168 - accuracy: 0.7944 - val_loss: 0.7191 - val_accuracy: 0.7778\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4252 - accuracy: 0.7850 - val_loss: 0.6662 - val_accuracy: 0.8148\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8178 - val_loss: 0.6705 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4026 - accuracy: 0.8178 - val_loss: 0.6860 - val_accuracy: 0.7963\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3994 - accuracy: 0.8318 - val_loss: 0.6967 - val_accuracy: 0.7778\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3977 - accuracy: 0.8178 - val_loss: 0.7043 - val_accuracy: 0.7963\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3825 - accuracy: 0.8224 - val_loss: 0.7219 - val_accuracy: 0.8148\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.8318 - val_loss: 0.7327 - val_accuracy: 0.7778\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4170 - accuracy: 0.8178 - val_loss: 0.7000 - val_accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.8318 - val_loss: 0.6972 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.7850 - val_loss: 0.7066 - val_accuracy: 0.7778\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4157 - accuracy: 0.8131 - val_loss: 0.6892 - val_accuracy: 0.7778\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4092 - accuracy: 0.7944 - val_loss: 0.6671 - val_accuracy: 0.8148\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3580 - accuracy: 0.8505 - val_loss: 0.6604 - val_accuracy: 0.8519\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3929 - accuracy: 0.8131 - val_loss: 0.6605 - val_accuracy: 0.8148\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.8131 - val_loss: 0.6679 - val_accuracy: 0.7963\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.8131 - val_loss: 0.6690 - val_accuracy: 0.8148\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.7944 - val_loss: 0.6794 - val_accuracy: 0.8148\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8131 - val_loss: 0.6939 - val_accuracy: 0.8148\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4134 - accuracy: 0.7991 - val_loss: 0.7034 - val_accuracy: 0.7963\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8505 - val_loss: 0.7192 - val_accuracy: 0.7778\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3979 - accuracy: 0.8084 - val_loss: 0.7270 - val_accuracy: 0.7963\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3657 - accuracy: 0.8271 - val_loss: 0.7147 - val_accuracy: 0.8148\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3831 - accuracy: 0.8551 - val_loss: 0.6900 - val_accuracy: 0.8148\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3808 - accuracy: 0.8224 - val_loss: 0.6918 - val_accuracy: 0.8148\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8411 - val_loss: 0.6986 - val_accuracy: 0.8148\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3691 - accuracy: 0.8458 - val_loss: 0.6943 - val_accuracy: 0.8148\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3976 - accuracy: 0.8271 - val_loss: 0.7164 - val_accuracy: 0.8148\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3856 - accuracy: 0.8318 - val_loss: 0.7154 - val_accuracy: 0.7963\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3751 - accuracy: 0.8271 - val_loss: 0.7080 - val_accuracy: 0.7593\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3669 - accuracy: 0.8084 - val_loss: 0.6987 - val_accuracy: 0.7963\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.8131 - val_loss: 0.6883 - val_accuracy: 0.7593\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3957 - accuracy: 0.8084 - val_loss: 0.6892 - val_accuracy: 0.7963\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3903 - accuracy: 0.8458 - val_loss: 0.6795 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.8364 - val_loss: 0.6723 - val_accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3950 - accuracy: 0.8178 - val_loss: 0.6785 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3691 - accuracy: 0.8178 - val_loss: 0.6803 - val_accuracy: 0.8148\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3394 - accuracy: 0.8224 - val_loss: 0.6979 - val_accuracy: 0.8148\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.8271 - val_loss: 0.7112 - val_accuracy: 0.8148\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3928 - accuracy: 0.8318 - val_loss: 0.7069 - val_accuracy: 0.8148\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.8551 - val_loss: 0.7065 - val_accuracy: 0.7593\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4122 - accuracy: 0.8178 - val_loss: 0.7018 - val_accuracy: 0.7963\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8411 - val_loss: 0.7160 - val_accuracy: 0.7963\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.8271 - val_loss: 0.7064 - val_accuracy: 0.7593\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3898 - accuracy: 0.8224 - val_loss: 0.6992 - val_accuracy: 0.8148\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3460 - accuracy: 0.8458 - val_loss: 0.7019 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3616 - accuracy: 0.8551 - val_loss: 0.6907 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3628 - accuracy: 0.8505 - val_loss: 0.7072 - val_accuracy: 0.8148\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3934 - accuracy: 0.7944 - val_loss: 0.7218 - val_accuracy: 0.8148\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3739 - accuracy: 0.8505 - val_loss: 0.7051 - val_accuracy: 0.7963\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.8551 - val_loss: 0.6808 - val_accuracy: 0.8333\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8318 - val_loss: 0.6692 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3806 - accuracy: 0.8084 - val_loss: 0.6747 - val_accuracy: 0.7963\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.7991 - val_loss: 0.6661 - val_accuracy: 0.7963\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8411 - val_loss: 0.6763 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3500 - accuracy: 0.8224 - val_loss: 0.6674 - val_accuracy: 0.8333\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3316 - accuracy: 0.8458 - val_loss: 0.6693 - val_accuracy: 0.8148\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3590 - accuracy: 0.8411 - val_loss: 0.6713 - val_accuracy: 0.8148\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3671 - accuracy: 0.8364 - val_loss: 0.6939 - val_accuracy: 0.8148\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3813 - accuracy: 0.8224 - val_loss: 0.6889 - val_accuracy: 0.8333\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4037 - accuracy: 0.8037 - val_loss: 0.7096 - val_accuracy: 0.7963\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8131 - val_loss: 0.7103 - val_accuracy: 0.8148\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3979 - accuracy: 0.8318 - val_loss: 0.7137 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3814 - accuracy: 0.8084 - val_loss: 0.7065 - val_accuracy: 0.7963\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3606 - accuracy: 0.8318 - val_loss: 0.7120 - val_accuracy: 0.7963\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4017 - accuracy: 0.7944 - val_loss: 0.7316 - val_accuracy: 0.8148\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3795 - accuracy: 0.8084 - val_loss: 0.7393 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B75C93BB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.6464 - accuracy: 0.6355 - val_loss: 0.5649 - val_accuracy: 0.7778\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6214 - accuracy: 0.6402 - val_loss: 0.5237 - val_accuracy: 0.7963\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5593 - accuracy: 0.7243 - val_loss: 0.4730 - val_accuracy: 0.7963\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5507 - accuracy: 0.7336 - val_loss: 0.4453 - val_accuracy: 0.7963\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5028 - accuracy: 0.7850 - val_loss: 0.4211 - val_accuracy: 0.7963\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4618 - accuracy: 0.8131 - val_loss: 0.4133 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4987 - accuracy: 0.7944 - val_loss: 0.4193 - val_accuracy: 0.7963\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4946 - accuracy: 0.7897 - val_loss: 0.4225 - val_accuracy: 0.7963\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4689 - accuracy: 0.7850 - val_loss: 0.4120 - val_accuracy: 0.8148\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4470 - accuracy: 0.8224 - val_loss: 0.3986 - val_accuracy: 0.7963\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4743 - accuracy: 0.7991 - val_loss: 0.4058 - val_accuracy: 0.7963\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.8271 - val_loss: 0.4033 - val_accuracy: 0.7963\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4333 - accuracy: 0.8318 - val_loss: 0.4126 - val_accuracy: 0.8148\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4803 - accuracy: 0.7944 - val_loss: 0.4060 - val_accuracy: 0.7963\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.8271 - val_loss: 0.4078 - val_accuracy: 0.8148\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4179 - accuracy: 0.7897 - val_loss: 0.4109 - val_accuracy: 0.7963\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4324 - accuracy: 0.8131 - val_loss: 0.4170 - val_accuracy: 0.8148\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4857 - accuracy: 0.7710 - val_loss: 0.4065 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4588 - accuracy: 0.7991 - val_loss: 0.4036 - val_accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4627 - accuracy: 0.7757 - val_loss: 0.4189 - val_accuracy: 0.8148\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4521 - accuracy: 0.7897 - val_loss: 0.4068 - val_accuracy: 0.8148\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4801 - accuracy: 0.8037 - val_loss: 0.4215 - val_accuracy: 0.8148\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4593 - accuracy: 0.8084 - val_loss: 0.4140 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4646 - accuracy: 0.8084 - val_loss: 0.4223 - val_accuracy: 0.7963\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4747 - accuracy: 0.7944 - val_loss: 0.4195 - val_accuracy: 0.8148\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4719 - accuracy: 0.7850 - val_loss: 0.4101 - val_accuracy: 0.7963\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4606 - accuracy: 0.8037 - val_loss: 0.4118 - val_accuracy: 0.8148\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4523 - accuracy: 0.8037 - val_loss: 0.4061 - val_accuracy: 0.7963\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4738 - accuracy: 0.8037 - val_loss: 0.4025 - val_accuracy: 0.8148\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4708 - accuracy: 0.8037 - val_loss: 0.4067 - val_accuracy: 0.8148\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4428 - accuracy: 0.7897 - val_loss: 0.4148 - val_accuracy: 0.7963\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4589 - accuracy: 0.7944 - val_loss: 0.4063 - val_accuracy: 0.7963\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4615 - accuracy: 0.7897 - val_loss: 0.3986 - val_accuracy: 0.7963\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4682 - accuracy: 0.7710 - val_loss: 0.4015 - val_accuracy: 0.7963\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4150 - accuracy: 0.8224 - val_loss: 0.4047 - val_accuracy: 0.7963\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4251 - accuracy: 0.8037 - val_loss: 0.3987 - val_accuracy: 0.7963\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4588 - accuracy: 0.7944 - val_loss: 0.3999 - val_accuracy: 0.8148\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.8084 - val_loss: 0.4023 - val_accuracy: 0.7963\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4342 - accuracy: 0.7991 - val_loss: 0.4117 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4497 - accuracy: 0.8037 - val_loss: 0.4093 - val_accuracy: 0.8148\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4670 - accuracy: 0.7897 - val_loss: 0.4151 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4814 - accuracy: 0.7850 - val_loss: 0.4157 - val_accuracy: 0.7963\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4636 - accuracy: 0.7897 - val_loss: 0.4063 - val_accuracy: 0.7963\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4388 - accuracy: 0.7850 - val_loss: 0.4150 - val_accuracy: 0.7963\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.7710 - val_loss: 0.4283 - val_accuracy: 0.7963\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4468 - accuracy: 0.7897 - val_loss: 0.4124 - val_accuracy: 0.7963\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4359 - accuracy: 0.8178 - val_loss: 0.4053 - val_accuracy: 0.8148\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4767 - accuracy: 0.7944 - val_loss: 0.4201 - val_accuracy: 0.7963\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4350 - accuracy: 0.7944 - val_loss: 0.4126 - val_accuracy: 0.7778\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4383 - accuracy: 0.8178 - val_loss: 0.4094 - val_accuracy: 0.7963\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.8037 - val_loss: 0.4101 - val_accuracy: 0.7963\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4320 - accuracy: 0.7850 - val_loss: 0.4092 - val_accuracy: 0.7963\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4418 - accuracy: 0.7991 - val_loss: 0.4096 - val_accuracy: 0.7963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4506 - accuracy: 0.8037 - val_loss: 0.4107 - val_accuracy: 0.7963\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3972 - accuracy: 0.8084 - val_loss: 0.4135 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4346 - accuracy: 0.7991 - val_loss: 0.4188 - val_accuracy: 0.8148\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4425 - accuracy: 0.7757 - val_loss: 0.4232 - val_accuracy: 0.7963\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4219 - accuracy: 0.8224 - val_loss: 0.4262 - val_accuracy: 0.7963\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.8037 - val_loss: 0.4244 - val_accuracy: 0.7963\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.8178 - val_loss: 0.4258 - val_accuracy: 0.7963\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4326 - accuracy: 0.8224 - val_loss: 0.4237 - val_accuracy: 0.8148\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4234 - accuracy: 0.8224 - val_loss: 0.4241 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4527 - accuracy: 0.7991 - val_loss: 0.4259 - val_accuracy: 0.7778\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.8178 - val_loss: 0.4409 - val_accuracy: 0.8148\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4685 - accuracy: 0.7850 - val_loss: 0.4372 - val_accuracy: 0.7778\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4068 - accuracy: 0.8224 - val_loss: 0.4274 - val_accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4372 - accuracy: 0.7991 - val_loss: 0.4248 - val_accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4287 - accuracy: 0.8084 - val_loss: 0.4298 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4464 - accuracy: 0.8271 - val_loss: 0.4281 - val_accuracy: 0.7963\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4389 - accuracy: 0.7991 - val_loss: 0.4280 - val_accuracy: 0.7963\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4237 - accuracy: 0.8084 - val_loss: 0.4460 - val_accuracy: 0.7963\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4762 - accuracy: 0.7850 - val_loss: 0.4395 - val_accuracy: 0.7778\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4594 - accuracy: 0.7710 - val_loss: 0.4619 - val_accuracy: 0.7963\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4765 - accuracy: 0.7850 - val_loss: 0.4407 - val_accuracy: 0.7963\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.7944 - val_loss: 0.4381 - val_accuracy: 0.8148\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4616 - accuracy: 0.7897 - val_loss: 0.4347 - val_accuracy: 0.8148\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4386 - accuracy: 0.7804 - val_loss: 0.4365 - val_accuracy: 0.8148\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4551 - accuracy: 0.7991 - val_loss: 0.4395 - val_accuracy: 0.7778\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4376 - accuracy: 0.7804 - val_loss: 0.4420 - val_accuracy: 0.7963\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4193 - accuracy: 0.8131 - val_loss: 0.4367 - val_accuracy: 0.8148\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4158 - accuracy: 0.8037 - val_loss: 0.4350 - val_accuracy: 0.7963\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4197 - accuracy: 0.7757 - val_loss: 0.4337 - val_accuracy: 0.7963\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4396 - accuracy: 0.7664 - val_loss: 0.4365 - val_accuracy: 0.7963\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.8178 - val_loss: 0.4457 - val_accuracy: 0.7963\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4321 - accuracy: 0.7991 - val_loss: 0.4737 - val_accuracy: 0.7963\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4172 - accuracy: 0.8131 - val_loss: 0.4562 - val_accuracy: 0.7963\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4475 - accuracy: 0.7944 - val_loss: 0.4694 - val_accuracy: 0.8148\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4341 - accuracy: 0.7897 - val_loss: 0.4650 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4217 - accuracy: 0.8271 - val_loss: 0.4674 - val_accuracy: 0.8148\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4666 - accuracy: 0.7804 - val_loss: 0.4658 - val_accuracy: 0.7963\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4196 - accuracy: 0.8084 - val_loss: 0.4602 - val_accuracy: 0.7963\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4045 - accuracy: 0.8131 - val_loss: 0.4554 - val_accuracy: 0.7963\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.7897 - val_loss: 0.4561 - val_accuracy: 0.7963\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.7944 - val_loss: 0.4608 - val_accuracy: 0.7778\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.7897 - val_loss: 0.4603 - val_accuracy: 0.7963\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3941 - accuracy: 0.8178 - val_loss: 0.4594 - val_accuracy: 0.7963\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3978 - accuracy: 0.8411 - val_loss: 0.4578 - val_accuracy: 0.7778\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4342 - accuracy: 0.7944 - val_loss: 0.4610 - val_accuracy: 0.8148\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3971 - accuracy: 0.8084 - val_loss: 0.4700 - val_accuracy: 0.7407\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4237 - accuracy: 0.7804 - val_loss: 0.4767 - val_accuracy: 0.7963\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3996 - accuracy: 0.8271 - val_loss: 0.4814 - val_accuracy: 0.8148\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4282 - accuracy: 0.8084 - val_loss: 0.4893 - val_accuracy: 0.7963\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4187 - accuracy: 0.8084 - val_loss: 0.4848 - val_accuracy: 0.8148\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4087 - accuracy: 0.8411 - val_loss: 0.4788 - val_accuracy: 0.8148\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4150 - accuracy: 0.8178 - val_loss: 0.4807 - val_accuracy: 0.8148\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4124 - accuracy: 0.8084 - val_loss: 0.4763 - val_accuracy: 0.8148\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4141 - accuracy: 0.8037 - val_loss: 0.4767 - val_accuracy: 0.7778\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4260 - accuracy: 0.8084 - val_loss: 0.4865 - val_accuracy: 0.7963\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4404 - accuracy: 0.7850 - val_loss: 0.4950 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3830 - accuracy: 0.8364 - val_loss: 0.4997 - val_accuracy: 0.7778\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4321 - accuracy: 0.7991 - val_loss: 0.4905 - val_accuracy: 0.7778\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4432 - accuracy: 0.8037 - val_loss: 0.5002 - val_accuracy: 0.8148\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3997 - accuracy: 0.8271 - val_loss: 0.4987 - val_accuracy: 0.8148\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3830 - accuracy: 0.8364 - val_loss: 0.5072 - val_accuracy: 0.7593\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4124 - accuracy: 0.8364 - val_loss: 0.5079 - val_accuracy: 0.7963\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.85 - 0s 14ms/step - loss: 0.3832 - accuracy: 0.8318 - val_loss: 0.5152 - val_accuracy: 0.7593\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4270 - accuracy: 0.8037 - val_loss: 0.5310 - val_accuracy: 0.7407\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4000 - accuracy: 0.8178 - val_loss: 0.5184 - val_accuracy: 0.7778\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3866 - accuracy: 0.8364 - val_loss: 0.4986 - val_accuracy: 0.7963\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4459 - accuracy: 0.8178 - val_loss: 0.4968 - val_accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4149 - accuracy: 0.8131 - val_loss: 0.5034 - val_accuracy: 0.7778\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4265 - accuracy: 0.8084 - val_loss: 0.5080 - val_accuracy: 0.7778\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3939 - accuracy: 0.8411 - val_loss: 0.4966 - val_accuracy: 0.8148\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3874 - accuracy: 0.7991 - val_loss: 0.4984 - val_accuracy: 0.7778\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3668 - accuracy: 0.8364 - val_loss: 0.5068 - val_accuracy: 0.7963\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3937 - accuracy: 0.8364 - val_loss: 0.5083 - val_accuracy: 0.7778\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3810 - accuracy: 0.8318 - val_loss: 0.5143 - val_accuracy: 0.8148\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3964 - accuracy: 0.8224 - val_loss: 0.5191 - val_accuracy: 0.7407\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4176 - accuracy: 0.8037 - val_loss: 0.5207 - val_accuracy: 0.7593\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3958 - accuracy: 0.7991 - val_loss: 0.5320 - val_accuracy: 0.8148\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4030 - accuracy: 0.8224 - val_loss: 0.5147 - val_accuracy: 0.7963\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3970 - accuracy: 0.8224 - val_loss: 0.5498 - val_accuracy: 0.7778\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3801 - accuracy: 0.8318 - val_loss: 0.5382 - val_accuracy: 0.7963\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4128 - accuracy: 0.8131 - val_loss: 0.5594 - val_accuracy: 0.7407\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3672 - accuracy: 0.8364 - val_loss: 0.5383 - val_accuracy: 0.7407\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.8271 - val_loss: 0.5307 - val_accuracy: 0.7963\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3737 - accuracy: 0.8224 - val_loss: 0.5204 - val_accuracy: 0.8148\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4125 - accuracy: 0.8178 - val_loss: 0.5278 - val_accuracy: 0.7778\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4073 - accuracy: 0.8411 - val_loss: 0.5248 - val_accuracy: 0.7963\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3895 - accuracy: 0.8411 - val_loss: 0.5235 - val_accuracy: 0.7963\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3855 - accuracy: 0.8364 - val_loss: 0.5274 - val_accuracy: 0.7963\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4080 - accuracy: 0.8271 - val_loss: 0.5263 - val_accuracy: 0.7963\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3997 - accuracy: 0.8224 - val_loss: 0.5313 - val_accuracy: 0.7963\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3891 - accuracy: 0.8224 - val_loss: 0.5320 - val_accuracy: 0.7593\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4253 - accuracy: 0.8131 - val_loss: 0.5361 - val_accuracy: 0.7963\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4020 - accuracy: 0.8364 - val_loss: 0.5326 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3985 - accuracy: 0.8084 - val_loss: 0.5221 - val_accuracy: 0.8148\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4096 - accuracy: 0.8224 - val_loss: 0.5240 - val_accuracy: 0.8148\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4299 - accuracy: 0.8084 - val_loss: 0.5217 - val_accuracy: 0.7963\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4056 - accuracy: 0.7991 - val_loss: 0.5176 - val_accuracy: 0.7778\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3819 - accuracy: 0.8318 - val_loss: 0.5182 - val_accuracy: 0.7963\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3847 - accuracy: 0.8364 - val_loss: 0.5268 - val_accuracy: 0.7963\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4183 - accuracy: 0.8084 - val_loss: 0.5252 - val_accuracy: 0.8148\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3792 - accuracy: 0.8505 - val_loss: 0.5259 - val_accuracy: 0.7963\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3919 - accuracy: 0.8224 - val_loss: 0.5404 - val_accuracy: 0.7778\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3893 - accuracy: 0.7991 - val_loss: 0.5393 - val_accuracy: 0.7593\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3860 - accuracy: 0.8411 - val_loss: 0.5342 - val_accuracy: 0.7963\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3913 - accuracy: 0.7991 - val_loss: 0.5451 - val_accuracy: 0.7593\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3704 - accuracy: 0.8598 - val_loss: 0.5428 - val_accuracy: 0.7963\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3869 - accuracy: 0.8318 - val_loss: 0.5280 - val_accuracy: 0.8148\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3847 - accuracy: 0.8364 - val_loss: 0.5252 - val_accuracy: 0.8148\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.8131 - val_loss: 0.5266 - val_accuracy: 0.7963\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3507 - accuracy: 0.8458 - val_loss: 0.5283 - val_accuracy: 0.7963\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4243 - accuracy: 0.8224 - val_loss: 0.5419 - val_accuracy: 0.7778\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3908 - accuracy: 0.8318 - val_loss: 0.5437 - val_accuracy: 0.7963\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3938 - accuracy: 0.8458 - val_loss: 0.5344 - val_accuracy: 0.7963\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3857 - accuracy: 0.8364 - val_loss: 0.5265 - val_accuracy: 0.7963\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3559 - accuracy: 0.8318 - val_loss: 0.5357 - val_accuracy: 0.8148\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3699 - accuracy: 0.8224 - val_loss: 0.5421 - val_accuracy: 0.7778\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3800 - accuracy: 0.8458 - val_loss: 0.5505 - val_accuracy: 0.7593\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3604 - accuracy: 0.8364 - val_loss: 0.5664 - val_accuracy: 0.7963\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3613 - accuracy: 0.8458 - val_loss: 0.5670 - val_accuracy: 0.7407\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3793 - accuracy: 0.8551 - val_loss: 0.5673 - val_accuracy: 0.7407\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4099 - accuracy: 0.7944 - val_loss: 0.5627 - val_accuracy: 0.7963\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3990 - accuracy: 0.8271 - val_loss: 0.5593 - val_accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3682 - accuracy: 0.8458 - val_loss: 0.5487 - val_accuracy: 0.7963\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3902 - accuracy: 0.8224 - val_loss: 0.5352 - val_accuracy: 0.7963\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3713 - accuracy: 0.8364 - val_loss: 0.5345 - val_accuracy: 0.8148\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.8645 - val_loss: 0.5344 - val_accuracy: 0.7963\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3478 - accuracy: 0.8692 - val_loss: 0.5392 - val_accuracy: 0.8148\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3505 - accuracy: 0.8692 - val_loss: 0.5433 - val_accuracy: 0.8148\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3620 - accuracy: 0.8645 - val_loss: 0.5505 - val_accuracy: 0.7778\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3944 - accuracy: 0.7944 - val_loss: 0.5470 - val_accuracy: 0.7963\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3310 - accuracy: 0.8738 - val_loss: 0.5457 - val_accuracy: 0.7963\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3681 - accuracy: 0.8411 - val_loss: 0.5454 - val_accuracy: 0.8148\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3462 - accuracy: 0.8645 - val_loss: 0.5524 - val_accuracy: 0.7963\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3737 - accuracy: 0.8458 - val_loss: 0.5686 - val_accuracy: 0.7778\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.8271 - val_loss: 0.5674 - val_accuracy: 0.7407\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.8411 - val_loss: 0.5842 - val_accuracy: 0.7593\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3629 - accuracy: 0.8411 - val_loss: 0.5766 - val_accuracy: 0.7407\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4095 - accuracy: 0.7850 - val_loss: 0.5919 - val_accuracy: 0.7037\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3867 - accuracy: 0.8084 - val_loss: 0.5812 - val_accuracy: 0.7407\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3850 - accuracy: 0.8271 - val_loss: 0.5730 - val_accuracy: 0.7593\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3745 - accuracy: 0.8271 - val_loss: 0.5633 - val_accuracy: 0.7593\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3667 - accuracy: 0.8131 - val_loss: 0.5678 - val_accuracy: 0.7778\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.8364 - val_loss: 0.5590 - val_accuracy: 0.7778\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3711 - accuracy: 0.8505 - val_loss: 0.5638 - val_accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3631 - accuracy: 0.8505 - val_loss: 0.5587 - val_accuracy: 0.7593\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3637 - accuracy: 0.8505 - val_loss: 0.5600 - val_accuracy: 0.7778\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3892 - accuracy: 0.8224 - val_loss: 0.5612 - val_accuracy: 0.8148\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B75C93FB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 350ms/step - loss: 0.7088 - accuracy: 0.5209 - val_loss: 0.6220 - val_accuracy: 0.5472\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5913 - accuracy: 0.6326 - val_loss: 0.5735 - val_accuracy: 0.8113\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5756 - accuracy: 0.7023 - val_loss: 0.5467 - val_accuracy: 0.7736\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5097 - accuracy: 0.7814 - val_loss: 0.5218 - val_accuracy: 0.8113\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5082 - accuracy: 0.7209 - val_loss: 0.5171 - val_accuracy: 0.7925\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4945 - accuracy: 0.7814 - val_loss: 0.5416 - val_accuracy: 0.8113\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4622 - accuracy: 0.7767 - val_loss: 0.5383 - val_accuracy: 0.7925\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4627 - accuracy: 0.7814 - val_loss: 0.5485 - val_accuracy: 0.8113\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4494 - accuracy: 0.8093 - val_loss: 0.5482 - val_accuracy: 0.7736\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4418 - accuracy: 0.7953 - val_loss: 0.5416 - val_accuracy: 0.7925\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4186 - accuracy: 0.8047 - val_loss: 0.5521 - val_accuracy: 0.7925\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4557 - accuracy: 0.7907 - val_loss: 0.5526 - val_accuracy: 0.7925\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4152 - accuracy: 0.8140 - val_loss: 0.5448 - val_accuracy: 0.8113\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4710 - accuracy: 0.7860 - val_loss: 0.5318 - val_accuracy: 0.8302\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4374 - accuracy: 0.8047 - val_loss: 0.5506 - val_accuracy: 0.7925\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4290 - accuracy: 0.8093 - val_loss: 0.5025 - val_accuracy: 0.7925\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4482 - accuracy: 0.7907 - val_loss: 0.5091 - val_accuracy: 0.7736\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4387 - accuracy: 0.7628 - val_loss: 0.5078 - val_accuracy: 0.7925\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4391 - accuracy: 0.7953 - val_loss: 0.5552 - val_accuracy: 0.7547\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4578 - accuracy: 0.7767 - val_loss: 0.5459 - val_accuracy: 0.8113\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4315 - accuracy: 0.8047 - val_loss: 0.5498 - val_accuracy: 0.8113\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4049 - accuracy: 0.8047 - val_loss: 0.5911 - val_accuracy: 0.7925\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4259 - accuracy: 0.8047 - val_loss: 0.6251 - val_accuracy: 0.7736\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.7488 - val_loss: 0.5895 - val_accuracy: 0.7736\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4416 - accuracy: 0.8186 - val_loss: 0.5450 - val_accuracy: 0.7736\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4430 - accuracy: 0.8047 - val_loss: 0.5817 - val_accuracy: 0.7736\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.6075 - val_accuracy: 0.7547\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4265 - accuracy: 0.7953 - val_loss: 0.5563 - val_accuracy: 0.7925\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4152 - accuracy: 0.8093 - val_loss: 0.5758 - val_accuracy: 0.8113\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4295 - accuracy: 0.7953 - val_loss: 0.6095 - val_accuracy: 0.7736\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4365 - accuracy: 0.8140 - val_loss: 0.6295 - val_accuracy: 0.7736\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4385 - accuracy: 0.8000 - val_loss: 0.5985 - val_accuracy: 0.7925\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.8186 - val_loss: 0.5911 - val_accuracy: 0.7736\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4235 - accuracy: 0.8000 - val_loss: 0.5971 - val_accuracy: 0.7925\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4125 - accuracy: 0.8047 - val_loss: 0.5751 - val_accuracy: 0.8113\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4455 - accuracy: 0.8047 - val_loss: 0.5907 - val_accuracy: 0.7925\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8000 - val_loss: 0.6148 - val_accuracy: 0.7736\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4396 - accuracy: 0.7907 - val_loss: 0.6201 - val_accuracy: 0.7736\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4100 - accuracy: 0.8186 - val_loss: 0.5804 - val_accuracy: 0.7736\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4142 - accuracy: 0.8186 - val_loss: 0.5478 - val_accuracy: 0.8113\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4607 - accuracy: 0.7814 - val_loss: 0.5381 - val_accuracy: 0.8113\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4084 - accuracy: 0.8186 - val_loss: 0.5892 - val_accuracy: 0.7736\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4378 - accuracy: 0.8047 - val_loss: 0.6228 - val_accuracy: 0.8113\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4086 - accuracy: 0.8186 - val_loss: 0.6351 - val_accuracy: 0.8113\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.8000 - val_loss: 0.6408 - val_accuracy: 0.8113\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4259 - accuracy: 0.8093 - val_loss: 0.6355 - val_accuracy: 0.7736\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3952 - accuracy: 0.8233 - val_loss: 0.6217 - val_accuracy: 0.7925\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4309 - accuracy: 0.7814 - val_loss: 0.6253 - val_accuracy: 0.8113\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4457 - accuracy: 0.7860 - val_loss: 0.6728 - val_accuracy: 0.7547\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4208 - accuracy: 0.8093 - val_loss: 0.6265 - val_accuracy: 0.7736\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8000 - val_loss: 0.6115 - val_accuracy: 0.8113\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4250 - accuracy: 0.7907 - val_loss: 0.6605 - val_accuracy: 0.7736\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4153 - accuracy: 0.8140 - val_loss: 0.6637 - val_accuracy: 0.7736\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4421 - accuracy: 0.8047 - val_loss: 0.6012 - val_accuracy: 0.8113\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4160 - accuracy: 0.8000 - val_loss: 0.5969 - val_accuracy: 0.8113\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4378 - accuracy: 0.7860 - val_loss: 0.6598 - val_accuracy: 0.7925\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4350 - accuracy: 0.8047 - val_loss: 0.6496 - val_accuracy: 0.8113\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4229 - accuracy: 0.8093 - val_loss: 0.6349 - val_accuracy: 0.8302\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4034 - accuracy: 0.7907 - val_loss: 0.6361 - val_accuracy: 0.8113\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3923 - accuracy: 0.8233 - val_loss: 0.6367 - val_accuracy: 0.7925\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4132 - accuracy: 0.8233 - val_loss: 0.6276 - val_accuracy: 0.7736\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4185 - accuracy: 0.8047 - val_loss: 0.6409 - val_accuracy: 0.7736\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4100 - accuracy: 0.8000 - val_loss: 0.6434 - val_accuracy: 0.7736\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3833 - accuracy: 0.8326 - val_loss: 0.6340 - val_accuracy: 0.7736\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4488 - accuracy: 0.7674 - val_loss: 0.6073 - val_accuracy: 0.8113\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4248 - accuracy: 0.8093 - val_loss: 0.6240 - val_accuracy: 0.8113\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4165 - accuracy: 0.7814 - val_loss: 0.6588 - val_accuracy: 0.7925\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4424 - accuracy: 0.8140 - val_loss: 0.6987 - val_accuracy: 0.7736\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4182 - accuracy: 0.8186 - val_loss: 0.6672 - val_accuracy: 0.7547\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.8279 - val_loss: 0.6342 - val_accuracy: 0.7925\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4148 - accuracy: 0.8047 - val_loss: 0.6768 - val_accuracy: 0.7925\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4333 - accuracy: 0.7814 - val_loss: 0.6561 - val_accuracy: 0.7736\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.8140 - val_loss: 0.6609 - val_accuracy: 0.7925\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4043 - accuracy: 0.8186 - val_loss: 0.6611 - val_accuracy: 0.7925\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4039 - accuracy: 0.8093 - val_loss: 0.6924 - val_accuracy: 0.7925\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4418 - accuracy: 0.8047 - val_loss: 0.6495 - val_accuracy: 0.7925\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8140 - val_loss: 0.6637 - val_accuracy: 0.7925\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8512 - val_loss: 0.6786 - val_accuracy: 0.8113\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4468 - accuracy: 0.7814 - val_loss: 0.7389 - val_accuracy: 0.7736\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3900 - accuracy: 0.8093 - val_loss: 0.7197 - val_accuracy: 0.8302\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4277 - accuracy: 0.8093 - val_loss: 0.7070 - val_accuracy: 0.8113\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4278 - accuracy: 0.8093 - val_loss: 0.6960 - val_accuracy: 0.7736\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3804 - accuracy: 0.8372 - val_loss: 0.6593 - val_accuracy: 0.8113\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4147 - accuracy: 0.8233 - val_loss: 0.6632 - val_accuracy: 0.8302\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3941 - accuracy: 0.8372 - val_loss: 0.6794 - val_accuracy: 0.7736\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4009 - accuracy: 0.8093 - val_loss: 0.7007 - val_accuracy: 0.7736\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3600 - accuracy: 0.8279 - val_loss: 0.7097 - val_accuracy: 0.7925\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3828 - accuracy: 0.8465 - val_loss: 0.7366 - val_accuracy: 0.7736\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3992 - accuracy: 0.8279 - val_loss: 0.6867 - val_accuracy: 0.7925\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4398 - accuracy: 0.7953 - val_loss: 0.6731 - val_accuracy: 0.8113\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4163 - accuracy: 0.8000 - val_loss: 0.7056 - val_accuracy: 0.7925\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4101 - accuracy: 0.8140 - val_loss: 0.7545 - val_accuracy: 0.7736\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4204 - accuracy: 0.7907 - val_loss: 0.7242 - val_accuracy: 0.7925\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4432 - accuracy: 0.8140 - val_loss: 0.7364 - val_accuracy: 0.8113\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4298 - accuracy: 0.8000 - val_loss: 0.7864 - val_accuracy: 0.7736\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.8465 - val_loss: 0.7317 - val_accuracy: 0.7925\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4358 - accuracy: 0.8233 - val_loss: 0.7241 - val_accuracy: 0.7925\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4226 - accuracy: 0.8000 - val_loss: 0.7357 - val_accuracy: 0.7736\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3956 - accuracy: 0.8047 - val_loss: 0.7610 - val_accuracy: 0.8113\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3934 - accuracy: 0.8047 - val_loss: 0.7737 - val_accuracy: 0.8113\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3990 - accuracy: 0.8233 - val_loss: 0.8345 - val_accuracy: 0.7736\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4370 - accuracy: 0.7814 - val_loss: 0.7959 - val_accuracy: 0.7736\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4008 - accuracy: 0.8279 - val_loss: 0.7610 - val_accuracy: 0.8113\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.8186 - val_loss: 0.7652 - val_accuracy: 0.7547\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4307 - accuracy: 0.7767 - val_loss: 0.7542 - val_accuracy: 0.7736\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4177 - accuracy: 0.8140 - val_loss: 0.7262 - val_accuracy: 0.7925\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4165 - accuracy: 0.7953 - val_loss: 0.7636 - val_accuracy: 0.7925\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3992 - accuracy: 0.8093 - val_loss: 0.7868 - val_accuracy: 0.7736\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.8000 - val_loss: 0.8089 - val_accuracy: 0.8113\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4450 - accuracy: 0.7907 - val_loss: 0.7989 - val_accuracy: 0.8113\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8279 - val_loss: 0.7538 - val_accuracy: 0.7736\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4536 - accuracy: 0.7581 - val_loss: 0.7117 - val_accuracy: 0.8113\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4279 - accuracy: 0.8000 - val_loss: 0.7020 - val_accuracy: 0.8302\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4354 - accuracy: 0.7860 - val_loss: 0.7932 - val_accuracy: 0.7736\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4383 - accuracy: 0.8000 - val_loss: 0.7730 - val_accuracy: 0.7925\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4327 - accuracy: 0.7953 - val_loss: 0.7288 - val_accuracy: 0.8113\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4414 - accuracy: 0.7814 - val_loss: 0.7043 - val_accuracy: 0.8302\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3906 - accuracy: 0.8140 - val_loss: 0.7485 - val_accuracy: 0.7925\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3980 - accuracy: 0.8326 - val_loss: 0.7091 - val_accuracy: 0.7736\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4048 - accuracy: 0.8093 - val_loss: 0.6999 - val_accuracy: 0.8113\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4102 - accuracy: 0.8093 - val_loss: 0.7339 - val_accuracy: 0.7925\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4046 - accuracy: 0.8233 - val_loss: 0.7799 - val_accuracy: 0.7736\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4185 - accuracy: 0.8140 - val_loss: 0.7776 - val_accuracy: 0.7925\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4339 - accuracy: 0.8233 - val_loss: 0.7848 - val_accuracy: 0.8113\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3748 - accuracy: 0.8372 - val_loss: 0.8416 - val_accuracy: 0.7925\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4025 - accuracy: 0.8419 - val_loss: 0.8410 - val_accuracy: 0.7736\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4189 - accuracy: 0.8140 - val_loss: 0.7933 - val_accuracy: 0.8302\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4212 - accuracy: 0.8140 - val_loss: 0.7890 - val_accuracy: 0.8302\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4295 - accuracy: 0.7953 - val_loss: 0.7560 - val_accuracy: 0.8302\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4010 - accuracy: 0.8140 - val_loss: 0.7705 - val_accuracy: 0.7925\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8279 - val_loss: 0.7890 - val_accuracy: 0.7736\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.7953 - val_loss: 0.8180 - val_accuracy: 0.7547\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4332 - accuracy: 0.7953 - val_loss: 0.7735 - val_accuracy: 0.8302\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4081 - accuracy: 0.8140 - val_loss: 0.7747 - val_accuracy: 0.8302\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3856 - accuracy: 0.8372 - val_loss: 0.8005 - val_accuracy: 0.7736\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3929 - accuracy: 0.8093 - val_loss: 0.7962 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8047 - val_loss: 0.7938 - val_accuracy: 0.8302\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4112 - accuracy: 0.8047 - val_loss: 0.8124 - val_accuracy: 0.8113\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8140 - val_loss: 0.8116 - val_accuracy: 0.8113\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3738 - accuracy: 0.8233 - val_loss: 0.8096 - val_accuracy: 0.8113\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4081 - accuracy: 0.8233 - val_loss: 0.8633 - val_accuracy: 0.7925\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3886 - accuracy: 0.8279 - val_loss: 0.8409 - val_accuracy: 0.7736\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8093 - val_loss: 0.8194 - val_accuracy: 0.8113\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4437 - accuracy: 0.7860 - val_loss: 0.7995 - val_accuracy: 0.8491\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.8093 - val_loss: 0.8565 - val_accuracy: 0.7547\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3856 - accuracy: 0.8233 - val_loss: 0.8584 - val_accuracy: 0.7547\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.8093 - val_loss: 0.8372 - val_accuracy: 0.7925\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3890 - accuracy: 0.8140 - val_loss: 0.8289 - val_accuracy: 0.8113\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4090 - accuracy: 0.8186 - val_loss: 0.8211 - val_accuracy: 0.7925\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4011 - accuracy: 0.8093 - val_loss: 0.8225 - val_accuracy: 0.8113\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3818 - accuracy: 0.8140 - val_loss: 0.8074 - val_accuracy: 0.8302\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3577 - accuracy: 0.8279 - val_loss: 0.8181 - val_accuracy: 0.8113\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4366 - accuracy: 0.7860 - val_loss: 0.8246 - val_accuracy: 0.8113\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3787 - accuracy: 0.8372 - val_loss: 0.8395 - val_accuracy: 0.8113\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.8326 - val_loss: 0.8604 - val_accuracy: 0.8113\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3792 - accuracy: 0.8279 - val_loss: 0.8725 - val_accuracy: 0.7736\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3706 - accuracy: 0.8512 - val_loss: 0.8704 - val_accuracy: 0.7925\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4060 - accuracy: 0.8186 - val_loss: 0.8666 - val_accuracy: 0.7925\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3939 - accuracy: 0.8000 - val_loss: 0.8028 - val_accuracy: 0.8302\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3928 - accuracy: 0.8093 - val_loss: 0.8319 - val_accuracy: 0.8113\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4046 - accuracy: 0.8047 - val_loss: 0.8441 - val_accuracy: 0.8113\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3893 - accuracy: 0.8372 - val_loss: 0.8270 - val_accuracy: 0.7925\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3799 - accuracy: 0.8233 - val_loss: 0.8471 - val_accuracy: 0.7925\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3792 - accuracy: 0.8233 - val_loss: 0.8205 - val_accuracy: 0.8302\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4206 - accuracy: 0.8047 - val_loss: 0.8351 - val_accuracy: 0.8302\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.8465 - val_loss: 0.8948 - val_accuracy: 0.7925\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3925 - accuracy: 0.8279 - val_loss: 0.8910 - val_accuracy: 0.7925\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3697 - accuracy: 0.8326 - val_loss: 0.8529 - val_accuracy: 0.8302\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4090 - accuracy: 0.8233 - val_loss: 0.8780 - val_accuracy: 0.7736\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3841 - accuracy: 0.8047 - val_loss: 0.8486 - val_accuracy: 0.7925\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3640 - accuracy: 0.8279 - val_loss: 0.8455 - val_accuracy: 0.7925\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4252 - accuracy: 0.8186 - val_loss: 0.8246 - val_accuracy: 0.8113\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3594 - accuracy: 0.8465 - val_loss: 0.8283 - val_accuracy: 0.7925\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3628 - accuracy: 0.8372 - val_loss: 0.8746 - val_accuracy: 0.7925\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3959 - accuracy: 0.8326 - val_loss: 0.8588 - val_accuracy: 0.8113\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3875 - accuracy: 0.8419 - val_loss: 0.8779 - val_accuracy: 0.8113\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3698 - accuracy: 0.8233 - val_loss: 0.8709 - val_accuracy: 0.7925\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3854 - accuracy: 0.8140 - val_loss: 0.8723 - val_accuracy: 0.7925\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.8186 - val_loss: 0.8828 - val_accuracy: 0.8113\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3732 - accuracy: 0.8465 - val_loss: 0.8993 - val_accuracy: 0.7925\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3758 - accuracy: 0.8233 - val_loss: 0.8628 - val_accuracy: 0.7925\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3620 - accuracy: 0.8140 - val_loss: 0.8454 - val_accuracy: 0.7925\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3960 - accuracy: 0.8233 - val_loss: 0.8835 - val_accuracy: 0.7925\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4018 - accuracy: 0.8326 - val_loss: 0.9374 - val_accuracy: 0.7736\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4399 - accuracy: 0.8140 - val_loss: 0.9075 - val_accuracy: 0.8113\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3830 - accuracy: 0.8140 - val_loss: 0.8842 - val_accuracy: 0.8113\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4051 - accuracy: 0.7953 - val_loss: 0.8799 - val_accuracy: 0.8302\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3874 - accuracy: 0.8233 - val_loss: 0.9138 - val_accuracy: 0.7736\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4234 - accuracy: 0.8233 - val_loss: 0.8672 - val_accuracy: 0.8302\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4157 - accuracy: 0.7860 - val_loss: 0.8393 - val_accuracy: 0.7736\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4092 - accuracy: 0.7907 - val_loss: 0.8524 - val_accuracy: 0.8302\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3808 - accuracy: 0.8186 - val_loss: 0.8912 - val_accuracy: 0.7736\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4152 - accuracy: 0.8140 - val_loss: 0.8559 - val_accuracy: 0.8302\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4045 - accuracy: 0.7907 - val_loss: 0.8121 - val_accuracy: 0.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4135 - accuracy: 0.7953 - val_loss: 0.8387 - val_accuracy: 0.8302\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8093 - val_loss: 0.8455 - val_accuracy: 0.8113\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8186 - val_loss: 0.8694 - val_accuracy: 0.7925\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4253 - accuracy: 0.8047 - val_loss: 0.8948 - val_accuracy: 0.7925\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4019 - accuracy: 0.8140 - val_loss: 0.8417 - val_accuracy: 0.8113\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3950 - accuracy: 0.7953 - val_loss: 0.8737 - val_accuracy: 0.8113\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B96A2E9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.6641 - accuracy: 0.5814 - val_loss: 0.6260 - val_accuracy: 0.5472\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6083 - accuracy: 0.6512 - val_loss: 0.5921 - val_accuracy: 0.6792\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5707 - accuracy: 0.6837 - val_loss: 0.5505 - val_accuracy: 0.7736\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5039 - accuracy: 0.7907 - val_loss: 0.5217 - val_accuracy: 0.7547\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4738 - accuracy: 0.8093 - val_loss: 0.5016 - val_accuracy: 0.7547\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4598 - accuracy: 0.7814 - val_loss: 0.4993 - val_accuracy: 0.7547\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4198 - accuracy: 0.8326 - val_loss: 0.4891 - val_accuracy: 0.7925\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4489 - accuracy: 0.8140 - val_loss: 0.4852 - val_accuracy: 0.7547\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4291 - accuracy: 0.8000 - val_loss: 0.4935 - val_accuracy: 0.7358\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4442 - accuracy: 0.8140 - val_loss: 0.4973 - val_accuracy: 0.7358\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4349 - accuracy: 0.8000 - val_loss: 0.4954 - val_accuracy: 0.7547\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4404 - accuracy: 0.8047 - val_loss: 0.4998 - val_accuracy: 0.7736\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4522 - accuracy: 0.7907 - val_loss: 0.5042 - val_accuracy: 0.7547\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4207 - accuracy: 0.8140 - val_loss: 0.5137 - val_accuracy: 0.7547\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4707 - accuracy: 0.8140 - val_loss: 0.5089 - val_accuracy: 0.7547\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4373 - accuracy: 0.8233 - val_loss: 0.5041 - val_accuracy: 0.8113\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4198 - accuracy: 0.8093 - val_loss: 0.4999 - val_accuracy: 0.8113\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4315 - accuracy: 0.8093 - val_loss: 0.4986 - val_accuracy: 0.7736\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4003 - accuracy: 0.8093 - val_loss: 0.5021 - val_accuracy: 0.7925\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4215 - accuracy: 0.8233 - val_loss: 0.4972 - val_accuracy: 0.8113\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.8000 - val_loss: 0.4935 - val_accuracy: 0.7925\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4115 - accuracy: 0.8047 - val_loss: 0.4932 - val_accuracy: 0.7547\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.8000 - val_loss: 0.4863 - val_accuracy: 0.7925\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4054 - accuracy: 0.8326 - val_loss: 0.4940 - val_accuracy: 0.7736\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4216 - accuracy: 0.8233 - val_loss: 0.4900 - val_accuracy: 0.8113\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4560 - accuracy: 0.7907 - val_loss: 0.4841 - val_accuracy: 0.8113\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4164 - accuracy: 0.8140 - val_loss: 0.4749 - val_accuracy: 0.8113\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4141 - accuracy: 0.8233 - val_loss: 0.4772 - val_accuracy: 0.8113\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4493 - accuracy: 0.7814 - val_loss: 0.4872 - val_accuracy: 0.8113\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4494 - accuracy: 0.8000 - val_loss: 0.4873 - val_accuracy: 0.7925\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.8279 - val_loss: 0.4863 - val_accuracy: 0.8113\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8186 - val_loss: 0.4826 - val_accuracy: 0.8113\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4246 - accuracy: 0.8047 - val_loss: 0.4782 - val_accuracy: 0.8113\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4192 - accuracy: 0.8279 - val_loss: 0.4988 - val_accuracy: 0.7736\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4207 - accuracy: 0.8140 - val_loss: 0.4965 - val_accuracy: 0.8113\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4094 - accuracy: 0.8186 - val_loss: 0.5019 - val_accuracy: 0.7736\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4210 - accuracy: 0.8047 - val_loss: 0.5035 - val_accuracy: 0.8113\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4679 - accuracy: 0.7907 - val_loss: 0.5012 - val_accuracy: 0.8113\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4035 - accuracy: 0.8093 - val_loss: 0.4927 - val_accuracy: 0.7358\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4129 - accuracy: 0.8279 - val_loss: 0.4919 - val_accuracy: 0.7736\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4474 - accuracy: 0.8093 - val_loss: 0.5097 - val_accuracy: 0.8113\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.8140 - val_loss: 0.5172 - val_accuracy: 0.8113\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4247 - accuracy: 0.8093 - val_loss: 0.5153 - val_accuracy: 0.7547\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4210 - accuracy: 0.8093 - val_loss: 0.5046 - val_accuracy: 0.7547\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.8000 - val_loss: 0.4995 - val_accuracy: 0.7925\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4164 - accuracy: 0.8047 - val_loss: 0.5060 - val_accuracy: 0.7358\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4401 - accuracy: 0.8047 - val_loss: 0.4949 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4495 - accuracy: 0.7628 - val_loss: 0.4987 - val_accuracy: 0.7925\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4246 - accuracy: 0.7907 - val_loss: 0.4884 - val_accuracy: 0.7547\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4112 - accuracy: 0.8233 - val_loss: 0.4930 - val_accuracy: 0.7358\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4323 - accuracy: 0.8186 - val_loss: 0.4813 - val_accuracy: 0.8113\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4355 - accuracy: 0.8047 - val_loss: 0.5090 - val_accuracy: 0.7547\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4254 - accuracy: 0.8047 - val_loss: 0.4838 - val_accuracy: 0.8113\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4184 - accuracy: 0.8000 - val_loss: 0.4831 - val_accuracy: 0.7925\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4331 - accuracy: 0.8186 - val_loss: 0.4815 - val_accuracy: 0.8113\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4112 - accuracy: 0.8093 - val_loss: 0.4792 - val_accuracy: 0.8113\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4318 - accuracy: 0.8186 - val_loss: 0.4758 - val_accuracy: 0.8113\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4224 - accuracy: 0.8140 - val_loss: 0.4735 - val_accuracy: 0.7925\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4269 - accuracy: 0.8000 - val_loss: 0.4800 - val_accuracy: 0.8113\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4433 - accuracy: 0.8093 - val_loss: 0.4862 - val_accuracy: 0.8113\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4140 - accuracy: 0.8093 - val_loss: 0.4900 - val_accuracy: 0.8113\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.8093 - val_loss: 0.4944 - val_accuracy: 0.8113\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3848 - accuracy: 0.8233 - val_loss: 0.4861 - val_accuracy: 0.8113\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.8186 - val_loss: 0.4978 - val_accuracy: 0.8113\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4090 - accuracy: 0.8186 - val_loss: 0.5015 - val_accuracy: 0.7925\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3896 - accuracy: 0.8093 - val_loss: 0.4857 - val_accuracy: 0.7547\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3895 - accuracy: 0.8093 - val_loss: 0.4879 - val_accuracy: 0.8113\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3897 - accuracy: 0.8186 - val_loss: 0.4949 - val_accuracy: 0.8113\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3605 - accuracy: 0.8186 - val_loss: 0.5055 - val_accuracy: 0.8302\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4356 - accuracy: 0.8047 - val_loss: 0.5124 - val_accuracy: 0.8113\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4220 - accuracy: 0.8140 - val_loss: 0.5031 - val_accuracy: 0.7547\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8233 - val_loss: 0.4942 - val_accuracy: 0.8113\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3969 - accuracy: 0.8372 - val_loss: 0.5018 - val_accuracy: 0.8113\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.7860 - val_loss: 0.5115 - val_accuracy: 0.7925\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4001 - accuracy: 0.8186 - val_loss: 0.5185 - val_accuracy: 0.7925\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8047 - val_loss: 0.5147 - val_accuracy: 0.7736\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4045 - accuracy: 0.8186 - val_loss: 0.5079 - val_accuracy: 0.8113\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4049 - accuracy: 0.8186 - val_loss: 0.5129 - val_accuracy: 0.8113\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3936 - accuracy: 0.8140 - val_loss: 0.5132 - val_accuracy: 0.8113\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3926 - accuracy: 0.8140 - val_loss: 0.5243 - val_accuracy: 0.8113\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4218 - accuracy: 0.8093 - val_loss: 0.5330 - val_accuracy: 0.7925\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3911 - accuracy: 0.8047 - val_loss: 0.5213 - val_accuracy: 0.7736\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3976 - accuracy: 0.8186 - val_loss: 0.5156 - val_accuracy: 0.7736\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.8186 - val_loss: 0.5217 - val_accuracy: 0.7736\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.8140 - val_loss: 0.5229 - val_accuracy: 0.7736\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3920 - accuracy: 0.8233 - val_loss: 0.5168 - val_accuracy: 0.7925\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3820 - accuracy: 0.8233 - val_loss: 0.5140 - val_accuracy: 0.7925\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3673 - accuracy: 0.8326 - val_loss: 0.5192 - val_accuracy: 0.8113\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3733 - accuracy: 0.8186 - val_loss: 0.5382 - val_accuracy: 0.7547\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3878 - accuracy: 0.8326 - val_loss: 0.5353 - val_accuracy: 0.7358\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3724 - accuracy: 0.8372 - val_loss: 0.5391 - val_accuracy: 0.7358\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.5432 - val_accuracy: 0.7358\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3972 - accuracy: 0.8186 - val_loss: 0.5390 - val_accuracy: 0.7358\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3861 - accuracy: 0.8233 - val_loss: 0.5454 - val_accuracy: 0.7925\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4097 - accuracy: 0.8093 - val_loss: 0.5118 - val_accuracy: 0.8113\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3771 - accuracy: 0.8233 - val_loss: 0.5116 - val_accuracy: 0.7736\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4042 - accuracy: 0.8279 - val_loss: 0.5232 - val_accuracy: 0.7736\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3738 - accuracy: 0.8233 - val_loss: 0.5387 - val_accuracy: 0.7358\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4022 - accuracy: 0.8279 - val_loss: 0.5347 - val_accuracy: 0.7925\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4250 - accuracy: 0.8047 - val_loss: 0.5456 - val_accuracy: 0.7547\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4087 - accuracy: 0.8047 - val_loss: 0.5576 - val_accuracy: 0.7547\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4101 - accuracy: 0.8558 - val_loss: 0.5525 - val_accuracy: 0.7170\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8326 - val_loss: 0.5308 - val_accuracy: 0.7547\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4000 - accuracy: 0.8186 - val_loss: 0.5243 - val_accuracy: 0.8113\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.8279 - val_loss: 0.5117 - val_accuracy: 0.8113\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4020 - accuracy: 0.8326 - val_loss: 0.5207 - val_accuracy: 0.7925\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4105 - accuracy: 0.8279 - val_loss: 0.5455 - val_accuracy: 0.7925\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4084 - accuracy: 0.8419 - val_loss: 0.5504 - val_accuracy: 0.7736\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3904 - accuracy: 0.8326 - val_loss: 0.5334 - val_accuracy: 0.7925\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3822 - accuracy: 0.8372 - val_loss: 0.5299 - val_accuracy: 0.7358\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4186 - accuracy: 0.8093 - val_loss: 0.5216 - val_accuracy: 0.7925\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4065 - accuracy: 0.8140 - val_loss: 0.5315 - val_accuracy: 0.7736\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4133 - accuracy: 0.8000 - val_loss: 0.5267 - val_accuracy: 0.7736\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3989 - accuracy: 0.8233 - val_loss: 0.5350 - val_accuracy: 0.7925\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3655 - accuracy: 0.8465 - val_loss: 0.5409 - val_accuracy: 0.7925\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4064 - accuracy: 0.8093 - val_loss: 0.5417 - val_accuracy: 0.7925\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3650 - accuracy: 0.8419 - val_loss: 0.5344 - val_accuracy: 0.7736\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3661 - accuracy: 0.8465 - val_loss: 0.5205 - val_accuracy: 0.8113\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.8233 - val_loss: 0.5169 - val_accuracy: 0.7925\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3768 - accuracy: 0.8093 - val_loss: 0.5423 - val_accuracy: 0.7358\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3889 - accuracy: 0.8233 - val_loss: 0.5507 - val_accuracy: 0.7170\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3879 - accuracy: 0.8047 - val_loss: 0.5922 - val_accuracy: 0.7170\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3567 - accuracy: 0.8372 - val_loss: 0.5519 - val_accuracy: 0.7547\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3736 - accuracy: 0.8279 - val_loss: 0.5461 - val_accuracy: 0.7736\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4172 - accuracy: 0.8047 - val_loss: 0.5480 - val_accuracy: 0.7358\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.8512 - val_loss: 0.5705 - val_accuracy: 0.7547\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3788 - accuracy: 0.8512 - val_loss: 0.5493 - val_accuracy: 0.7925\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8093 - val_loss: 0.5591 - val_accuracy: 0.7170\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3979 - accuracy: 0.8233 - val_loss: 0.5335 - val_accuracy: 0.7358\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3938 - accuracy: 0.8326 - val_loss: 0.5430 - val_accuracy: 0.8302\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3931 - accuracy: 0.8186 - val_loss: 0.5391 - val_accuracy: 0.7925\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3718 - accuracy: 0.8233 - val_loss: 0.5423 - val_accuracy: 0.8302\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3635 - accuracy: 0.8419 - val_loss: 0.5492 - val_accuracy: 0.7358\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.8326 - val_loss: 0.5614 - val_accuracy: 0.6981\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3729 - accuracy: 0.8233 - val_loss: 0.5792 - val_accuracy: 0.7358\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8000 - val_loss: 0.5467 - val_accuracy: 0.7736\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3830 - accuracy: 0.8000 - val_loss: 0.5734 - val_accuracy: 0.6604\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3852 - accuracy: 0.8558 - val_loss: 0.5234 - val_accuracy: 0.7925\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3674 - accuracy: 0.8186 - val_loss: 0.5345 - val_accuracy: 0.8113\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3888 - accuracy: 0.8279 - val_loss: 0.5507 - val_accuracy: 0.8113\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3817 - accuracy: 0.8279 - val_loss: 0.5561 - val_accuracy: 0.7358\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4040 - accuracy: 0.8186 - val_loss: 0.5502 - val_accuracy: 0.7736\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3505 - accuracy: 0.8372 - val_loss: 0.5650 - val_accuracy: 0.7736\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3889 - accuracy: 0.8000 - val_loss: 0.5542 - val_accuracy: 0.7925\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3472 - accuracy: 0.8419 - val_loss: 0.5446 - val_accuracy: 0.7358\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3895 - accuracy: 0.8233 - val_loss: 0.5376 - val_accuracy: 0.7358\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3712 - accuracy: 0.8233 - val_loss: 0.5465 - val_accuracy: 0.7925\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.8698 - val_loss: 0.5536 - val_accuracy: 0.7736\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4077 - accuracy: 0.8233 - val_loss: 0.5611 - val_accuracy: 0.7358\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3811 - accuracy: 0.8326 - val_loss: 0.5489 - val_accuracy: 0.7547\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3482 - accuracy: 0.8372 - val_loss: 0.5605 - val_accuracy: 0.7358\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3957 - accuracy: 0.8279 - val_loss: 0.5369 - val_accuracy: 0.7736\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3919 - accuracy: 0.8186 - val_loss: 0.5289 - val_accuracy: 0.7736\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.8279 - val_loss: 0.5178 - val_accuracy: 0.7925\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3679 - accuracy: 0.8279 - val_loss: 0.5153 - val_accuracy: 0.7925\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3937 - accuracy: 0.8279 - val_loss: 0.5289 - val_accuracy: 0.7925\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3871 - accuracy: 0.8326 - val_loss: 0.5556 - val_accuracy: 0.7170\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3999 - accuracy: 0.8140 - val_loss: 0.5411 - val_accuracy: 0.7925\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3618 - accuracy: 0.8465 - val_loss: 0.5518 - val_accuracy: 0.7736\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3749 - accuracy: 0.8326 - val_loss: 0.5641 - val_accuracy: 0.7736\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.8326 - val_loss: 0.5633 - val_accuracy: 0.7358\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3574 - accuracy: 0.8465 - val_loss: 0.5510 - val_accuracy: 0.7925\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3851 - accuracy: 0.8279 - val_loss: 0.5477 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3771 - accuracy: 0.8372 - val_loss: 0.5358 - val_accuracy: 0.7736\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3760 - accuracy: 0.8372 - val_loss: 0.5356 - val_accuracy: 0.7358\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3858 - accuracy: 0.8372 - val_loss: 0.5411 - val_accuracy: 0.7547\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.8465 - val_loss: 0.5223 - val_accuracy: 0.7736\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3583 - accuracy: 0.8186 - val_loss: 0.5158 - val_accuracy: 0.7925\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3602 - accuracy: 0.8233 - val_loss: 0.5206 - val_accuracy: 0.7736\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3320 - accuracy: 0.8605 - val_loss: 0.5024 - val_accuracy: 0.7925\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3266 - accuracy: 0.8419 - val_loss: 0.4995 - val_accuracy: 0.7736\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3464 - accuracy: 0.8233 - val_loss: 0.5007 - val_accuracy: 0.7736\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3666 - accuracy: 0.8465 - val_loss: 0.5105 - val_accuracy: 0.7925\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3464 - accuracy: 0.8698 - val_loss: 0.5133 - val_accuracy: 0.7925\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3531 - accuracy: 0.8326 - val_loss: 0.5341 - val_accuracy: 0.7736\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3769 - accuracy: 0.8186 - val_loss: 0.5268 - val_accuracy: 0.7925\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3735 - accuracy: 0.8186 - val_loss: 0.5293 - val_accuracy: 0.7925\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3610 - accuracy: 0.8372 - val_loss: 0.5405 - val_accuracy: 0.7925\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.8419 - val_loss: 0.5375 - val_accuracy: 0.7547\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3805 - accuracy: 0.8140 - val_loss: 0.5463 - val_accuracy: 0.7736\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3441 - accuracy: 0.8465 - val_loss: 0.5341 - val_accuracy: 0.7170\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3272 - accuracy: 0.8512 - val_loss: 0.5191 - val_accuracy: 0.7925\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3719 - accuracy: 0.8093 - val_loss: 0.5211 - val_accuracy: 0.7925\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3715 - accuracy: 0.8140 - val_loss: 0.5233 - val_accuracy: 0.7170\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8093 - val_loss: 0.5251 - val_accuracy: 0.7170\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3412 - accuracy: 0.8372 - val_loss: 0.5504 - val_accuracy: 0.7925\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3408 - accuracy: 0.8558 - val_loss: 0.5970 - val_accuracy: 0.7547\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3719 - accuracy: 0.8233 - val_loss: 0.5270 - val_accuracy: 0.8113\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3510 - accuracy: 0.8326 - val_loss: 0.5274 - val_accuracy: 0.7925\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3835 - accuracy: 0.8372 - val_loss: 0.5381 - val_accuracy: 0.7358\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3510 - accuracy: 0.8279 - val_loss: 0.5386 - val_accuracy: 0.7736\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.8140 - val_loss: 0.5691 - val_accuracy: 0.7358\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3406 - accuracy: 0.8605 - val_loss: 0.5405 - val_accuracy: 0.7547\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3349 - accuracy: 0.8465 - val_loss: 0.5548 - val_accuracy: 0.7736\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.8465 - val_loss: 0.6325 - val_accuracy: 0.6792\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3753 - accuracy: 0.8186 - val_loss: 0.5539 - val_accuracy: 0.7736\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3817 - accuracy: 0.8186 - val_loss: 0.5532 - val_accuracy: 0.7547\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3741 - accuracy: 0.8372 - val_loss: 0.6135 - val_accuracy: 0.7170\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3491 - accuracy: 0.8512 - val_loss: 0.5593 - val_accuracy: 0.7547\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3430 - accuracy: 0.8512 - val_loss: 0.5367 - val_accuracy: 0.7925\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B95F075310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/'+'Theft/'+'/CDI_Based/Intensity/CSV/'+'Optical_Mag'+'.csv',index_col=0)\n",
    "data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+'Burglary'+'/Optical_Mag.csv',index_col=0)\n",
    "\n",
    "y=data['Class'].values\n",
    "X=data.drop(['Class'], axis=1).values\n",
    "#X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "#     std =StandardScaler()\n",
    "#     X_train=std.fit_transform(X[train])\n",
    "#     X_test=std.transform(X[test])\n",
    "    X_train,X_test=X[train],X[test]\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "          LSTM(\n",
    "              units=128,\n",
    "              input_shape=[X_train.shape[1], X_train.shape[2]]\n",
    "          )\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                         optimizer=Adam(lr = lr),\n",
    "                         metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=\"1d+cnn.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "    history=model.fit(X_train, y[train],\n",
    "                epochs=200,\n",
    "                batch_size=64,\n",
    "                validation_data=(X_test, y[test]),\n",
    "                verbose=1,\n",
    "                callbacks=[checkpointer]).history\n",
    "    model=load_model('1d+cnn.h5')\n",
    "    y_prob = model.predict(X_test, verbose=0)\n",
    "    fpr_test,tpr_test,_ = roc_curve(y[test],y_prob)     \n",
    "    auc_test = auc(fpr_test,tpr_test)  \n",
    "    interp_tpr = np.interp(mean_fpr,fpr_test, tpr_test)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(auc_test)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='dodgerblue',label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title='ROC of gray'+ ' on Dataset ')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T02:16:04.444335Z",
     "start_time": "2020-10-03T02:13:41.472989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.8100 - accuracy: 0.4579 - val_loss: 0.6707 - val_accuracy: 0.5741\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6756 - accuracy: 0.5794 - val_loss: 0.6885 - val_accuracy: 0.5370\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6761 - accuracy: 0.5935 - val_loss: 0.6330 - val_accuracy: 0.6111\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6233 - accuracy: 0.6869 - val_loss: 0.5392 - val_accuracy: 0.7963\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5651 - accuracy: 0.7243 - val_loss: 0.5056 - val_accuracy: 0.8148\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5806 - accuracy: 0.7570 - val_loss: 0.4817 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5738 - accuracy: 0.7336 - val_loss: 0.4697 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5622 - accuracy: 0.7243 - val_loss: 0.4565 - val_accuracy: 0.7963\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5668 - accuracy: 0.7150 - val_loss: 0.4379 - val_accuracy: 0.8148\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5364 - accuracy: 0.7523 - val_loss: 0.4320 - val_accuracy: 0.8148\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5505 - accuracy: 0.7290 - val_loss: 0.4299 - val_accuracy: 0.8148\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5465 - accuracy: 0.7617 - val_loss: 0.4261 - val_accuracy: 0.7778\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5265 - accuracy: 0.7710 - val_loss: 0.4202 - val_accuracy: 0.7778\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5017 - accuracy: 0.7617 - val_loss: 0.4110 - val_accuracy: 0.7778\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5374 - accuracy: 0.7430 - val_loss: 0.4064 - val_accuracy: 0.7963\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5336 - accuracy: 0.7664 - val_loss: 0.4043 - val_accuracy: 0.7778\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5525 - accuracy: 0.7056 - val_loss: 0.4164 - val_accuracy: 0.7778\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5403 - accuracy: 0.7383 - val_loss: 0.4228 - val_accuracy: 0.7963\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.7757 - val_loss: 0.4087 - val_accuracy: 0.7778\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5229 - accuracy: 0.7383 - val_loss: 0.4048 - val_accuracy: 0.7778\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.7430 - val_loss: 0.4049 - val_accuracy: 0.7593\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5356 - accuracy: 0.7430 - val_loss: 0.4026 - val_accuracy: 0.7963\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5327 - accuracy: 0.7430 - val_loss: 0.4026 - val_accuracy: 0.7593\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5365 - accuracy: 0.7150 - val_loss: 0.4004 - val_accuracy: 0.8148\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5386 - accuracy: 0.7570 - val_loss: 0.4029 - val_accuracy: 0.7593\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5235 - accuracy: 0.7336 - val_loss: 0.4128 - val_accuracy: 0.7963\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5443 - accuracy: 0.7290 - val_loss: 0.4178 - val_accuracy: 0.8148\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5107 - accuracy: 0.7804 - val_loss: 0.4085 - val_accuracy: 0.8148\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5311 - accuracy: 0.7336 - val_loss: 0.4040 - val_accuracy: 0.7778\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5080 - accuracy: 0.7617 - val_loss: 0.3968 - val_accuracy: 0.7963\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5173 - accuracy: 0.7710 - val_loss: 0.3949 - val_accuracy: 0.8148\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5071 - accuracy: 0.7617 - val_loss: 0.4012 - val_accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.5165 - accuracy: 0.7757 - val_loss: 0.4143 - val_accuracy: 0.7778\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.4879 - accuracy: 0.7710 - val_loss: 0.4156 - val_accuracy: 0.7778\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5122 - accuracy: 0.7757 - val_loss: 0.4068 - val_accuracy: 0.8148\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5349 - accuracy: 0.7570 - val_loss: 0.4015 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5632 - accuracy: 0.7336 - val_loss: 0.4018 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.5344 - accuracy: 0.7523 - val_loss: 0.4052 - val_accuracy: 0.8148\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5117 - accuracy: 0.7290 - val_loss: 0.4206 - val_accuracy: 0.7963\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5400 - accuracy: 0.7617 - val_loss: 0.4157 - val_accuracy: 0.7778\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5192 - accuracy: 0.7523 - val_loss: 0.4133 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.5787 - accuracy: 0.7196 - val_loss: 0.4144 - val_accuracy: 0.8333\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5079 - accuracy: 0.7383 - val_loss: 0.4168 - val_accuracy: 0.8333\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.5212 - accuracy: 0.7523 - val_loss: 0.4180 - val_accuracy: 0.8519\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5264 - accuracy: 0.7430 - val_loss: 0.4220 - val_accuracy: 0.8148\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5051 - accuracy: 0.7617 - val_loss: 0.4286 - val_accuracy: 0.7963\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5031 - accuracy: 0.7664 - val_loss: 0.4329 - val_accuracy: 0.7963\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5039 - accuracy: 0.7617 - val_loss: 0.4265 - val_accuracy: 0.7963\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.5464 - accuracy: 0.7570 - val_loss: 0.4156 - val_accuracy: 0.7963\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5205 - accuracy: 0.7430 - val_loss: 0.4134 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.5250 - accuracy: 0.7383 - val_loss: 0.4151 - val_accuracy: 0.8333\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5207 - accuracy: 0.7430 - val_loss: 0.4159 - val_accuracy: 0.7963\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.4995 - accuracy: 0.7757 - val_loss: 0.4247 - val_accuracy: 0.7963\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5149 - accuracy: 0.7617 - val_loss: 0.4206 - val_accuracy: 0.8148\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.5294 - accuracy: 0.7383 - val_loss: 0.4119 - val_accuracy: 0.8148\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.4856 - accuracy: 0.7991 - val_loss: 0.4109 - val_accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.5103 - accuracy: 0.7710 - val_loss: 0.4097 - val_accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5018 - accuracy: 0.7617 - val_loss: 0.4105 - val_accuracy: 0.8333\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5236 - accuracy: 0.7617 - val_loss: 0.4152 - val_accuracy: 0.8148\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.5462 - accuracy: 0.7430 - val_loss: 0.4129 - val_accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.5161 - accuracy: 0.7710 - val_loss: 0.4153 - val_accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4879 - accuracy: 0.7523 - val_loss: 0.4158 - val_accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.5150 - accuracy: 0.7336 - val_loss: 0.4144 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5080 - accuracy: 0.7430 - val_loss: 0.4134 - val_accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.5262 - accuracy: 0.7523 - val_loss: 0.4134 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.5112 - accuracy: 0.7804 - val_loss: 0.4196 - val_accuracy: 0.7963\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.5032 - accuracy: 0.7430 - val_loss: 0.4176 - val_accuracy: 0.8148\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5091 - accuracy: 0.7336 - val_loss: 0.4144 - val_accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5307 - accuracy: 0.7523 - val_loss: 0.4122 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5174 - accuracy: 0.7570 - val_loss: 0.4103 - val_accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.5122 - accuracy: 0.7804 - val_loss: 0.4103 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.5226 - accuracy: 0.7570 - val_loss: 0.4114 - val_accuracy: 0.8519\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.5328 - accuracy: 0.7570 - val_loss: 0.4112 - val_accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4714 - accuracy: 0.7850 - val_loss: 0.4203 - val_accuracy: 0.7963\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5030 - accuracy: 0.7617 - val_loss: 0.4221 - val_accuracy: 0.7778\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.5021 - accuracy: 0.7710 - val_loss: 0.4136 - val_accuracy: 0.8148\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5132 - accuracy: 0.7710 - val_loss: 0.4151 - val_accuracy: 0.8519\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5238 - accuracy: 0.7523 - val_loss: 0.4155 - val_accuracy: 0.8148\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4828 - accuracy: 0.7617 - val_loss: 0.4209 - val_accuracy: 0.8148\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.5233 - accuracy: 0.7383 - val_loss: 0.4221 - val_accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5394 - accuracy: 0.7570 - val_loss: 0.4229 - val_accuracy: 0.8148\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.5254 - accuracy: 0.7570 - val_loss: 0.4241 - val_accuracy: 0.8148\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.5168 - accuracy: 0.7804 - val_loss: 0.4261 - val_accuracy: 0.8519\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5188 - accuracy: 0.7477 - val_loss: 0.4272 - val_accuracy: 0.8519\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5074 - accuracy: 0.7664 - val_loss: 0.4256 - val_accuracy: 0.8148\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5420 - accuracy: 0.7383 - val_loss: 0.4281 - val_accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5194 - accuracy: 0.7617 - val_loss: 0.4445 - val_accuracy: 0.7963\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5321 - accuracy: 0.7617 - val_loss: 0.4343 - val_accuracy: 0.7963\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5202 - accuracy: 0.7383 - val_loss: 0.4249 - val_accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5178 - accuracy: 0.7757 - val_loss: 0.4270 - val_accuracy: 0.8519\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4947 - accuracy: 0.7850 - val_loss: 0.4290 - val_accuracy: 0.8519\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5131 - accuracy: 0.7664 - val_loss: 0.4247 - val_accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5069 - accuracy: 0.7477 - val_loss: 0.4254 - val_accuracy: 0.8148\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5331 - accuracy: 0.7664 - val_loss: 0.4280 - val_accuracy: 0.8148\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5046 - accuracy: 0.7523 - val_loss: 0.4253 - val_accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5222 - accuracy: 0.7617 - val_loss: 0.4268 - val_accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5265 - accuracy: 0.7477 - val_loss: 0.4252 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5317 - accuracy: 0.7523 - val_loss: 0.4286 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4998 - accuracy: 0.7804 - val_loss: 0.4300 - val_accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5125 - accuracy: 0.7570 - val_loss: 0.4279 - val_accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5271 - accuracy: 0.7383 - val_loss: 0.4265 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4751 - accuracy: 0.7710 - val_loss: 0.4259 - val_accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5210 - accuracy: 0.7523 - val_loss: 0.4249 - val_accuracy: 0.8519\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5268 - accuracy: 0.7430 - val_loss: 0.4263 - val_accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5466 - accuracy: 0.7477 - val_loss: 0.4249 - val_accuracy: 0.8519\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5117 - accuracy: 0.7477 - val_loss: 0.4261 - val_accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5284 - accuracy: 0.7570 - val_loss: 0.4274 - val_accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4913 - accuracy: 0.7757 - val_loss: 0.4264 - val_accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7570 - val_loss: 0.4232 - val_accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5226 - accuracy: 0.7383 - val_loss: 0.4251 - val_accuracy: 0.8519\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5023 - accuracy: 0.7664 - val_loss: 0.4237 - val_accuracy: 0.8519\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5236 - accuracy: 0.7336 - val_loss: 0.4217 - val_accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5072 - accuracy: 0.7897 - val_loss: 0.4236 - val_accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5154 - accuracy: 0.7710 - val_loss: 0.4236 - val_accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5289 - accuracy: 0.7477 - val_loss: 0.4237 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5116 - accuracy: 0.7617 - val_loss: 0.4240 - val_accuracy: 0.8333\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5215 - accuracy: 0.7336 - val_loss: 0.4252 - val_accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5190 - accuracy: 0.7336 - val_loss: 0.4254 - val_accuracy: 0.8148\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5029 - accuracy: 0.7570 - val_loss: 0.4256 - val_accuracy: 0.8148\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5144 - accuracy: 0.7710 - val_loss: 0.4245 - val_accuracy: 0.8148\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4841 - accuracy: 0.7477 - val_loss: 0.4225 - val_accuracy: 0.8148\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4999 - accuracy: 0.7617 - val_loss: 0.4204 - val_accuracy: 0.7963\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5420 - accuracy: 0.7430 - val_loss: 0.4188 - val_accuracy: 0.8148\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5048 - accuracy: 0.7570 - val_loss: 0.4208 - val_accuracy: 0.8148\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.7477 - val_loss: 0.4216 - val_accuracy: 0.8148\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5029 - accuracy: 0.7523 - val_loss: 0.4241 - val_accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5077 - accuracy: 0.7477 - val_loss: 0.4257 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5078 - accuracy: 0.7617 - val_loss: 0.4264 - val_accuracy: 0.8519\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5171 - accuracy: 0.7664 - val_loss: 0.4272 - val_accuracy: 0.8148\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5081 - accuracy: 0.7523 - val_loss: 0.4259 - val_accuracy: 0.8148\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4723 - accuracy: 0.8084 - val_loss: 0.4252 - val_accuracy: 0.8519\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5055 - accuracy: 0.7290 - val_loss: 0.4243 - val_accuracy: 0.8148\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5226 - accuracy: 0.7477 - val_loss: 0.4201 - val_accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4907 - accuracy: 0.7710 - val_loss: 0.4167 - val_accuracy: 0.8148\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4804 - accuracy: 0.7664 - val_loss: 0.4201 - val_accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5298 - accuracy: 0.7617 - val_loss: 0.4191 - val_accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5022 - accuracy: 0.7664 - val_loss: 0.4198 - val_accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5233 - accuracy: 0.7103 - val_loss: 0.4199 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5002 - accuracy: 0.7804 - val_loss: 0.4218 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4834 - accuracy: 0.7944 - val_loss: 0.4231 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4975 - accuracy: 0.7477 - val_loss: 0.4233 - val_accuracy: 0.8148\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5010 - accuracy: 0.7710 - val_loss: 0.4237 - val_accuracy: 0.7963\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5142 - accuracy: 0.7430 - val_loss: 0.4209 - val_accuracy: 0.8148\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5026 - accuracy: 0.7570 - val_loss: 0.4208 - val_accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5122 - accuracy: 0.7383 - val_loss: 0.4201 - val_accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4890 - accuracy: 0.7430 - val_loss: 0.4176 - val_accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5437 - accuracy: 0.7243 - val_loss: 0.4186 - val_accuracy: 0.8148\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5194 - accuracy: 0.7664 - val_loss: 0.4190 - val_accuracy: 0.8148\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5382 - accuracy: 0.7243 - val_loss: 0.4213 - val_accuracy: 0.8148\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5153 - accuracy: 0.7570 - val_loss: 0.4226 - val_accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5157 - accuracy: 0.7570 - val_loss: 0.4258 - val_accuracy: 0.8148\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5129 - accuracy: 0.7477 - val_loss: 0.4304 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4822 - accuracy: 0.7804 - val_loss: 0.4306 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5246 - accuracy: 0.7243 - val_loss: 0.4274 - val_accuracy: 0.8148\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5014 - accuracy: 0.7804 - val_loss: 0.4282 - val_accuracy: 0.8148\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5556 - accuracy: 0.7430 - val_loss: 0.4285 - val_accuracy: 0.8148\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5200 - accuracy: 0.7570 - val_loss: 0.4282 - val_accuracy: 0.8148\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5006 - accuracy: 0.7710 - val_loss: 0.4266 - val_accuracy: 0.8148\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5155 - accuracy: 0.7477 - val_loss: 0.4258 - val_accuracy: 0.8148\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5032 - accuracy: 0.7757 - val_loss: 0.4254 - val_accuracy: 0.8148\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5172 - accuracy: 0.7523 - val_loss: 0.4254 - val_accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4772 - accuracy: 0.7757 - val_loss: 0.4229 - val_accuracy: 0.8148\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4971 - accuracy: 0.7710 - val_loss: 0.4226 - val_accuracy: 0.8148\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4871 - accuracy: 0.7664 - val_loss: 0.4212 - val_accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5325 - accuracy: 0.7570 - val_loss: 0.4220 - val_accuracy: 0.8148\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4992 - accuracy: 0.7710 - val_loss: 0.4204 - val_accuracy: 0.8148\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4888 - accuracy: 0.7897 - val_loss: 0.4260 - val_accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5066 - accuracy: 0.7617 - val_loss: 0.4300 - val_accuracy: 0.8148\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5145 - accuracy: 0.7664 - val_loss: 0.4285 - val_accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4692 - accuracy: 0.8037 - val_loss: 0.4345 - val_accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4980 - accuracy: 0.7477 - val_loss: 0.4344 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4867 - accuracy: 0.7757 - val_loss: 0.4317 - val_accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4932 - accuracy: 0.7570 - val_loss: 0.4304 - val_accuracy: 0.8148\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4610 - accuracy: 0.7710 - val_loss: 0.4333 - val_accuracy: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5199 - accuracy: 0.7523 - val_loss: 0.4338 - val_accuracy: 0.8148\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4787 - accuracy: 0.7664 - val_loss: 0.4294 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4724 - accuracy: 0.7897 - val_loss: 0.4291 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5189 - accuracy: 0.7430 - val_loss: 0.4271 - val_accuracy: 0.8148\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4911 - accuracy: 0.7710 - val_loss: 0.4234 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4741 - accuracy: 0.7804 - val_loss: 0.4239 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4873 - accuracy: 0.7477 - val_loss: 0.4254 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5031 - accuracy: 0.7710 - val_loss: 0.4271 - val_accuracy: 0.8519\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4806 - accuracy: 0.7664 - val_loss: 0.4298 - val_accuracy: 0.8519\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5165 - accuracy: 0.7570 - val_loss: 0.4343 - val_accuracy: 0.8519\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5039 - accuracy: 0.7523 - val_loss: 0.4394 - val_accuracy: 0.8148\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5217 - accuracy: 0.7523 - val_loss: 0.4399 - val_accuracy: 0.8148\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5179 - accuracy: 0.7430 - val_loss: 0.4402 - val_accuracy: 0.8333\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5269 - accuracy: 0.7570 - val_loss: 0.4393 - val_accuracy: 0.8519\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5150 - accuracy: 0.7664 - val_loss: 0.4399 - val_accuracy: 0.8519\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4902 - accuracy: 0.7617 - val_loss: 0.4395 - val_accuracy: 0.8519\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5015 - accuracy: 0.7757 - val_loss: 0.4368 - val_accuracy: 0.8148\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4959 - accuracy: 0.7804 - val_loss: 0.4361 - val_accuracy: 0.8148\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5087 - accuracy: 0.7477 - val_loss: 0.4329 - val_accuracy: 0.8148\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4983 - accuracy: 0.7757 - val_loss: 0.4290 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5095 - accuracy: 0.7477 - val_loss: 0.4257 - val_accuracy: 0.8148\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4747 - accuracy: 0.7617 - val_loss: 0.4262 - val_accuracy: 0.8333\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5268 - accuracy: 0.7570 - val_loss: 0.4293 - val_accuracy: 0.8519\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5050 - accuracy: 0.7383 - val_loss: 0.4298 - val_accuracy: 0.8148\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4901 - accuracy: 0.8037 - val_loss: 0.4304 - val_accuracy: 0.8148\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5261 - accuracy: 0.7430 - val_loss: 0.4348 - val_accuracy: 0.8333\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B971813280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.6875 - accuracy: 0.5187 - val_loss: 0.6196 - val_accuracy: 0.7222\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6243 - accuracy: 0.6729 - val_loss: 0.5958 - val_accuracy: 0.7593\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5877 - accuracy: 0.6916 - val_loss: 0.5747 - val_accuracy: 0.7593\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5777 - accuracy: 0.7290 - val_loss: 0.5580 - val_accuracy: 0.7407\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5672 - accuracy: 0.7150 - val_loss: 0.5512 - val_accuracy: 0.7407\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5290 - accuracy: 0.7570 - val_loss: 0.5439 - val_accuracy: 0.7037\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5488 - accuracy: 0.7103 - val_loss: 0.5457 - val_accuracy: 0.7593\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4842 - accuracy: 0.7850 - val_loss: 0.5370 - val_accuracy: 0.7222\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5063 - accuracy: 0.7570 - val_loss: 0.5409 - val_accuracy: 0.7407\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5062 - accuracy: 0.7243 - val_loss: 0.5493 - val_accuracy: 0.7407\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5096 - accuracy: 0.7383 - val_loss: 0.5456 - val_accuracy: 0.7407\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.7804 - val_loss: 0.5511 - val_accuracy: 0.7407\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5145 - accuracy: 0.7290 - val_loss: 0.5415 - val_accuracy: 0.7407\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5103 - accuracy: 0.7477 - val_loss: 0.5511 - val_accuracy: 0.7037\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4848 - accuracy: 0.7804 - val_loss: 0.5567 - val_accuracy: 0.6852\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.7757 - val_loss: 0.5531 - val_accuracy: 0.6852\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4809 - accuracy: 0.7710 - val_loss: 0.5488 - val_accuracy: 0.7037\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5047 - accuracy: 0.7477 - val_loss: 0.5459 - val_accuracy: 0.7222\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4927 - accuracy: 0.7804 - val_loss: 0.5441 - val_accuracy: 0.7222\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4619 - accuracy: 0.7664 - val_loss: 0.5416 - val_accuracy: 0.7222\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4715 - accuracy: 0.7850 - val_loss: 0.5445 - val_accuracy: 0.7037\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5138 - accuracy: 0.7570 - val_loss: 0.5471 - val_accuracy: 0.7037\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5368 - accuracy: 0.7290 - val_loss: 0.5467 - val_accuracy: 0.7222\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4794 - accuracy: 0.7850 - val_loss: 0.5408 - val_accuracy: 0.7037\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5032 - accuracy: 0.7383 - val_loss: 0.5369 - val_accuracy: 0.7407\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4753 - accuracy: 0.7944 - val_loss: 0.5411 - val_accuracy: 0.7407\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4719 - accuracy: 0.7617 - val_loss: 0.5615 - val_accuracy: 0.7407\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4617 - accuracy: 0.7710 - val_loss: 0.5729 - val_accuracy: 0.7593\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5242 - accuracy: 0.7290 - val_loss: 0.5522 - val_accuracy: 0.6852\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5056 - accuracy: 0.7617 - val_loss: 0.5475 - val_accuracy: 0.7222\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5212 - accuracy: 0.7336 - val_loss: 0.5474 - val_accuracy: 0.6852\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4953 - accuracy: 0.7523 - val_loss: 0.5458 - val_accuracy: 0.7037\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4656 - accuracy: 0.7570 - val_loss: 0.5450 - val_accuracy: 0.7037\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5129 - accuracy: 0.7710 - val_loss: 0.5416 - val_accuracy: 0.7037\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4569 - accuracy: 0.7850 - val_loss: 0.5432 - val_accuracy: 0.7037\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4853 - accuracy: 0.8037 - val_loss: 0.5387 - val_accuracy: 0.7037\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5102 - accuracy: 0.7430 - val_loss: 0.5350 - val_accuracy: 0.7407\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5070 - accuracy: 0.7570 - val_loss: 0.5424 - val_accuracy: 0.7037\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4870 - accuracy: 0.7336 - val_loss: 0.5451 - val_accuracy: 0.6852\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4462 - accuracy: 0.8037 - val_loss: 0.5572 - val_accuracy: 0.7222\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4937 - accuracy: 0.7757 - val_loss: 0.5536 - val_accuracy: 0.7222\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5025 - accuracy: 0.7617 - val_loss: 0.5504 - val_accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4892 - accuracy: 0.7523 - val_loss: 0.5485 - val_accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4708 - accuracy: 0.7617 - val_loss: 0.5476 - val_accuracy: 0.6852\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5115 - accuracy: 0.7617 - val_loss: 0.5506 - val_accuracy: 0.7037\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4239 - accuracy: 0.8131 - val_loss: 0.5549 - val_accuracy: 0.7222\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5137 - accuracy: 0.7430 - val_loss: 0.5465 - val_accuracy: 0.7037\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5027 - accuracy: 0.7664 - val_loss: 0.5424 - val_accuracy: 0.6852\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4716 - accuracy: 0.7664 - val_loss: 0.5406 - val_accuracy: 0.6852\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4804 - accuracy: 0.7664 - val_loss: 0.5435 - val_accuracy: 0.7037\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4780 - accuracy: 0.7944 - val_loss: 0.5503 - val_accuracy: 0.7222\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4693 - accuracy: 0.7804 - val_loss: 0.5462 - val_accuracy: 0.7222\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4808 - accuracy: 0.7523 - val_loss: 0.5438 - val_accuracy: 0.7037\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5030 - accuracy: 0.7430 - val_loss: 0.5418 - val_accuracy: 0.7037\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4340 - accuracy: 0.8131 - val_loss: 0.5423 - val_accuracy: 0.6852\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4788 - accuracy: 0.7710 - val_loss: 0.5422 - val_accuracy: 0.6852\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5203 - accuracy: 0.7383 - val_loss: 0.5415 - val_accuracy: 0.7037\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4598 - accuracy: 0.7570 - val_loss: 0.5410 - val_accuracy: 0.7037\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4791 - accuracy: 0.7477 - val_loss: 0.5381 - val_accuracy: 0.7037\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4494 - accuracy: 0.7757 - val_loss: 0.5377 - val_accuracy: 0.6667\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4863 - accuracy: 0.7664 - val_loss: 0.5388 - val_accuracy: 0.7037\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4836 - accuracy: 0.7710 - val_loss: 0.5404 - val_accuracy: 0.7037\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4934 - accuracy: 0.7383 - val_loss: 0.5397 - val_accuracy: 0.7037\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5366 - accuracy: 0.7336 - val_loss: 0.5376 - val_accuracy: 0.6667\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4531 - accuracy: 0.7850 - val_loss: 0.5379 - val_accuracy: 0.6852\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5164 - accuracy: 0.7336 - val_loss: 0.5384 - val_accuracy: 0.6852\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4673 - accuracy: 0.7850 - val_loss: 0.5488 - val_accuracy: 0.7407\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5018 - accuracy: 0.7710 - val_loss: 0.5486 - val_accuracy: 0.7222\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4577 - accuracy: 0.7804 - val_loss: 0.5420 - val_accuracy: 0.7037\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4532 - accuracy: 0.7804 - val_loss: 0.5421 - val_accuracy: 0.6667\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4548 - accuracy: 0.7991 - val_loss: 0.5432 - val_accuracy: 0.6667\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5012 - accuracy: 0.7430 - val_loss: 0.5438 - val_accuracy: 0.6667\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4762 - accuracy: 0.7383 - val_loss: 0.5448 - val_accuracy: 0.6667\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4602 - accuracy: 0.7850 - val_loss: 0.5487 - val_accuracy: 0.6852\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4518 - accuracy: 0.7664 - val_loss: 0.5512 - val_accuracy: 0.6852\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4951 - accuracy: 0.7617 - val_loss: 0.5493 - val_accuracy: 0.6852\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4911 - accuracy: 0.7570 - val_loss: 0.5429 - val_accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5012 - accuracy: 0.7523 - val_loss: 0.5403 - val_accuracy: 0.6667\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4728 - accuracy: 0.7617 - val_loss: 0.5384 - val_accuracy: 0.6852\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4927 - accuracy: 0.7570 - val_loss: 0.5377 - val_accuracy: 0.6667\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4526 - accuracy: 0.7850 - val_loss: 0.5371 - val_accuracy: 0.6852\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5123 - accuracy: 0.7196 - val_loss: 0.5365 - val_accuracy: 0.6667\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4761 - accuracy: 0.7757 - val_loss: 0.5363 - val_accuracy: 0.6852\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4447 - accuracy: 0.7523 - val_loss: 0.5348 - val_accuracy: 0.6852\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4804 - accuracy: 0.7664 - val_loss: 0.5343 - val_accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5009 - accuracy: 0.7430 - val_loss: 0.5351 - val_accuracy: 0.6852\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4696 - accuracy: 0.7664 - val_loss: 0.5361 - val_accuracy: 0.7037\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4561 - accuracy: 0.7897 - val_loss: 0.5365 - val_accuracy: 0.6852\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4763 - accuracy: 0.7710 - val_loss: 0.5359 - val_accuracy: 0.7037\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4623 - accuracy: 0.7570 - val_loss: 0.5375 - val_accuracy: 0.7037\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4657 - accuracy: 0.7804 - val_loss: 0.5365 - val_accuracy: 0.7037\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4774 - accuracy: 0.7570 - val_loss: 0.5354 - val_accuracy: 0.7037\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4655 - accuracy: 0.7804 - val_loss: 0.5359 - val_accuracy: 0.7037\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5060 - accuracy: 0.7243 - val_loss: 0.5393 - val_accuracy: 0.7037\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4668 - accuracy: 0.7897 - val_loss: 0.5439 - val_accuracy: 0.7037\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4880 - accuracy: 0.7430 - val_loss: 0.5429 - val_accuracy: 0.7037\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4571 - accuracy: 0.7664 - val_loss: 0.5382 - val_accuracy: 0.7037\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4809 - accuracy: 0.7570 - val_loss: 0.5347 - val_accuracy: 0.6852\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4834 - accuracy: 0.7710 - val_loss: 0.5347 - val_accuracy: 0.6852\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5012 - accuracy: 0.7430 - val_loss: 0.5378 - val_accuracy: 0.7037\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4785 - accuracy: 0.7570 - val_loss: 0.5386 - val_accuracy: 0.7037\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4505 - accuracy: 0.8037 - val_loss: 0.5432 - val_accuracy: 0.7037\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4802 - accuracy: 0.7430 - val_loss: 0.5497 - val_accuracy: 0.7222\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4500 - accuracy: 0.7850 - val_loss: 0.5488 - val_accuracy: 0.7222\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4813 - accuracy: 0.7757 - val_loss: 0.5442 - val_accuracy: 0.7037\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4844 - accuracy: 0.7710 - val_loss: 0.5420 - val_accuracy: 0.6852\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4747 - accuracy: 0.7477 - val_loss: 0.5423 - val_accuracy: 0.7037\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4934 - accuracy: 0.7523 - val_loss: 0.5449 - val_accuracy: 0.7037\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4565 - accuracy: 0.7570 - val_loss: 0.5442 - val_accuracy: 0.6852\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4746 - accuracy: 0.7477 - val_loss: 0.5462 - val_accuracy: 0.7037\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4188 - accuracy: 0.7944 - val_loss: 0.5480 - val_accuracy: 0.7037\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4827 - accuracy: 0.7804 - val_loss: 0.5504 - val_accuracy: 0.7037\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4886 - accuracy: 0.7477 - val_loss: 0.5526 - val_accuracy: 0.7037\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4757 - accuracy: 0.7477 - val_loss: 0.5498 - val_accuracy: 0.6852\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4757 - accuracy: 0.7430 - val_loss: 0.5493 - val_accuracy: 0.6852\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4292 - accuracy: 0.7897 - val_loss: 0.5475 - val_accuracy: 0.6852\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4957 - accuracy: 0.7477 - val_loss: 0.5477 - val_accuracy: 0.7037\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.7617 - val_loss: 0.5491 - val_accuracy: 0.7037\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4726 - accuracy: 0.7664 - val_loss: 0.5466 - val_accuracy: 0.6852\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4770 - accuracy: 0.7430 - val_loss: 0.5466 - val_accuracy: 0.6852\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4698 - accuracy: 0.7570 - val_loss: 0.5470 - val_accuracy: 0.6852\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4637 - accuracy: 0.7570 - val_loss: 0.5507 - val_accuracy: 0.6852\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5088 - accuracy: 0.7477 - val_loss: 0.5490 - val_accuracy: 0.6852\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4746 - accuracy: 0.7477 - val_loss: 0.5476 - val_accuracy: 0.6852\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4762 - accuracy: 0.7617 - val_loss: 0.5418 - val_accuracy: 0.6852\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4752 - accuracy: 0.7710 - val_loss: 0.5394 - val_accuracy: 0.6852\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4823 - accuracy: 0.7757 - val_loss: 0.5406 - val_accuracy: 0.6852\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4759 - accuracy: 0.7336 - val_loss: 0.5374 - val_accuracy: 0.6852\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5003 - accuracy: 0.7430 - val_loss: 0.5521 - val_accuracy: 0.7222\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4582 - accuracy: 0.7617 - val_loss: 0.5521 - val_accuracy: 0.7037\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4707 - accuracy: 0.7850 - val_loss: 0.5404 - val_accuracy: 0.6852\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4920 - accuracy: 0.7243 - val_loss: 0.5398 - val_accuracy: 0.6667\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5177 - accuracy: 0.7617 - val_loss: 0.5430 - val_accuracy: 0.6852\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4556 - accuracy: 0.7804 - val_loss: 0.5503 - val_accuracy: 0.7037\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4575 - accuracy: 0.7570 - val_loss: 0.5505 - val_accuracy: 0.7222\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4797 - accuracy: 0.7430 - val_loss: 0.5421 - val_accuracy: 0.6852\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4837 - accuracy: 0.7336 - val_loss: 0.5377 - val_accuracy: 0.6852\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5030 - accuracy: 0.7243 - val_loss: 0.5395 - val_accuracy: 0.6852\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4543 - accuracy: 0.7757 - val_loss: 0.5377 - val_accuracy: 0.6852\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4603 - accuracy: 0.7617 - val_loss: 0.5346 - val_accuracy: 0.6852\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4628 - accuracy: 0.7804 - val_loss: 0.5339 - val_accuracy: 0.6852\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4640 - accuracy: 0.7664 - val_loss: 0.5345 - val_accuracy: 0.6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4351 - accuracy: 0.8084 - val_loss: 0.5362 - val_accuracy: 0.6852\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4765 - accuracy: 0.7664 - val_loss: 0.5447 - val_accuracy: 0.7037\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4673 - accuracy: 0.7664 - val_loss: 0.5441 - val_accuracy: 0.7037\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4477 - accuracy: 0.7944 - val_loss: 0.5432 - val_accuracy: 0.6852\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4703 - accuracy: 0.7664 - val_loss: 0.5392 - val_accuracy: 0.6852\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4064 - accuracy: 0.8131 - val_loss: 0.5385 - val_accuracy: 0.6667\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4279 - accuracy: 0.7944 - val_loss: 0.5392 - val_accuracy: 0.6852\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4723 - accuracy: 0.7617 - val_loss: 0.5436 - val_accuracy: 0.6852\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4450 - accuracy: 0.7757 - val_loss: 0.5434 - val_accuracy: 0.6852\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4507 - accuracy: 0.7664 - val_loss: 0.5444 - val_accuracy: 0.7037\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4785 - accuracy: 0.7150 - val_loss: 0.5426 - val_accuracy: 0.6852\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4843 - accuracy: 0.7664 - val_loss: 0.5409 - val_accuracy: 0.6852\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4979 - accuracy: 0.7150 - val_loss: 0.5405 - val_accuracy: 0.6852\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4881 - accuracy: 0.7757 - val_loss: 0.5416 - val_accuracy: 0.6852\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4625 - accuracy: 0.7664 - val_loss: 0.5440 - val_accuracy: 0.6852\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4387 - accuracy: 0.7897 - val_loss: 0.5438 - val_accuracy: 0.6852\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4629 - accuracy: 0.7897 - val_loss: 0.5417 - val_accuracy: 0.6852\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4564 - accuracy: 0.7804 - val_loss: 0.5420 - val_accuracy: 0.6852\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4523 - accuracy: 0.7897 - val_loss: 0.5435 - val_accuracy: 0.6852\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4512 - accuracy: 0.7944 - val_loss: 0.5501 - val_accuracy: 0.7037\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4665 - accuracy: 0.7897 - val_loss: 0.5482 - val_accuracy: 0.7037\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4352 - accuracy: 0.7944 - val_loss: 0.5454 - val_accuracy: 0.6852\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4754 - accuracy: 0.7430 - val_loss: 0.5427 - val_accuracy: 0.6852\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4931 - accuracy: 0.7477 - val_loss: 0.5414 - val_accuracy: 0.6852\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4809 - accuracy: 0.7430 - val_loss: 0.5398 - val_accuracy: 0.6852\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4952 - accuracy: 0.7850 - val_loss: 0.5391 - val_accuracy: 0.6852\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5135 - accuracy: 0.7336 - val_loss: 0.5391 - val_accuracy: 0.6852\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4733 - accuracy: 0.7710 - val_loss: 0.5426 - val_accuracy: 0.7037\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4757 - accuracy: 0.7336 - val_loss: 0.5384 - val_accuracy: 0.6852\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4598 - accuracy: 0.7757 - val_loss: 0.5372 - val_accuracy: 0.6852\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.7664 - val_loss: 0.5390 - val_accuracy: 0.7037\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4398 - accuracy: 0.7897 - val_loss: 0.5417 - val_accuracy: 0.6852\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4949 - accuracy: 0.7383 - val_loss: 0.5425 - val_accuracy: 0.6852\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4736 - accuracy: 0.7290 - val_loss: 0.5439 - val_accuracy: 0.6852\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4308 - accuracy: 0.7897 - val_loss: 0.5459 - val_accuracy: 0.7037\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4622 - accuracy: 0.7570 - val_loss: 0.5533 - val_accuracy: 0.7222\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5138 - accuracy: 0.7336 - val_loss: 0.5551 - val_accuracy: 0.7222\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4853 - accuracy: 0.7570 - val_loss: 0.5477 - val_accuracy: 0.7037\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4727 - accuracy: 0.7664 - val_loss: 0.5437 - val_accuracy: 0.7037\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4711 - accuracy: 0.7850 - val_loss: 0.5411 - val_accuracy: 0.7037\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4600 - accuracy: 0.7710 - val_loss: 0.5405 - val_accuracy: 0.7037\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4514 - accuracy: 0.7757 - val_loss: 0.5411 - val_accuracy: 0.7037\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4541 - accuracy: 0.7897 - val_loss: 0.5420 - val_accuracy: 0.7037\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4263 - accuracy: 0.7617 - val_loss: 0.5428 - val_accuracy: 0.7037\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4792 - accuracy: 0.7336 - val_loss: 0.5432 - val_accuracy: 0.7037\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4733 - accuracy: 0.7430 - val_loss: 0.5462 - val_accuracy: 0.7037\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4711 - accuracy: 0.7710 - val_loss: 0.5435 - val_accuracy: 0.7037\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4593 - accuracy: 0.7477 - val_loss: 0.5389 - val_accuracy: 0.7037\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4513 - accuracy: 0.7757 - val_loss: 0.5370 - val_accuracy: 0.7037\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4507 - accuracy: 0.7710 - val_loss: 0.5366 - val_accuracy: 0.7037\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4840 - accuracy: 0.7383 - val_loss: 0.5402 - val_accuracy: 0.7037\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4489 - accuracy: 0.7664 - val_loss: 0.5467 - val_accuracy: 0.7222\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4509 - accuracy: 0.7757 - val_loss: 0.5507 - val_accuracy: 0.7222\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4644 - accuracy: 0.7570 - val_loss: 0.5451 - val_accuracy: 0.7222\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4797 - accuracy: 0.7383 - val_loss: 0.5407 - val_accuracy: 0.6852\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4427 - accuracy: 0.7897 - val_loss: 0.5395 - val_accuracy: 0.6852\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4571 - accuracy: 0.7570 - val_loss: 0.5375 - val_accuracy: 0.6852\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4698 - accuracy: 0.7290 - val_loss: 0.5401 - val_accuracy: 0.6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B7010C65E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.7420 - accuracy: 0.5280 - val_loss: 0.6784 - val_accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6526 - accuracy: 0.6215 - val_loss: 0.6296 - val_accuracy: 0.6852\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6078 - accuracy: 0.7009 - val_loss: 0.5851 - val_accuracy: 0.7222\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5481 - accuracy: 0.7290 - val_loss: 0.5615 - val_accuracy: 0.7593\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5478 - accuracy: 0.6916 - val_loss: 0.5475 - val_accuracy: 0.7222\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5049 - accuracy: 0.7477 - val_loss: 0.5451 - val_accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5179 - accuracy: 0.7523 - val_loss: 0.5528 - val_accuracy: 0.7037\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5224 - accuracy: 0.7430 - val_loss: 0.5549 - val_accuracy: 0.7037\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5038 - accuracy: 0.7757 - val_loss: 0.5400 - val_accuracy: 0.7222\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4751 - accuracy: 0.7757 - val_loss: 0.5329 - val_accuracy: 0.7593\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4828 - accuracy: 0.7710 - val_loss: 0.5380 - val_accuracy: 0.7222\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4572 - accuracy: 0.7850 - val_loss: 0.5545 - val_accuracy: 0.7037\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5496 - accuracy: 0.7383 - val_loss: 0.5565 - val_accuracy: 0.7037\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4730 - accuracy: 0.7477 - val_loss: 0.5307 - val_accuracy: 0.7593\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5362 - accuracy: 0.7150 - val_loss: 0.5347 - val_accuracy: 0.7593\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5357 - accuracy: 0.7196 - val_loss: 0.5287 - val_accuracy: 0.7593\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4952 - accuracy: 0.7617 - val_loss: 0.5331 - val_accuracy: 0.7593\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4892 - accuracy: 0.7804 - val_loss: 0.5529 - val_accuracy: 0.7037\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4956 - accuracy: 0.7710 - val_loss: 0.5503 - val_accuracy: 0.7037\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5184 - accuracy: 0.7477 - val_loss: 0.5339 - val_accuracy: 0.7593\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4702 - accuracy: 0.7664 - val_loss: 0.5319 - val_accuracy: 0.7593\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4774 - accuracy: 0.7570 - val_loss: 0.5382 - val_accuracy: 0.7593\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4983 - accuracy: 0.7570 - val_loss: 0.5591 - val_accuracy: 0.7222\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4707 - accuracy: 0.7664 - val_loss: 0.5483 - val_accuracy: 0.7407\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5048 - accuracy: 0.7710 - val_loss: 0.5349 - val_accuracy: 0.7593\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4873 - accuracy: 0.7710 - val_loss: 0.5345 - val_accuracy: 0.7407\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4826 - accuracy: 0.7757 - val_loss: 0.5319 - val_accuracy: 0.7593\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4977 - accuracy: 0.7570 - val_loss: 0.5360 - val_accuracy: 0.7222\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5015 - accuracy: 0.7570 - val_loss: 0.5409 - val_accuracy: 0.7222\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4986 - accuracy: 0.7430 - val_loss: 0.5373 - val_accuracy: 0.7222\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4697 - accuracy: 0.7664 - val_loss: 0.5311 - val_accuracy: 0.7593\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4587 - accuracy: 0.7804 - val_loss: 0.5315 - val_accuracy: 0.7593\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4630 - accuracy: 0.7757 - val_loss: 0.5325 - val_accuracy: 0.7593\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4524 - accuracy: 0.7991 - val_loss: 0.5342 - val_accuracy: 0.7593\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4544 - accuracy: 0.7757 - val_loss: 0.5365 - val_accuracy: 0.7593\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4811 - accuracy: 0.7897 - val_loss: 0.5348 - val_accuracy: 0.7593\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4707 - accuracy: 0.7757 - val_loss: 0.5360 - val_accuracy: 0.7593\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4990 - accuracy: 0.7570 - val_loss: 0.5401 - val_accuracy: 0.7593\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4499 - accuracy: 0.7850 - val_loss: 0.5388 - val_accuracy: 0.7593\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4943 - accuracy: 0.7477 - val_loss: 0.5408 - val_accuracy: 0.7407\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5108 - accuracy: 0.7804 - val_loss: 0.5343 - val_accuracy: 0.7593\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4798 - accuracy: 0.7991 - val_loss: 0.5358 - val_accuracy: 0.7593\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4594 - accuracy: 0.7757 - val_loss: 0.5411 - val_accuracy: 0.7407\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4719 - accuracy: 0.8084 - val_loss: 0.5475 - val_accuracy: 0.7222\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4894 - accuracy: 0.7617 - val_loss: 0.5501 - val_accuracy: 0.7222\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.7710 - val_loss: 0.5418 - val_accuracy: 0.7222\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4763 - accuracy: 0.7757 - val_loss: 0.5335 - val_accuracy: 0.7593\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4903 - accuracy: 0.7430 - val_loss: 0.5325 - val_accuracy: 0.7593\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4625 - accuracy: 0.7897 - val_loss: 0.5358 - val_accuracy: 0.7407\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4701 - accuracy: 0.7617 - val_loss: 0.5407 - val_accuracy: 0.7407\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5221 - accuracy: 0.7570 - val_loss: 0.5392 - val_accuracy: 0.7407\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4643 - accuracy: 0.7991 - val_loss: 0.5313 - val_accuracy: 0.7593\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4983 - accuracy: 0.7430 - val_loss: 0.5312 - val_accuracy: 0.7593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5067 - accuracy: 0.7477 - val_loss: 0.5351 - val_accuracy: 0.7407\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4927 - accuracy: 0.7757 - val_loss: 0.5462 - val_accuracy: 0.7037\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4922 - accuracy: 0.7710 - val_loss: 0.5510 - val_accuracy: 0.7037\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4658 - accuracy: 0.7944 - val_loss: 0.5406 - val_accuracy: 0.7037\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4999 - accuracy: 0.7710 - val_loss: 0.5298 - val_accuracy: 0.7593\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4810 - accuracy: 0.7757 - val_loss: 0.5308 - val_accuracy: 0.7593\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4998 - accuracy: 0.7243 - val_loss: 0.5304 - val_accuracy: 0.7593\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4283 - accuracy: 0.8084 - val_loss: 0.5301 - val_accuracy: 0.7593\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4875 - accuracy: 0.7477 - val_loss: 0.5331 - val_accuracy: 0.7407\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4419 - accuracy: 0.8037 - val_loss: 0.5387 - val_accuracy: 0.7037\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4750 - accuracy: 0.7710 - val_loss: 0.5378 - val_accuracy: 0.7222\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4612 - accuracy: 0.7664 - val_loss: 0.5354 - val_accuracy: 0.7407\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5021 - accuracy: 0.7570 - val_loss: 0.5336 - val_accuracy: 0.7407\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4969 - accuracy: 0.7477 - val_loss: 0.5336 - val_accuracy: 0.7407\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4533 - accuracy: 0.7710 - val_loss: 0.5353 - val_accuracy: 0.7407\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4626 - accuracy: 0.7850 - val_loss: 0.5399 - val_accuracy: 0.7407\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4664 - accuracy: 0.7664 - val_loss: 0.5490 - val_accuracy: 0.7037\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4988 - accuracy: 0.7430 - val_loss: 0.5462 - val_accuracy: 0.7037\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4887 - accuracy: 0.7523 - val_loss: 0.5385 - val_accuracy: 0.7222\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4443 - accuracy: 0.7664 - val_loss: 0.5359 - val_accuracy: 0.7407\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4740 - accuracy: 0.7477 - val_loss: 0.5334 - val_accuracy: 0.7407\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4741 - accuracy: 0.7477 - val_loss: 0.5320 - val_accuracy: 0.7407\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4340 - accuracy: 0.8271 - val_loss: 0.5335 - val_accuracy: 0.7407\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4698 - accuracy: 0.7664 - val_loss: 0.5387 - val_accuracy: 0.7222\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4545 - accuracy: 0.8037 - val_loss: 0.5348 - val_accuracy: 0.7222\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4675 - accuracy: 0.7664 - val_loss: 0.5315 - val_accuracy: 0.7407\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4423 - accuracy: 0.7897 - val_loss: 0.5302 - val_accuracy: 0.7407\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.7757 - val_loss: 0.5318 - val_accuracy: 0.7407\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4841 - accuracy: 0.7757 - val_loss: 0.5308 - val_accuracy: 0.7407\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4544 - accuracy: 0.7570 - val_loss: 0.5311 - val_accuracy: 0.7407\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4734 - accuracy: 0.7570 - val_loss: 0.5330 - val_accuracy: 0.7222\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4635 - accuracy: 0.7944 - val_loss: 0.5364 - val_accuracy: 0.7222\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5027 - accuracy: 0.7664 - val_loss: 0.5339 - val_accuracy: 0.7407\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4995 - accuracy: 0.7804 - val_loss: 0.5335 - val_accuracy: 0.7407\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4871 - accuracy: 0.7850 - val_loss: 0.5330 - val_accuracy: 0.7407\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4795 - accuracy: 0.7570 - val_loss: 0.5335 - val_accuracy: 0.7407\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.7850 - val_loss: 0.5396 - val_accuracy: 0.7037\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4672 - accuracy: 0.7383 - val_loss: 0.5382 - val_accuracy: 0.7037\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4732 - accuracy: 0.7664 - val_loss: 0.5333 - val_accuracy: 0.7407\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5019 - accuracy: 0.7336 - val_loss: 0.5302 - val_accuracy: 0.7593\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4466 - accuracy: 0.7664 - val_loss: 0.5301 - val_accuracy: 0.7407\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4630 - accuracy: 0.7617 - val_loss: 0.5329 - val_accuracy: 0.7222\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4455 - accuracy: 0.7850 - val_loss: 0.5345 - val_accuracy: 0.7037\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4591 - accuracy: 0.8037 - val_loss: 0.5313 - val_accuracy: 0.7222\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4575 - accuracy: 0.7757 - val_loss: 0.5286 - val_accuracy: 0.7407\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4570 - accuracy: 0.7430 - val_loss: 0.5283 - val_accuracy: 0.7407\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4291 - accuracy: 0.8037 - val_loss: 0.5319 - val_accuracy: 0.7407\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4585 - accuracy: 0.7710 - val_loss: 0.5325 - val_accuracy: 0.7407\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4777 - accuracy: 0.7850 - val_loss: 0.5328 - val_accuracy: 0.7222\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4502 - accuracy: 0.7944 - val_loss: 0.5301 - val_accuracy: 0.7593\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4384 - accuracy: 0.7850 - val_loss: 0.5299 - val_accuracy: 0.7593\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4583 - accuracy: 0.7804 - val_loss: 0.5326 - val_accuracy: 0.7222\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4699 - accuracy: 0.7757 - val_loss: 0.5364 - val_accuracy: 0.7222\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4566 - accuracy: 0.7617 - val_loss: 0.5327 - val_accuracy: 0.7222\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4751 - accuracy: 0.7804 - val_loss: 0.5306 - val_accuracy: 0.7593\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4610 - accuracy: 0.7664 - val_loss: 0.5302 - val_accuracy: 0.7593\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4699 - accuracy: 0.7477 - val_loss: 0.5285 - val_accuracy: 0.7593\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4596 - accuracy: 0.7710 - val_loss: 0.5264 - val_accuracy: 0.7407\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4557 - accuracy: 0.7710 - val_loss: 0.5259 - val_accuracy: 0.7222\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4779 - accuracy: 0.7477 - val_loss: 0.5252 - val_accuracy: 0.7222\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4328 - accuracy: 0.7991 - val_loss: 0.5230 - val_accuracy: 0.7407\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4609 - accuracy: 0.7617 - val_loss: 0.5233 - val_accuracy: 0.7222\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4495 - accuracy: 0.7944 - val_loss: 0.5228 - val_accuracy: 0.7222\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4929 - accuracy: 0.7383 - val_loss: 0.5220 - val_accuracy: 0.7593\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4679 - accuracy: 0.7617 - val_loss: 0.5216 - val_accuracy: 0.7593\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4542 - accuracy: 0.7710 - val_loss: 0.5218 - val_accuracy: 0.7407\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.7804 - val_loss: 0.5223 - val_accuracy: 0.7222\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4533 - accuracy: 0.7850 - val_loss: 0.5210 - val_accuracy: 0.7593\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.7804 - val_loss: 0.5211 - val_accuracy: 0.7593\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4363 - accuracy: 0.7897 - val_loss: 0.5239 - val_accuracy: 0.7222\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4617 - accuracy: 0.7804 - val_loss: 0.5291 - val_accuracy: 0.7037\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4389 - accuracy: 0.7850 - val_loss: 0.5260 - val_accuracy: 0.7222\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4448 - accuracy: 0.7850 - val_loss: 0.5233 - val_accuracy: 0.7407\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4570 - accuracy: 0.7570 - val_loss: 0.5232 - val_accuracy: 0.7593\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4530 - accuracy: 0.7897 - val_loss: 0.5238 - val_accuracy: 0.7593\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4589 - accuracy: 0.7804 - val_loss: 0.5243 - val_accuracy: 0.7593\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4811 - accuracy: 0.7944 - val_loss: 0.5239 - val_accuracy: 0.7593\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4402 - accuracy: 0.7991 - val_loss: 0.5245 - val_accuracy: 0.7593\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4757 - accuracy: 0.7523 - val_loss: 0.5251 - val_accuracy: 0.7593\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4634 - accuracy: 0.7757 - val_loss: 0.5248 - val_accuracy: 0.7593\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4664 - accuracy: 0.7617 - val_loss: 0.5240 - val_accuracy: 0.7593\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4768 - accuracy: 0.7710 - val_loss: 0.5244 - val_accuracy: 0.7407\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4825 - accuracy: 0.7523 - val_loss: 0.5244 - val_accuracy: 0.7407\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4374 - accuracy: 0.7850 - val_loss: 0.5242 - val_accuracy: 0.7593\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5075 - accuracy: 0.7570 - val_loss: 0.5239 - val_accuracy: 0.7593\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4356 - accuracy: 0.8037 - val_loss: 0.5236 - val_accuracy: 0.7407\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4374 - accuracy: 0.8271 - val_loss: 0.5259 - val_accuracy: 0.7037\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4511 - accuracy: 0.7804 - val_loss: 0.5258 - val_accuracy: 0.7037\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4430 - accuracy: 0.7617 - val_loss: 0.5251 - val_accuracy: 0.7407\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4534 - accuracy: 0.7523 - val_loss: 0.5290 - val_accuracy: 0.7593\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.7804 - val_loss: 0.5298 - val_accuracy: 0.7593\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4647 - accuracy: 0.7804 - val_loss: 0.5276 - val_accuracy: 0.7593\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4491 - accuracy: 0.7710 - val_loss: 0.5290 - val_accuracy: 0.7037\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4861 - accuracy: 0.7336 - val_loss: 0.5282 - val_accuracy: 0.7407\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4472 - accuracy: 0.8037 - val_loss: 0.5287 - val_accuracy: 0.7593\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4690 - accuracy: 0.7477 - val_loss: 0.5274 - val_accuracy: 0.7407\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4807 - accuracy: 0.7710 - val_loss: 0.5256 - val_accuracy: 0.7407\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4562 - accuracy: 0.7664 - val_loss: 0.5246 - val_accuracy: 0.7407\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4705 - accuracy: 0.7570 - val_loss: 0.5244 - val_accuracy: 0.7222\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4357 - accuracy: 0.7804 - val_loss: 0.5260 - val_accuracy: 0.7037\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4620 - accuracy: 0.7897 - val_loss: 0.5280 - val_accuracy: 0.7037\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4307 - accuracy: 0.7991 - val_loss: 0.5329 - val_accuracy: 0.7037\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4383 - accuracy: 0.8037 - val_loss: 0.5289 - val_accuracy: 0.7222\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4255 - accuracy: 0.7897 - val_loss: 0.5306 - val_accuracy: 0.7593\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4324 - accuracy: 0.7991 - val_loss: 0.5324 - val_accuracy: 0.7593\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.7664 - val_loss: 0.5325 - val_accuracy: 0.7593\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4718 - accuracy: 0.7617 - val_loss: 0.5304 - val_accuracy: 0.7407\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4860 - accuracy: 0.8037 - val_loss: 0.5316 - val_accuracy: 0.7037\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4862 - accuracy: 0.7617 - val_loss: 0.5316 - val_accuracy: 0.7037\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4198 - accuracy: 0.7944 - val_loss: 0.5320 - val_accuracy: 0.7037\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4649 - accuracy: 0.7850 - val_loss: 0.5291 - val_accuracy: 0.7037\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.7617 - val_loss: 0.5274 - val_accuracy: 0.7407\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4747 - accuracy: 0.7710 - val_loss: 0.5300 - val_accuracy: 0.7593\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4479 - accuracy: 0.7804 - val_loss: 0.5271 - val_accuracy: 0.7593\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4662 - accuracy: 0.7617 - val_loss: 0.5234 - val_accuracy: 0.7407\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4353 - accuracy: 0.7757 - val_loss: 0.5274 - val_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4620 - accuracy: 0.7850 - val_loss: 0.5287 - val_accuracy: 0.7222\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4582 - accuracy: 0.7710 - val_loss: 0.5236 - val_accuracy: 0.7037\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4339 - accuracy: 0.7757 - val_loss: 0.5207 - val_accuracy: 0.7407\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4538 - accuracy: 0.7944 - val_loss: 0.5210 - val_accuracy: 0.7407\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4550 - accuracy: 0.7897 - val_loss: 0.5212 - val_accuracy: 0.7593\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4193 - accuracy: 0.8131 - val_loss: 0.5216 - val_accuracy: 0.7407\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4183 - accuracy: 0.8131 - val_loss: 0.5233 - val_accuracy: 0.7037\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4288 - accuracy: 0.7897 - val_loss: 0.5242 - val_accuracy: 0.7222\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4353 - accuracy: 0.8084 - val_loss: 0.5249 - val_accuracy: 0.7407\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4755 - accuracy: 0.7757 - val_loss: 0.5249 - val_accuracy: 0.7593\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4508 - accuracy: 0.7944 - val_loss: 0.5251 - val_accuracy: 0.7222\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4584 - accuracy: 0.7617 - val_loss: 0.5274 - val_accuracy: 0.7037\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4511 - accuracy: 0.7944 - val_loss: 0.5284 - val_accuracy: 0.7037\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4580 - accuracy: 0.7897 - val_loss: 0.5290 - val_accuracy: 0.7037\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4226 - accuracy: 0.8084 - val_loss: 0.5277 - val_accuracy: 0.7037\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4356 - accuracy: 0.7897 - val_loss: 0.5266 - val_accuracy: 0.7593\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4371 - accuracy: 0.8084 - val_loss: 0.5296 - val_accuracy: 0.7593\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4592 - accuracy: 0.7757 - val_loss: 0.5286 - val_accuracy: 0.7593\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4603 - accuracy: 0.7477 - val_loss: 0.5273 - val_accuracy: 0.7222\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4546 - accuracy: 0.7710 - val_loss: 0.5279 - val_accuracy: 0.7037\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4792 - accuracy: 0.7617 - val_loss: 0.5266 - val_accuracy: 0.7407\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4523 - accuracy: 0.7710 - val_loss: 0.5273 - val_accuracy: 0.7037\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4531 - accuracy: 0.7897 - val_loss: 0.5270 - val_accuracy: 0.7222\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4712 - accuracy: 0.7617 - val_loss: 0.5256 - val_accuracy: 0.7407\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4476 - accuracy: 0.8178 - val_loss: 0.5263 - val_accuracy: 0.7593\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4167 - accuracy: 0.7944 - val_loss: 0.5255 - val_accuracy: 0.7407\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4776 - accuracy: 0.7804 - val_loss: 0.5262 - val_accuracy: 0.7222\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4731 - accuracy: 0.7664 - val_loss: 0.5271 - val_accuracy: 0.7222\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4516 - accuracy: 0.7897 - val_loss: 0.5267 - val_accuracy: 0.7222\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4235 - accuracy: 0.7850 - val_loss: 0.5270 - val_accuracy: 0.7222\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4858 - accuracy: 0.7664 - val_loss: 0.5272 - val_accuracy: 0.7222\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B972F75550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.7500 - accuracy: 0.5070 - val_loss: 0.6669 - val_accuracy: 0.5472\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6800 - accuracy: 0.6047 - val_loss: 0.6252 - val_accuracy: 0.6981\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5940 - accuracy: 0.6884 - val_loss: 0.6138 - val_accuracy: 0.6792\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5890 - accuracy: 0.7070 - val_loss: 0.5908 - val_accuracy: 0.7170\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5892 - accuracy: 0.6605 - val_loss: 0.5962 - val_accuracy: 0.7358\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5780 - accuracy: 0.6977 - val_loss: 0.5994 - val_accuracy: 0.6981\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5674 - accuracy: 0.7023 - val_loss: 0.6009 - val_accuracy: 0.6792\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5650 - accuracy: 0.7023 - val_loss: 0.5862 - val_accuracy: 0.6604\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5381 - accuracy: 0.7395 - val_loss: 0.5795 - val_accuracy: 0.6792\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5426 - accuracy: 0.7116 - val_loss: 0.5699 - val_accuracy: 0.6981\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5450 - accuracy: 0.7302 - val_loss: 0.5662 - val_accuracy: 0.6792\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5492 - accuracy: 0.7349 - val_loss: 0.5734 - val_accuracy: 0.6792\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5091 - accuracy: 0.7302 - val_loss: 0.5691 - val_accuracy: 0.6604\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5351 - accuracy: 0.7209 - val_loss: 0.5645 - val_accuracy: 0.6792\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5388 - accuracy: 0.7488 - val_loss: 0.5639 - val_accuracy: 0.6792\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5301 - accuracy: 0.7581 - val_loss: 0.5975 - val_accuracy: 0.6792\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5357 - accuracy: 0.7535 - val_loss: 0.5839 - val_accuracy: 0.6792\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5001 - accuracy: 0.7767 - val_loss: 0.5995 - val_accuracy: 0.6792\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5388 - accuracy: 0.7116 - val_loss: 0.6057 - val_accuracy: 0.6604\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5614 - accuracy: 0.7256 - val_loss: 0.6051 - val_accuracy: 0.6981\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5173 - accuracy: 0.7488 - val_loss: 0.5965 - val_accuracy: 0.7170\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5127 - accuracy: 0.7674 - val_loss: 0.6113 - val_accuracy: 0.6415\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5143 - accuracy: 0.7395 - val_loss: 0.6608 - val_accuracy: 0.6415\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5573 - accuracy: 0.7209 - val_loss: 0.6416 - val_accuracy: 0.6415\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5184 - accuracy: 0.7349 - val_loss: 0.6027 - val_accuracy: 0.6415\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5166 - accuracy: 0.7116 - val_loss: 0.5985 - val_accuracy: 0.6981\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5433 - accuracy: 0.7116 - val_loss: 0.6075 - val_accuracy: 0.6415\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5021 - accuracy: 0.7442 - val_loss: 0.6156 - val_accuracy: 0.6415\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5166 - accuracy: 0.7442 - val_loss: 0.6145 - val_accuracy: 0.6415\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4887 - accuracy: 0.7442 - val_loss: 0.6020 - val_accuracy: 0.6792\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5118 - accuracy: 0.7488 - val_loss: 0.6026 - val_accuracy: 0.6981\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5173 - accuracy: 0.7628 - val_loss: 0.6180 - val_accuracy: 0.6415\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4849 - accuracy: 0.7767 - val_loss: 0.6202 - val_accuracy: 0.6415\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5060 - accuracy: 0.7581 - val_loss: 0.6152 - val_accuracy: 0.6415\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5296 - accuracy: 0.7395 - val_loss: 0.6156 - val_accuracy: 0.6415\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5222 - accuracy: 0.7395 - val_loss: 0.6146 - val_accuracy: 0.6415\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5481 - accuracy: 0.7535 - val_loss: 0.6097 - val_accuracy: 0.6792\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5133 - accuracy: 0.7349 - val_loss: 0.6099 - val_accuracy: 0.6792\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5546 - accuracy: 0.7256 - val_loss: 0.6098 - val_accuracy: 0.6792\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4962 - accuracy: 0.7581 - val_loss: 0.6162 - val_accuracy: 0.6415\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5194 - accuracy: 0.7721 - val_loss: 0.6231 - val_accuracy: 0.6415\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5078 - accuracy: 0.7814 - val_loss: 0.6179 - val_accuracy: 0.6415\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4914 - accuracy: 0.7814 - val_loss: 0.6162 - val_accuracy: 0.6604\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5043 - accuracy: 0.7581 - val_loss: 0.6171 - val_accuracy: 0.6604\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5134 - accuracy: 0.7209 - val_loss: 0.6143 - val_accuracy: 0.7170\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5359 - accuracy: 0.7628 - val_loss: 0.6321 - val_accuracy: 0.6415\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5098 - accuracy: 0.7628 - val_loss: 0.6558 - val_accuracy: 0.6415\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5025 - accuracy: 0.7814 - val_loss: 0.6308 - val_accuracy: 0.6415\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5253 - accuracy: 0.7488 - val_loss: 0.6175 - val_accuracy: 0.6792\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4984 - accuracy: 0.7488 - val_loss: 0.6180 - val_accuracy: 0.6792\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5119 - accuracy: 0.7442 - val_loss: 0.6278 - val_accuracy: 0.6415\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4926 - accuracy: 0.7488 - val_loss: 0.6400 - val_accuracy: 0.6415\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5046 - accuracy: 0.7442 - val_loss: 0.6197 - val_accuracy: 0.7170\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5064 - accuracy: 0.7302 - val_loss: 0.6183 - val_accuracy: 0.7170\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5231 - accuracy: 0.7442 - val_loss: 0.6183 - val_accuracy: 0.7170\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4868 - accuracy: 0.7907 - val_loss: 0.6248 - val_accuracy: 0.6604\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5413 - accuracy: 0.7349 - val_loss: 0.6394 - val_accuracy: 0.6415\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4871 - accuracy: 0.7581 - val_loss: 0.6347 - val_accuracy: 0.6415\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4897 - accuracy: 0.7628 - val_loss: 0.6189 - val_accuracy: 0.7170\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5062 - accuracy: 0.7302 - val_loss: 0.6191 - val_accuracy: 0.7170\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4967 - accuracy: 0.7581 - val_loss: 0.6405 - val_accuracy: 0.6415\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4865 - accuracy: 0.7767 - val_loss: 0.6342 - val_accuracy: 0.6415\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5190 - accuracy: 0.7628 - val_loss: 0.6219 - val_accuracy: 0.7170\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5414 - accuracy: 0.7349 - val_loss: 0.6213 - val_accuracy: 0.6981\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5134 - accuracy: 0.7535 - val_loss: 0.6235 - val_accuracy: 0.6604\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4962 - accuracy: 0.7488 - val_loss: 0.6253 - val_accuracy: 0.6604\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4723 - accuracy: 0.7674 - val_loss: 0.6253 - val_accuracy: 0.6604\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5166 - accuracy: 0.7442 - val_loss: 0.6274 - val_accuracy: 0.6604\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4826 - accuracy: 0.7721 - val_loss: 0.6185 - val_accuracy: 0.7170\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4867 - accuracy: 0.7628 - val_loss: 0.6198 - val_accuracy: 0.7170\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5302 - accuracy: 0.7442 - val_loss: 0.6224 - val_accuracy: 0.6981\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4982 - accuracy: 0.7442 - val_loss: 0.6272 - val_accuracy: 0.6604\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4950 - accuracy: 0.7907 - val_loss: 0.6261 - val_accuracy: 0.6792\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4741 - accuracy: 0.7535 - val_loss: 0.6250 - val_accuracy: 0.6792\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4973 - accuracy: 0.6977 - val_loss: 0.6278 - val_accuracy: 0.6792\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5182 - accuracy: 0.7535 - val_loss: 0.6359 - val_accuracy: 0.6604\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5025 - accuracy: 0.7302 - val_loss: 0.6248 - val_accuracy: 0.6792\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4837 - accuracy: 0.7721 - val_loss: 0.6253 - val_accuracy: 0.6792\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5036 - accuracy: 0.7535 - val_loss: 0.6294 - val_accuracy: 0.6792\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5174 - accuracy: 0.7535 - val_loss: 0.6312 - val_accuracy: 0.6792\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4955 - accuracy: 0.7721 - val_loss: 0.6358 - val_accuracy: 0.6604\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4983 - accuracy: 0.7767 - val_loss: 0.6315 - val_accuracy: 0.6792\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5022 - accuracy: 0.7674 - val_loss: 0.6270 - val_accuracy: 0.6792\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4909 - accuracy: 0.7814 - val_loss: 0.6257 - val_accuracy: 0.6792\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4739 - accuracy: 0.7581 - val_loss: 0.6244 - val_accuracy: 0.6981\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5067 - accuracy: 0.7535 - val_loss: 0.6263 - val_accuracy: 0.6792\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5341 - accuracy: 0.7070 - val_loss: 0.6232 - val_accuracy: 0.6981\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4861 - accuracy: 0.7535 - val_loss: 0.6337 - val_accuracy: 0.6604\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4712 - accuracy: 0.7442 - val_loss: 0.6348 - val_accuracy: 0.6604\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4749 - accuracy: 0.7814 - val_loss: 0.6197 - val_accuracy: 0.7170\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4942 - accuracy: 0.7907 - val_loss: 0.6228 - val_accuracy: 0.7358\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5107 - accuracy: 0.7581 - val_loss: 0.6201 - val_accuracy: 0.7358\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4970 - accuracy: 0.7535 - val_loss: 0.6258 - val_accuracy: 0.6604\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4879 - accuracy: 0.7674 - val_loss: 0.6388 - val_accuracy: 0.6415\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5110 - accuracy: 0.7395 - val_loss: 0.6231 - val_accuracy: 0.6792\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4759 - accuracy: 0.7814 - val_loss: 0.6142 - val_accuracy: 0.7170\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5146 - accuracy: 0.7488 - val_loss: 0.6150 - val_accuracy: 0.7358\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5118 - accuracy: 0.7209 - val_loss: 0.6203 - val_accuracy: 0.6981\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4735 - accuracy: 0.7581 - val_loss: 0.6250 - val_accuracy: 0.6604\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4747 - accuracy: 0.7721 - val_loss: 0.6205 - val_accuracy: 0.6981\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4996 - accuracy: 0.7209 - val_loss: 0.6196 - val_accuracy: 0.7358\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5065 - accuracy: 0.7581 - val_loss: 0.6188 - val_accuracy: 0.7170\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5000 - accuracy: 0.7767 - val_loss: 0.6279 - val_accuracy: 0.6604\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5045 - accuracy: 0.7581 - val_loss: 0.6209 - val_accuracy: 0.7170\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5113 - accuracy: 0.7442 - val_loss: 0.6209 - val_accuracy: 0.7170\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5033 - accuracy: 0.7488 - val_loss: 0.6218 - val_accuracy: 0.7170\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4945 - accuracy: 0.7535 - val_loss: 0.6200 - val_accuracy: 0.7170\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4911 - accuracy: 0.7488 - val_loss: 0.6220 - val_accuracy: 0.6981\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4847 - accuracy: 0.7395 - val_loss: 0.6196 - val_accuracy: 0.6981\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4902 - accuracy: 0.7442 - val_loss: 0.6169 - val_accuracy: 0.7170\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4910 - accuracy: 0.7581 - val_loss: 0.6182 - val_accuracy: 0.7358\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4674 - accuracy: 0.7581 - val_loss: 0.6148 - val_accuracy: 0.7170\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4818 - accuracy: 0.7395 - val_loss: 0.6148 - val_accuracy: 0.6981\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5084 - accuracy: 0.7674 - val_loss: 0.6150 - val_accuracy: 0.6981\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4907 - accuracy: 0.7674 - val_loss: 0.6134 - val_accuracy: 0.7170\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4925 - accuracy: 0.7349 - val_loss: 0.6140 - val_accuracy: 0.7170\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5041 - accuracy: 0.8140 - val_loss: 0.6153 - val_accuracy: 0.7170\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5196 - accuracy: 0.7395 - val_loss: 0.6152 - val_accuracy: 0.7170\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5113 - accuracy: 0.7628 - val_loss: 0.6163 - val_accuracy: 0.7170\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4882 - accuracy: 0.7349 - val_loss: 0.6209 - val_accuracy: 0.6792\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4810 - accuracy: 0.7814 - val_loss: 0.6188 - val_accuracy: 0.6981\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4736 - accuracy: 0.7907 - val_loss: 0.6175 - val_accuracy: 0.7170\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4534 - accuracy: 0.7907 - val_loss: 0.6179 - val_accuracy: 0.7170\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.6182 - val_accuracy: 0.7170\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4735 - accuracy: 0.7442 - val_loss: 0.6184 - val_accuracy: 0.7170\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4671 - accuracy: 0.7860 - val_loss: 0.6210 - val_accuracy: 0.6981\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4940 - accuracy: 0.7721 - val_loss: 0.6185 - val_accuracy: 0.7170\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4723 - accuracy: 0.7535 - val_loss: 0.6184 - val_accuracy: 0.7170\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.7907 - val_loss: 0.6174 - val_accuracy: 0.7170\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4917 - accuracy: 0.7674 - val_loss: 0.6168 - val_accuracy: 0.7170\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5093 - accuracy: 0.7535 - val_loss: 0.6162 - val_accuracy: 0.7170\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4589 - accuracy: 0.7581 - val_loss: 0.6158 - val_accuracy: 0.7170\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4953 - accuracy: 0.7860 - val_loss: 0.6161 - val_accuracy: 0.7170\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4641 - accuracy: 0.7581 - val_loss: 0.6154 - val_accuracy: 0.7170\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4796 - accuracy: 0.7721 - val_loss: 0.6156 - val_accuracy: 0.7170\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4892 - accuracy: 0.7488 - val_loss: 0.6158 - val_accuracy: 0.7170\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4808 - accuracy: 0.7535 - val_loss: 0.6162 - val_accuracy: 0.7170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5019 - accuracy: 0.7442 - val_loss: 0.6181 - val_accuracy: 0.7170\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4821 - accuracy: 0.7488 - val_loss: 0.6164 - val_accuracy: 0.7170\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5000 - accuracy: 0.7349 - val_loss: 0.6201 - val_accuracy: 0.6981\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4897 - accuracy: 0.7302 - val_loss: 0.6222 - val_accuracy: 0.6981\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5202 - accuracy: 0.7721 - val_loss: 0.6171 - val_accuracy: 0.7170\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4893 - accuracy: 0.7674 - val_loss: 0.6221 - val_accuracy: 0.6604\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5059 - accuracy: 0.7581 - val_loss: 0.6183 - val_accuracy: 0.7170\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4664 - accuracy: 0.7674 - val_loss: 0.6193 - val_accuracy: 0.7170\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4643 - accuracy: 0.8000 - val_loss: 0.6188 - val_accuracy: 0.7170\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5246 - accuracy: 0.7395 - val_loss: 0.6203 - val_accuracy: 0.6981\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4886 - accuracy: 0.7395 - val_loss: 0.6225 - val_accuracy: 0.6792\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5075 - accuracy: 0.7488 - val_loss: 0.6204 - val_accuracy: 0.6981\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4770 - accuracy: 0.7721 - val_loss: 0.6232 - val_accuracy: 0.7170\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4917 - accuracy: 0.7628 - val_loss: 0.6246 - val_accuracy: 0.7170\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4581 - accuracy: 0.8000 - val_loss: 0.6237 - val_accuracy: 0.6981\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4812 - accuracy: 0.7860 - val_loss: 0.6257 - val_accuracy: 0.6981\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4602 - accuracy: 0.7674 - val_loss: 0.6287 - val_accuracy: 0.6604\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4999 - accuracy: 0.7488 - val_loss: 0.6276 - val_accuracy: 0.6981\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5126 - accuracy: 0.7302 - val_loss: 0.6307 - val_accuracy: 0.7170\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4929 - accuracy: 0.7628 - val_loss: 0.6311 - val_accuracy: 0.6792\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5050 - accuracy: 0.7674 - val_loss: 0.6355 - val_accuracy: 0.6604\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4824 - accuracy: 0.7907 - val_loss: 0.6365 - val_accuracy: 0.6604\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4809 - accuracy: 0.7767 - val_loss: 0.6336 - val_accuracy: 0.6604\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4700 - accuracy: 0.7721 - val_loss: 0.6302 - val_accuracy: 0.6981\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5135 - accuracy: 0.7395 - val_loss: 0.6277 - val_accuracy: 0.6981\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5246 - accuracy: 0.7395 - val_loss: 0.6251 - val_accuracy: 0.7170\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5089 - accuracy: 0.7628 - val_loss: 0.6227 - val_accuracy: 0.7170\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4695 - accuracy: 0.7814 - val_loss: 0.6212 - val_accuracy: 0.6981\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4810 - accuracy: 0.7628 - val_loss: 0.6243 - val_accuracy: 0.6792\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5040 - accuracy: 0.7628 - val_loss: 0.6253 - val_accuracy: 0.6604\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4811 - accuracy: 0.7628 - val_loss: 0.6204 - val_accuracy: 0.7170\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4996 - accuracy: 0.7395 - val_loss: 0.6251 - val_accuracy: 0.7547\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4839 - accuracy: 0.7674 - val_loss: 0.6205 - val_accuracy: 0.7170\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4728 - accuracy: 0.7674 - val_loss: 0.6219 - val_accuracy: 0.6981\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4763 - accuracy: 0.7721 - val_loss: 0.6228 - val_accuracy: 0.6981\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4832 - accuracy: 0.7628 - val_loss: 0.6249 - val_accuracy: 0.7170\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5014 - accuracy: 0.7442 - val_loss: 0.6264 - val_accuracy: 0.7170\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4692 - accuracy: 0.7721 - val_loss: 0.6245 - val_accuracy: 0.7170\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5264 - accuracy: 0.7442 - val_loss: 0.6256 - val_accuracy: 0.6981\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4851 - accuracy: 0.7721 - val_loss: 0.6255 - val_accuracy: 0.6981\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4822 - accuracy: 0.7535 - val_loss: 0.6245 - val_accuracy: 0.7358\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4907 - accuracy: 0.7674 - val_loss: 0.6257 - val_accuracy: 0.7358\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4794 - accuracy: 0.7395 - val_loss: 0.6278 - val_accuracy: 0.7170\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4691 - accuracy: 0.7814 - val_loss: 0.6279 - val_accuracy: 0.6981\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4718 - accuracy: 0.7628 - val_loss: 0.6265 - val_accuracy: 0.6981\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4753 - accuracy: 0.7628 - val_loss: 0.6327 - val_accuracy: 0.6604\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5089 - accuracy: 0.7442 - val_loss: 0.6249 - val_accuracy: 0.6792\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4538 - accuracy: 0.7628 - val_loss: 0.6236 - val_accuracy: 0.7358\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5130 - accuracy: 0.7163 - val_loss: 0.6235 - val_accuracy: 0.7547\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4726 - accuracy: 0.7674 - val_loss: 0.6216 - val_accuracy: 0.7170\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4705 - accuracy: 0.7581 - val_loss: 0.6283 - val_accuracy: 0.6604\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5047 - accuracy: 0.7814 - val_loss: 0.6291 - val_accuracy: 0.6604\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5021 - accuracy: 0.7349 - val_loss: 0.6232 - val_accuracy: 0.7358\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4506 - accuracy: 0.7721 - val_loss: 0.6272 - val_accuracy: 0.6981\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.7767 - val_loss: 0.6269 - val_accuracy: 0.6981\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4496 - accuracy: 0.7581 - val_loss: 0.6239 - val_accuracy: 0.7358\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4549 - accuracy: 0.7721 - val_loss: 0.6248 - val_accuracy: 0.7170\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4507 - accuracy: 0.7953 - val_loss: 0.6270 - val_accuracy: 0.7170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4629 - accuracy: 0.7814 - val_loss: 0.6306 - val_accuracy: 0.6792\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4744 - accuracy: 0.7442 - val_loss: 0.6315 - val_accuracy: 0.6981\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4653 - accuracy: 0.7628 - val_loss: 0.6312 - val_accuracy: 0.7170\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4835 - accuracy: 0.7628 - val_loss: 0.6312 - val_accuracy: 0.7170\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5009 - accuracy: 0.7628 - val_loss: 0.6313 - val_accuracy: 0.7170\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B929F1F790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6925 - accuracy: 0.5535 - val_loss: 0.6570 - val_accuracy: 0.6038\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6764 - accuracy: 0.5581 - val_loss: 0.6394 - val_accuracy: 0.6038\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6715 - accuracy: 0.5814 - val_loss: 0.5906 - val_accuracy: 0.7925\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6443 - accuracy: 0.6093 - val_loss: 0.5690 - val_accuracy: 0.8113\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6149 - accuracy: 0.6837 - val_loss: 0.5603 - val_accuracy: 0.8113\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6064 - accuracy: 0.6744 - val_loss: 0.5472 - val_accuracy: 0.8302\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6024 - accuracy: 0.6791 - val_loss: 0.5390 - val_accuracy: 0.8302\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6016 - accuracy: 0.6558 - val_loss: 0.5314 - val_accuracy: 0.8302\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5942 - accuracy: 0.6791 - val_loss: 0.5244 - val_accuracy: 0.8113\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5646 - accuracy: 0.7163 - val_loss: 0.5152 - val_accuracy: 0.7736\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6013 - accuracy: 0.6837 - val_loss: 0.5096 - val_accuracy: 0.7358\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5685 - accuracy: 0.6930 - val_loss: 0.5065 - val_accuracy: 0.7358\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5834 - accuracy: 0.7116 - val_loss: 0.5077 - val_accuracy: 0.8302\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5843 - accuracy: 0.6930 - val_loss: 0.5132 - val_accuracy: 0.8302\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.7442 - val_loss: 0.5194 - val_accuracy: 0.7925\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5757 - accuracy: 0.6930 - val_loss: 0.5090 - val_accuracy: 0.8302\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5571 - accuracy: 0.6930 - val_loss: 0.5075 - val_accuracy: 0.7925\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5779 - accuracy: 0.6930 - val_loss: 0.5032 - val_accuracy: 0.7925\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5780 - accuracy: 0.6791 - val_loss: 0.4942 - val_accuracy: 0.8113\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5303 - accuracy: 0.7581 - val_loss: 0.4875 - val_accuracy: 0.8113\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5637 - accuracy: 0.6930 - val_loss: 0.4872 - val_accuracy: 0.8113\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5649 - accuracy: 0.7163 - val_loss: 0.4933 - val_accuracy: 0.8113\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5623 - accuracy: 0.6884 - val_loss: 0.4970 - val_accuracy: 0.7925\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5512 - accuracy: 0.7116 - val_loss: 0.4919 - val_accuracy: 0.8113\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5529 - accuracy: 0.7116 - val_loss: 0.4909 - val_accuracy: 0.7736\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5637 - accuracy: 0.6977 - val_loss: 0.4923 - val_accuracy: 0.7736\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5657 - accuracy: 0.7023 - val_loss: 0.4945 - val_accuracy: 0.8113\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5558 - accuracy: 0.6744 - val_loss: 0.4957 - val_accuracy: 0.8113\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5462 - accuracy: 0.7442 - val_loss: 0.4940 - val_accuracy: 0.8113\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5587 - accuracy: 0.7116 - val_loss: 0.4886 - val_accuracy: 0.7925\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5624 - accuracy: 0.7163 - val_loss: 0.4871 - val_accuracy: 0.7925\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5472 - accuracy: 0.6884 - val_loss: 0.4868 - val_accuracy: 0.7925\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5767 - accuracy: 0.7209 - val_loss: 0.4856 - val_accuracy: 0.7925\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5527 - accuracy: 0.7023 - val_loss: 0.4867 - val_accuracy: 0.7925\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5475 - accuracy: 0.7070 - val_loss: 0.4885 - val_accuracy: 0.7925\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5525 - accuracy: 0.7395 - val_loss: 0.4886 - val_accuracy: 0.7925\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5634 - accuracy: 0.7163 - val_loss: 0.4908 - val_accuracy: 0.7925\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5714 - accuracy: 0.6930 - val_loss: 0.4881 - val_accuracy: 0.7925\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5482 - accuracy: 0.7349 - val_loss: 0.4960 - val_accuracy: 0.7925\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5481 - accuracy: 0.7023 - val_loss: 0.4952 - val_accuracy: 0.8113\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5762 - accuracy: 0.7116 - val_loss: 0.4860 - val_accuracy: 0.7925\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5334 - accuracy: 0.7442 - val_loss: 0.4854 - val_accuracy: 0.7925\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5422 - accuracy: 0.7395 - val_loss: 0.4831 - val_accuracy: 0.7925\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5498 - accuracy: 0.7116 - val_loss: 0.4814 - val_accuracy: 0.7736\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5717 - accuracy: 0.7116 - val_loss: 0.4837 - val_accuracy: 0.7170\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5693 - accuracy: 0.6791 - val_loss: 0.4837 - val_accuracy: 0.7736\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5683 - accuracy: 0.7070 - val_loss: 0.4857 - val_accuracy: 0.7736\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5458 - accuracy: 0.7256 - val_loss: 0.4895 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5608 - accuracy: 0.7209 - val_loss: 0.4908 - val_accuracy: 0.7736\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5479 - accuracy: 0.7209 - val_loss: 0.4947 - val_accuracy: 0.7736\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5652 - accuracy: 0.6977 - val_loss: 0.4990 - val_accuracy: 0.8113\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5420 - accuracy: 0.7163 - val_loss: 0.5093 - val_accuracy: 0.8113\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5828 - accuracy: 0.6884 - val_loss: 0.5119 - val_accuracy: 0.7925\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5443 - accuracy: 0.6977 - val_loss: 0.4975 - val_accuracy: 0.7925\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5557 - accuracy: 0.7023 - val_loss: 0.4910 - val_accuracy: 0.7170\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5561 - accuracy: 0.6977 - val_loss: 0.4916 - val_accuracy: 0.7170\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5375 - accuracy: 0.6884 - val_loss: 0.4912 - val_accuracy: 0.7736\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5403 - accuracy: 0.7209 - val_loss: 0.5048 - val_accuracy: 0.8113\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5624 - accuracy: 0.7209 - val_loss: 0.5070 - val_accuracy: 0.7736\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5786 - accuracy: 0.6884 - val_loss: 0.4885 - val_accuracy: 0.7736\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5458 - accuracy: 0.7256 - val_loss: 0.4872 - val_accuracy: 0.7170\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5574 - accuracy: 0.7116 - val_loss: 0.4906 - val_accuracy: 0.7170\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5604 - accuracy: 0.6698 - val_loss: 0.4842 - val_accuracy: 0.7736\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5575 - accuracy: 0.6977 - val_loss: 0.4928 - val_accuracy: 0.7925\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5675 - accuracy: 0.6930 - val_loss: 0.4875 - val_accuracy: 0.7736\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5228 - accuracy: 0.7349 - val_loss: 0.4846 - val_accuracy: 0.7736\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5299 - accuracy: 0.7116 - val_loss: 0.4846 - val_accuracy: 0.7736\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5324 - accuracy: 0.7395 - val_loss: 0.4849 - val_accuracy: 0.7547\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5682 - accuracy: 0.6977 - val_loss: 0.4848 - val_accuracy: 0.7736\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5753 - accuracy: 0.7023 - val_loss: 0.4874 - val_accuracy: 0.7736\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5537 - accuracy: 0.6884 - val_loss: 0.4920 - val_accuracy: 0.7925\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5533 - accuracy: 0.7070 - val_loss: 0.4872 - val_accuracy: 0.7736\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5705 - accuracy: 0.6558 - val_loss: 0.4843 - val_accuracy: 0.7736\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5425 - accuracy: 0.7023 - val_loss: 0.4826 - val_accuracy: 0.7736\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.6930 - val_loss: 0.4819 - val_accuracy: 0.7736\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5373 - accuracy: 0.7163 - val_loss: 0.4810 - val_accuracy: 0.7736\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5432 - accuracy: 0.7116 - val_loss: 0.4803 - val_accuracy: 0.7736\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5492 - accuracy: 0.7256 - val_loss: 0.4790 - val_accuracy: 0.7736\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5589 - accuracy: 0.6791 - val_loss: 0.4801 - val_accuracy: 0.7736\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5639 - accuracy: 0.7256 - val_loss: 0.4797 - val_accuracy: 0.7736\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5546 - accuracy: 0.7209 - val_loss: 0.4817 - val_accuracy: 0.7736\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5419 - accuracy: 0.7209 - val_loss: 0.4817 - val_accuracy: 0.7736\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.7116 - val_loss: 0.4818 - val_accuracy: 0.7736\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5533 - accuracy: 0.7302 - val_loss: 0.4838 - val_accuracy: 0.7925\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5147 - accuracy: 0.7442 - val_loss: 0.4808 - val_accuracy: 0.7736\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5576 - accuracy: 0.6791 - val_loss: 0.4811 - val_accuracy: 0.7736\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5457 - accuracy: 0.7209 - val_loss: 0.4809 - val_accuracy: 0.7736\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5480 - accuracy: 0.7302 - val_loss: 0.4827 - val_accuracy: 0.7736\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5731 - accuracy: 0.7023 - val_loss: 0.4818 - val_accuracy: 0.7736\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5389 - accuracy: 0.6977 - val_loss: 0.4784 - val_accuracy: 0.7736\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5611 - accuracy: 0.7116 - val_loss: 0.4776 - val_accuracy: 0.7736\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5341 - accuracy: 0.7116 - val_loss: 0.4761 - val_accuracy: 0.7736\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5615 - accuracy: 0.7070 - val_loss: 0.4768 - val_accuracy: 0.7925\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5894 - accuracy: 0.6837 - val_loss: 0.4724 - val_accuracy: 0.7736\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5736 - accuracy: 0.7023 - val_loss: 0.4747 - val_accuracy: 0.7736\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5502 - accuracy: 0.7209 - val_loss: 0.4734 - val_accuracy: 0.7736\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5459 - accuracy: 0.7163 - val_loss: 0.4789 - val_accuracy: 0.7925\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5509 - accuracy: 0.6884 - val_loss: 0.4847 - val_accuracy: 0.7925\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5769 - accuracy: 0.6744 - val_loss: 0.4814 - val_accuracy: 0.7736\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5616 - accuracy: 0.6744 - val_loss: 0.4783 - val_accuracy: 0.7736\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5366 - accuracy: 0.7163 - val_loss: 0.4779 - val_accuracy: 0.7736\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.6558 - val_loss: 0.4876 - val_accuracy: 0.8113\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5603 - accuracy: 0.7209 - val_loss: 0.4851 - val_accuracy: 0.8113\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5468 - accuracy: 0.7256 - val_loss: 0.4749 - val_accuracy: 0.7736\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5458 - accuracy: 0.6977 - val_loss: 0.4777 - val_accuracy: 0.7547\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5666 - accuracy: 0.6791 - val_loss: 0.4771 - val_accuracy: 0.7547\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5562 - accuracy: 0.7070 - val_loss: 0.4770 - val_accuracy: 0.7736\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5433 - accuracy: 0.7302 - val_loss: 0.4862 - val_accuracy: 0.8113\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.7349 - val_loss: 0.4782 - val_accuracy: 0.7736\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5363 - accuracy: 0.7209 - val_loss: 0.4777 - val_accuracy: 0.7736\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5528 - accuracy: 0.7070 - val_loss: 0.4788 - val_accuracy: 0.7736\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5161 - accuracy: 0.7302 - val_loss: 0.4784 - val_accuracy: 0.7736\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5638 - accuracy: 0.7023 - val_loss: 0.4775 - val_accuracy: 0.7736\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5044 - accuracy: 0.7302 - val_loss: 0.4752 - val_accuracy: 0.7736\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5655 - accuracy: 0.7070 - val_loss: 0.4752 - val_accuracy: 0.7736\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5650 - accuracy: 0.6930 - val_loss: 0.4751 - val_accuracy: 0.7736\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5512 - accuracy: 0.7302 - val_loss: 0.4756 - val_accuracy: 0.7925\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5246 - accuracy: 0.7302 - val_loss: 0.4780 - val_accuracy: 0.7925\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5512 - accuracy: 0.7163 - val_loss: 0.4736 - val_accuracy: 0.7736\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5143 - accuracy: 0.7302 - val_loss: 0.4739 - val_accuracy: 0.7736\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5267 - accuracy: 0.7070 - val_loss: 0.4743 - val_accuracy: 0.7736\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5215 - accuracy: 0.7628 - val_loss: 0.4788 - val_accuracy: 0.7925\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5461 - accuracy: 0.7116 - val_loss: 0.4745 - val_accuracy: 0.7736\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5493 - accuracy: 0.7070 - val_loss: 0.4739 - val_accuracy: 0.7736\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5709 - accuracy: 0.6977 - val_loss: 0.4756 - val_accuracy: 0.7736\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5523 - accuracy: 0.7023 - val_loss: 0.4760 - val_accuracy: 0.7736\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5375 - accuracy: 0.6837 - val_loss: 0.4791 - val_accuracy: 0.7925\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5433 - accuracy: 0.7256 - val_loss: 0.4806 - val_accuracy: 0.8113\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5588 - accuracy: 0.6744 - val_loss: 0.4779 - val_accuracy: 0.7736\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5274 - accuracy: 0.7488 - val_loss: 0.4761 - val_accuracy: 0.7547\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5613 - accuracy: 0.7070 - val_loss: 0.4923 - val_accuracy: 0.7925\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5898 - accuracy: 0.6326 - val_loss: 0.5059 - val_accuracy: 0.7925\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5666 - accuracy: 0.6558 - val_loss: 0.5128 - val_accuracy: 0.7925\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5425 - accuracy: 0.7116 - val_loss: 0.4948 - val_accuracy: 0.7925\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5449 - accuracy: 0.6930 - val_loss: 0.4925 - val_accuracy: 0.7170\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5534 - accuracy: 0.6930 - val_loss: 0.4937 - val_accuracy: 0.7170\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5622 - accuracy: 0.6744 - val_loss: 0.4938 - val_accuracy: 0.7736\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6011 - accuracy: 0.6698 - val_loss: 0.4980 - val_accuracy: 0.7925\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5158 - accuracy: 0.7442 - val_loss: 0.4927 - val_accuracy: 0.7925\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5697 - accuracy: 0.6977 - val_loss: 0.4880 - val_accuracy: 0.7547\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5585 - accuracy: 0.7163 - val_loss: 0.4852 - val_accuracy: 0.7736\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5613 - accuracy: 0.6977 - val_loss: 0.4848 - val_accuracy: 0.7925\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5662 - accuracy: 0.7023 - val_loss: 0.4853 - val_accuracy: 0.7925\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5723 - accuracy: 0.7209 - val_loss: 0.4834 - val_accuracy: 0.7736\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5447 - accuracy: 0.7116 - val_loss: 0.4836 - val_accuracy: 0.7736\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5818 - accuracy: 0.6605 - val_loss: 0.4842 - val_accuracy: 0.7358\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5608 - accuracy: 0.7023 - val_loss: 0.4847 - val_accuracy: 0.7736\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5422 - accuracy: 0.7349 - val_loss: 0.4923 - val_accuracy: 0.7925\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5595 - accuracy: 0.7209 - val_loss: 0.4942 - val_accuracy: 0.7925\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5775 - accuracy: 0.6930 - val_loss: 0.4913 - val_accuracy: 0.7925\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5405 - accuracy: 0.7116 - val_loss: 0.4880 - val_accuracy: 0.7736\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5241 - accuracy: 0.7163 - val_loss: 0.4874 - val_accuracy: 0.7736\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5581 - accuracy: 0.7023 - val_loss: 0.4887 - val_accuracy: 0.7736\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5309 - accuracy: 0.7349 - val_loss: 0.4885 - val_accuracy: 0.7736\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5636 - accuracy: 0.7023 - val_loss: 0.4889 - val_accuracy: 0.7925\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5309 - accuracy: 0.7163 - val_loss: 0.4874 - val_accuracy: 0.7736\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5352 - accuracy: 0.7070 - val_loss: 0.4852 - val_accuracy: 0.7736\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5303 - accuracy: 0.7209 - val_loss: 0.4840 - val_accuracy: 0.7736\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5448 - accuracy: 0.7302 - val_loss: 0.4853 - val_accuracy: 0.7736\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5408 - accuracy: 0.6977 - val_loss: 0.4949 - val_accuracy: 0.8113\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5341 - accuracy: 0.7209 - val_loss: 0.5063 - val_accuracy: 0.7547\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5600 - accuracy: 0.6930 - val_loss: 0.4957 - val_accuracy: 0.7925\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5243 - accuracy: 0.6977 - val_loss: 0.4859 - val_accuracy: 0.7736\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5545 - accuracy: 0.7070 - val_loss: 0.4847 - val_accuracy: 0.7547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5444 - accuracy: 0.7209 - val_loss: 0.4852 - val_accuracy: 0.7736\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5451 - accuracy: 0.7163 - val_loss: 0.4896 - val_accuracy: 0.7925\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5383 - accuracy: 0.7256 - val_loss: 0.4892 - val_accuracy: 0.7925\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5328 - accuracy: 0.7302 - val_loss: 0.4860 - val_accuracy: 0.7925\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5565 - accuracy: 0.6884 - val_loss: 0.4829 - val_accuracy: 0.7736\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5798 - accuracy: 0.7116 - val_loss: 0.4825 - val_accuracy: 0.7547\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5586 - accuracy: 0.6930 - val_loss: 0.4816 - val_accuracy: 0.7547\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5536 - accuracy: 0.6884 - val_loss: 0.4821 - val_accuracy: 0.7925\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5475 - accuracy: 0.7070 - val_loss: 0.4818 - val_accuracy: 0.7925\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5227 - accuracy: 0.7163 - val_loss: 0.4799 - val_accuracy: 0.7925\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5698 - accuracy: 0.6744 - val_loss: 0.4780 - val_accuracy: 0.7736\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5561 - accuracy: 0.6930 - val_loss: 0.4765 - val_accuracy: 0.7736\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5459 - accuracy: 0.7070 - val_loss: 0.4770 - val_accuracy: 0.7736\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5371 - accuracy: 0.7116 - val_loss: 0.4770 - val_accuracy: 0.7925\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5473 - accuracy: 0.7116 - val_loss: 0.4729 - val_accuracy: 0.8113\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5327 - accuracy: 0.7116 - val_loss: 0.4721 - val_accuracy: 0.8113\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5465 - accuracy: 0.7209 - val_loss: 0.4723 - val_accuracy: 0.7925\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5607 - accuracy: 0.6977 - val_loss: 0.4718 - val_accuracy: 0.7925\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5283 - accuracy: 0.7535 - val_loss: 0.4707 - val_accuracy: 0.7925\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5280 - accuracy: 0.7302 - val_loss: 0.4707 - val_accuracy: 0.7736\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5474 - accuracy: 0.7163 - val_loss: 0.4700 - val_accuracy: 0.7736\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5755 - accuracy: 0.6744 - val_loss: 0.4705 - val_accuracy: 0.7736\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5686 - accuracy: 0.7116 - val_loss: 0.4753 - val_accuracy: 0.8113\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5368 - accuracy: 0.7163 - val_loss: 0.4760 - val_accuracy: 0.8113\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5387 - accuracy: 0.7209 - val_loss: 0.4745 - val_accuracy: 0.8113\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5205 - accuracy: 0.7488 - val_loss: 0.4786 - val_accuracy: 0.8113\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5798 - accuracy: 0.6791 - val_loss: 0.4739 - val_accuracy: 0.7736\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5563 - accuracy: 0.7209 - val_loss: 0.4770 - val_accuracy: 0.7358\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5553 - accuracy: 0.6744 - val_loss: 0.4802 - val_accuracy: 0.7170\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5567 - accuracy: 0.7116 - val_loss: 0.4859 - val_accuracy: 0.7925\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5345 - accuracy: 0.7349 - val_loss: 0.5036 - val_accuracy: 0.7925\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5610 - accuracy: 0.7070 - val_loss: 0.4944 - val_accuracy: 0.7925\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5583 - accuracy: 0.6837 - val_loss: 0.4888 - val_accuracy: 0.7170\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5512 - accuracy: 0.7302 - val_loss: 0.4918 - val_accuracy: 0.7358\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5513 - accuracy: 0.6837 - val_loss: 0.4872 - val_accuracy: 0.7358\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5759 - accuracy: 0.6930 - val_loss: 0.4871 - val_accuracy: 0.7736\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B900890670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name='Burglary'\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/'+'Theft/'+'/CDI_Based/Intensity/CSV/'+'Optical_Mag'+'.csv',index_col=0)\n",
    "\n",
    "Gray_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Gray.csv',index_col=0)\n",
    "Gray_data=Gray_data.drop(['27'], axis=1)\n",
    "Canny_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Canny.csv',index_col=0)\n",
    "Canny_data=Canny_data.drop(['27'], axis=1)\n",
    "Laplacian_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Laplacian.csv',index_col=0)\n",
    "Laplacian_data=Laplacian_data.drop(['27'], axis=1)\n",
    "Harris_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Harris.csv',index_col=0)\n",
    "Harris_data=Harris_data.drop(['27'], axis=1)\n",
    "Optical_Ang_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Optical_Ang.csv',index_col=0)\n",
    "Optical_Mag_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Optical_Mag.csv',index_col=0)\n",
    "Euler_data = pd.read_csv('C:/Users/jingy/Jupyter/Crime/Combine/CDI/Intensity/CSV/'+dataset_name+'/Euler.csv',index_col=0)\n",
    "Euler_data=Euler_data.drop(['27'], axis=1)\n",
    "y=Gray_data['Class'].values\n",
    "Gray_X=Gray_data.drop(['Class'], axis=1).values\n",
    "Canny_X=Canny_data.drop(['Class'], axis=1).values\n",
    "Laplacian_X=Laplacian_data.drop(['Class'], axis=1).values\n",
    "Harris_X=Harris_data.drop(['Class'], axis=1).values\n",
    "Optical_Ang_X=Optical_Ang_data.drop(['Class'], axis=1).values\n",
    "Optical_Mag_X=Optical_Mag_data.drop(['Class'], axis=1).values\n",
    "Euler_X=Euler_data.drop(['Class'], axis=1).values\n",
    "X=np.dstack((Gray_X,Canny_X,Laplacian_X,Harris_X,Optical_Mag_X,Euler_X,Optical_Ang_X))\n",
    "#X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "#     std =StandardScaler()\n",
    "#     X_train=std.fit_transform(X[train])\n",
    "#     X_test=std.transform(X[test])\n",
    "#     X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#     X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    X_train,X_test=X[train],X[test]\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "          LSTM(\n",
    "              units=128,\n",
    "              input_shape=[X_train.shape[1], X_train.shape[2]]\n",
    "          )\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                         optimizer=Adam(lr = lr),\n",
    "                         metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=\"1d+cnn.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "    history=model.fit(X_train, y[train],\n",
    "                epochs=200,\n",
    "                batch_size=64,\n",
    "                validation_data=(X_test, y[test]),\n",
    "                verbose=1,\n",
    "                callbacks=[checkpointer]).history\n",
    "    model=load_model('1d+cnn.h5')\n",
    "    y_prob = model.predict(X_test, verbose=0)\n",
    "    fpr_test,tpr_test,_ = roc_curve(y[test],y_prob)     \n",
    "    auc_test = auc(fpr_test,tpr_test)  \n",
    "    interp_tpr = np.interp(mean_fpr,fpr_test, tpr_test)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(auc_test)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='dodgerblue',label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title='ROC of gray'+ ' on Dataset ')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crowd] *",
   "language": "python",
   "name": "conda-env-crowd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
